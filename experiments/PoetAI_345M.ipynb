{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PoetAI_345M.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Q2gworrugGe_",
        "2_J3hNrk2NOV",
        "Pt0gDyFETs2i"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0725dceb54374e5c91f65cb1cea7f2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5523a41956824d50aa7bd180e468ef2c",
              "IPY_MODEL_a200f6b275f24f6689ea06f11d5604b0",
              "IPY_MODEL_8df96d6ca9564b71958ed6d8c5446f41"
            ],
            "layout": "IPY_MODEL_e0c3e3f6634547559118b584ce006607"
          }
        },
        "5523a41956824d50aa7bd180e468ef2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cf9f00c22b348d297368c5b0b0323ab",
            "placeholder": "​",
            "style": "IPY_MODEL_c6bfb175abdf41328fac71538db6b2a8",
            "value": "Downloading: 100%"
          }
        },
        "a200f6b275f24f6689ea06f11d5604b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f1ef3d0eb79436f827a60b221d5e700",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c012fe8671244921ae1f28365d835695",
            "value": 1042301
          }
        },
        "8df96d6ca9564b71958ed6d8c5446f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_096823c6ee304345a572ee62dd1d546f",
            "placeholder": "​",
            "style": "IPY_MODEL_9f7301098c2d4e7a9577b7d9a4b7f85c",
            "value": " 0.99M/0.99M [00:01&lt;00:00, 995kB/s]"
          }
        },
        "e0c3e3f6634547559118b584ce006607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf9f00c22b348d297368c5b0b0323ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6bfb175abdf41328fac71538db6b2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f1ef3d0eb79436f827a60b221d5e700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c012fe8671244921ae1f28365d835695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "096823c6ee304345a572ee62dd1d546f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f7301098c2d4e7a9577b7d9a4b7f85c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "866e8e096d26426ca2da1069bb1332fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9460c1e427e3456c9a03c1aa4659d13e",
              "IPY_MODEL_751c5b2954ce4d8d9e2039395fcf8253",
              "IPY_MODEL_7256f1d04ba7471eb1fc910799efe332"
            ],
            "layout": "IPY_MODEL_d186fcb5a90c4a37aeecb1099518631e"
          }
        },
        "9460c1e427e3456c9a03c1aa4659d13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db920494faaf4cc9be41394ccade0652",
            "placeholder": "​",
            "style": "IPY_MODEL_9cdf5703bc934b1c87856c15f1202a79",
            "value": "Downloading: 100%"
          }
        },
        "751c5b2954ce4d8d9e2039395fcf8253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ea514dd76e24034808d2003dcd28a3e",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62c0dc854776475395151c5ef59caf68",
            "value": 456318
          }
        },
        "7256f1d04ba7471eb1fc910799efe332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae164cc504ae4753a650c0f458a5add6",
            "placeholder": "​",
            "style": "IPY_MODEL_1ed99a3d148147c99079ac237d4a5f20",
            "value": " 446k/446k [00:01&lt;00:00, 497kB/s]"
          }
        },
        "d186fcb5a90c4a37aeecb1099518631e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db920494faaf4cc9be41394ccade0652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cdf5703bc934b1c87856c15f1202a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ea514dd76e24034808d2003dcd28a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62c0dc854776475395151c5ef59caf68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae164cc504ae4753a650c0f458a5add6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ed99a3d148147c99079ac237d4a5f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5a31fa6871d446e8c5c4e7413954ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1957b6d8c1f4829b592b04ad41f62c8",
              "IPY_MODEL_37c1b4ea4aca42ef9fa4fabcc2daa5e2",
              "IPY_MODEL_036e1ba7a086452daa83bf1e56720197"
            ],
            "layout": "IPY_MODEL_ab34dd3a24d64387b8b6ee033ba97f66"
          }
        },
        "a1957b6d8c1f4829b592b04ad41f62c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa2839985d6e4b0f9e1e568f66ae682e",
            "placeholder": "​",
            "style": "IPY_MODEL_254d8903b3e74fbdae9e7a857263f781",
            "value": "Downloading: 100%"
          }
        },
        "37c1b4ea4aca42ef9fa4fabcc2daa5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_074cc82b4c134df980e62957921a31da",
            "max": 718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9ef5ab4a36f4831a93b6e7629889b27",
            "value": 718
          }
        },
        "036e1ba7a086452daa83bf1e56720197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcc57e1f80af4ba89825d66adffa5737",
            "placeholder": "​",
            "style": "IPY_MODEL_1ba2991e26cb4d7488e6c67226777250",
            "value": " 718/718 [00:00&lt;00:00, 26.8kB/s]"
          }
        },
        "ab34dd3a24d64387b8b6ee033ba97f66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa2839985d6e4b0f9e1e568f66ae682e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "254d8903b3e74fbdae9e7a857263f781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "074cc82b4c134df980e62957921a31da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9ef5ab4a36f4831a93b6e7629889b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcc57e1f80af4ba89825d66adffa5737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ba2991e26cb4d7488e6c67226777250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "491636a480ac47caa9e1b7999af85b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8796083ffd845d0b51e4be4af727e7a",
              "IPY_MODEL_2c1836d231fb4213bbcc179ed2177150",
              "IPY_MODEL_25d51541cbc24e4e8532b69f5903f036"
            ],
            "layout": "IPY_MODEL_5ebae7af124b4597ac4f5318803fabba"
          }
        },
        "f8796083ffd845d0b51e4be4af727e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e6a2a52d03847c0b5e62883fafa719f",
            "placeholder": "​",
            "style": "IPY_MODEL_8aee547c1eb14419ba930b4fa1ed420e",
            "value": "Downloading: 100%"
          }
        },
        "2c1836d231fb4213bbcc179ed2177150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a7bed495c9b4414b9ffba5b7c8f7f94",
            "max": 1520013706,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb89912573104beaad393454fd199014",
            "value": 1520013706
          }
        },
        "25d51541cbc24e4e8532b69f5903f036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2085bf2367e442d807a18829b845918",
            "placeholder": "​",
            "style": "IPY_MODEL_4f6be236287241d0b92ba6e4cdc06841",
            "value": " 1.42G/1.42G [00:25&lt;00:00, 60.2MB/s]"
          }
        },
        "5ebae7af124b4597ac4f5318803fabba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e6a2a52d03847c0b5e62883fafa719f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aee547c1eb14419ba930b4fa1ed420e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a7bed495c9b4414b9ffba5b7c8f7f94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb89912573104beaad393454fd199014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2085bf2367e442d807a18829b845918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f6be236287241d0b92ba6e4cdc06841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashashGaurav/poetai/blob/master/experiments/PoetAI_345M_submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instance Checks"
      ],
      "metadata": {
        "id": "VfDqz8QkTgrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "metadata": {
        "id": "NoqNNU3JTipr",
        "outputId": "4446823a-f86d-42c4-c4d2-157a062ca966",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 26 04:38:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dependencies"
      ],
      "metadata": {
        "id": "yyk5qs5BTQAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers[sentencepiece]\n",
        "! pip install einops\n",
        "! pip install python-Levenshtein\n",
        "! pip install neptune-client\n",
        "! pip install deep-phonemizer"
      ],
      "metadata": {
        "id": "UPBGeasCCIrS",
        "outputId": "cc9e8dfd-e012-426c-d871-ff835a863845",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers[sentencepiece]\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 34.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 76.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 91.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 92.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 65.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[sentencepiece]) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[sentencepiece]) (3.8.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers[sentencepiece]) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.18.0\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.1\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149873 sha256=72c3bf9091d997e3744f1a6e411097eec3ac5a654d84aaba4768be0051c811ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.2\n",
            "Collecting neptune-client\n",
            "  Downloading neptune-client-0.16.1.tar.gz (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 37.5 MB/s \n",
            "\u001b[?25hCollecting bravado\n",
            "  Downloading bravado-11.0.3-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 61.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (3.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.5)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting PyJWT\n",
            "  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.15.0)\n",
            "Collecting websocket-client!=1.0.0,>=0.35.0\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting GitPython>=2.0.8\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 69.7 MB/s \n",
            "\u001b[?25hCollecting boto3>=1.16.0\n",
            "  Downloading boto3-1.22.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 77.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from neptune-client) (21.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.24.3)\n",
            "Collecting swagger-spec-validator>=2.7.4\n",
            "  Downloading swagger_spec_validator-2.7.4-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from neptune-client) (5.4.8)\n",
            "Collecting botocore<1.26.0,>=1.25.0\n",
            "  Downloading botocore-1.25.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 70.4 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.26.0,>=1.25.0->boto3>=1.16.0->neptune-client) (2.8.2)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 73.6 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=2.0.8->neptune-client) (4.2.0)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 80.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (3.0.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (4.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (6.0)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 84.2 MB/s \n",
            "\u001b[?25hCollecting monotonic\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (1.0.3)\n",
            "Collecting bravado-core>=5.16.1\n",
            "  Downloading bravado_core-5.17.0-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting jsonref\n",
            "  Downloading jsonref-0.2-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2022.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (4.11.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (5.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.18.1)\n",
            "Collecting rfc3339-validator\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting fqdn\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting webcolors>=1.11\n",
            "  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n",
            "Collecting uri-template\n",
            "  Downloading uri_template-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting rfc3987\n",
            "  Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\n",
            "Collecting isoduration\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting jsonpointer>1.13\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (3.8.0)\n",
            "Requirement already satisfied: cached-property>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from fqdn->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.5.2)\n",
            "Collecting arrow>=0.15.0\n",
            "  Downloading arrow-1.2.2-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->neptune-client) (3.0.8)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (1.21.6)\n",
            "Building wheels for collected packages: neptune-client, future\n",
            "  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neptune-client: filename=neptune_client-0.16.1-py2.py3-none-any.whl size=565960 sha256=216c7e124bd027ad0808543685d574032ce8e63d73a18f9b11b7dbd26b72971b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/1a/02/10440cbdf7d5e3a3a13aab8ed77dfb54504c89b5d22a09bb51\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=8a91b11a363dc953235ab2cc20a4915e22f9f41df6ece072da00d350c829c62c\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built neptune-client future\n",
            "Installing collected packages: arrow, webcolors, urllib3, uri-template, rfc3987, rfc3339-validator, jsonpointer, jmespath, isoduration, fqdn, swagger-spec-validator, smmap, simplejson, jsonref, botocore, s3transfer, monotonic, gitdb, bravado-core, websocket-client, PyJWT, GitPython, future, bravado, boto3, neptune-client\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.27 PyJWT-2.3.0 arrow-1.2.2 boto3-1.22.0 botocore-1.25.0 bravado-11.0.3 bravado-core-5.17.0 fqdn-1.5.1 future-0.18.2 gitdb-4.0.9 isoduration-20.11.0 jmespath-1.0.0 jsonpointer-2.3 jsonref-0.2 monotonic-1.6 neptune-client-0.16.1 rfc3339-validator-0.1.4 rfc3987-1.3.8 s3transfer-0.5.2 simplejson-3.17.6 smmap-5.0.0 swagger-spec-validator-2.7.4 uri-template-1.2.0 urllib3-1.25.11 webcolors-1.11.1 websocket-client-1.3.2\n",
            "Collecting deep-phonemizer\n",
            "  Downloading deep-phonemizer-0.0.17.tar.gz (24 kB)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from deep-phonemizer) (1.11.0+cu113)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from deep-phonemizer) (4.64.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from deep-phonemizer) (6.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from deep-phonemizer) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2.0->deep-phonemizer) (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->deep-phonemizer) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->deep-phonemizer) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->deep-phonemizer) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->deep-phonemizer) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->deep-phonemizer) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->deep-phonemizer) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->deep-phonemizer) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->deep-phonemizer) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->deep-phonemizer) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->deep-phonemizer) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->deep-phonemizer) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->deep-phonemizer) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->deep-phonemizer) (1.44.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard->deep-phonemizer) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->deep-phonemizer) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->deep-phonemizer) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->deep-phonemizer) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->deep-phonemizer) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->deep-phonemizer) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->deep-phonemizer) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->deep-phonemizer) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->deep-phonemizer) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->deep-phonemizer) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->deep-phonemizer) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->deep-phonemizer) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->deep-phonemizer) (3.2.0)\n",
            "Building wheels for collected packages: deep-phonemizer\n",
            "  Building wheel for deep-phonemizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deep-phonemizer: filename=deep_phonemizer-0.0.17-py3-none-any.whl size=29727 sha256=67f8ff55d82870dc85d363c13e51818168f99cf6b84291cac96e19e3eb2a17b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/09/57/64a017d46381d74a6b84869bbf763e3fe8579cc248ac65c651\n",
            "Successfully built deep-phonemizer\n",
            "Installing collected packages: deep-phonemizer\n",
            "Successfully installed deep-phonemizer-0.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading deep phonemizer's model as dependency"
      ],
      "metadata": {
        "id": "hVXw6Ty4irBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! curl https://public-asai-dl-models.s3.eu-central-1.amazonaws.com/DeepPhonemizer/en_us_cmudict_ipa_forward.pt --output en_us_cmudict_ipa_forward.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBmoF0HbiLtJ",
        "outputId": "dbb48d61-4252-4674-9eb0-6aa119babe0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 62.5M  100 62.5M    0     0  9513k      0  0:00:06  0:00:06 --:--:-- 14.3M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Codebase"
      ],
      "metadata": {
        "id": "On5zrz-zTX8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from transformers import (GPT2Tokenizer, \n",
        "                          GPT2LMHeadModel, \n",
        "                          GPT2Config, \n",
        "                          AdamW, \n",
        "                          get_linear_schedule_with_warmup)\n",
        "\n",
        "from torch.utils.data import (Dataset, \n",
        "                              random_split,\n",
        "                              DataLoader,\n",
        "                              RandomSampler,\n",
        "                              SequentialSampler)\n",
        "\n",
        "from einops import rearrange\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import pdb\n",
        "\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "\n",
        "import nltk\n",
        "from functools import lru_cache\n",
        "import itertools\n",
        "from itertools import product as iterprod\n",
        "\n",
        "import neptune.new as neptune"
      ],
      "metadata": {
        "id": "apeJTbZxGbDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    \"path_to_data_folder\": '/content/Project/data/'\n",
        "}"
      ],
      "metadata": {
        "id": "C-If8LHa7CLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poem_stanza_df = pd.read_csv(os.path.join(args['path_to_data_folder'], 'limericks_clean_with_@and#.csv'), index_col=0)\n",
        "poem_stanza_df = poem_stanza_df.fillna('')"
      ],
      "metadata": {
        "id": "omSiWHwNGldV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poem_stanza_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "zfgUZAOJJYb9",
        "outputId": "0f9eefb5-008b-458e-fa5d-85c2c4e2f5f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            limerick\n",
              "0  capn jack was washed over the side@\\nhis crew ...\n",
              "1  as a soup bisque is best when served hot@\\nmad...\n",
              "2  simply add to the grasp of a rhesus@\\nthe anti...\n",
              "3  abeds where you sleep in the night@\\nunless yo...\n",
              "4  a smiling young fellow from spain@\\nfell aslee...\n",
              "5  the man who becomes alcoholic@\\nis not on a pe...\n",
              "6  its in castles that monarchs reside@\\nthick st...\n",
              "7  configuration is called absolute@\\nwhen a mole...\n",
              "8  according to my recollection@\\nthe buoy was me...\n",
              "9  can you cure my addiction please doc@\\ni drink..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e31943b6-14d6-4071-b4b8-3b9921707913\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>limerick</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>capn jack was washed over the side@\\nhis crew ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>as a soup bisque is best when served hot@\\nmad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>simply add to the grasp of a rhesus@\\nthe anti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abeds where you sleep in the night@\\nunless yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a smiling young fellow from spain@\\nfell aslee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>the man who becomes alcoholic@\\nis not on a pe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>its in castles that monarchs reside@\\nthick st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>configuration is called absolute@\\nwhen a mole...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>according to my recollection@\\nthe buoy was me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>can you cure my addiction please doc@\\ni drink...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e31943b6-14d6-4071-b4b8-3b9921707913')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e31943b6-14d6-4071-b4b8-3b9921707913 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e31943b6-14d6-4071-b4b8-3b9921707913');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 73\n",
        "BATCH_SIZE = 1\n",
        "MAX_LEN = 64"
      ],
      "metadata": {
        "id": "_S6Onj3bJcpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code for loading the dataset, creating dataloader, running GPT-2 model, and generating samples is referenced from Generating an Edgar Allan Poe-Styled Poem Using GPT-2 https://scottmduda.medium.com/generating-an-edgar-allen-poe-styled-poem-using-gpt-2-289801ded82c"
      ],
      "metadata": {
        "id": "9kB8gQPTg7rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
        "tokenizer.model_max_length = MAX_LEN\n",
        "tokenizer.add_tokens('\\n')\n",
        "\n",
        "special_tokens_dict = {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'pad_token': '<PAD>'}\n",
        "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
      ],
      "metadata": {
        "id": "29JUfyFnJf-0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112,
          "referenced_widgets": [
            "0725dceb54374e5c91f65cb1cea7f2b8",
            "5523a41956824d50aa7bd180e468ef2c",
            "a200f6b275f24f6689ea06f11d5604b0",
            "8df96d6ca9564b71958ed6d8c5446f41",
            "e0c3e3f6634547559118b584ce006607",
            "0cf9f00c22b348d297368c5b0b0323ab",
            "c6bfb175abdf41328fac71538db6b2a8",
            "5f1ef3d0eb79436f827a60b221d5e700",
            "c012fe8671244921ae1f28365d835695",
            "096823c6ee304345a572ee62dd1d546f",
            "9f7301098c2d4e7a9577b7d9a4b7f85c",
            "866e8e096d26426ca2da1069bb1332fd",
            "9460c1e427e3456c9a03c1aa4659d13e",
            "751c5b2954ce4d8d9e2039395fcf8253",
            "7256f1d04ba7471eb1fc910799efe332",
            "d186fcb5a90c4a37aeecb1099518631e",
            "db920494faaf4cc9be41394ccade0652",
            "9cdf5703bc934b1c87856c15f1202a79",
            "6ea514dd76e24034808d2003dcd28a3e",
            "62c0dc854776475395151c5ef59caf68",
            "ae164cc504ae4753a650c0f458a5add6",
            "1ed99a3d148147c99079ac237d4a5f20",
            "f5a31fa6871d446e8c5c4e7413954ece",
            "a1957b6d8c1f4829b592b04ad41f62c8",
            "37c1b4ea4aca42ef9fa4fabcc2daa5e2",
            "036e1ba7a086452daa83bf1e56720197",
            "ab34dd3a24d64387b8b6ee033ba97f66",
            "aa2839985d6e4b0f9e1e568f66ae682e",
            "254d8903b3e74fbdae9e7a857263f781",
            "074cc82b4c134df980e62957921a31da",
            "c9ef5ab4a36f4831a93b6e7629889b27",
            "bcc57e1f80af4ba89825d66adffa5737",
            "1ba2991e26cb4d7488e6c67226777250"
          ]
        },
        "outputId": "f67b93db-5285-4c55-fa9d-f0c9545142e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0725dceb54374e5c91f65cb1cea7f2b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "866e8e096d26426ca2da1069bb1332fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/718 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5a31fa6871d446e8c5c4e7413954ece"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_poem = []\n",
        "for poem in poem_stanza_df['limerick']:\n",
        "  len_poem.append(len([char for char in poem]))\n",
        "len_poem.sort(reverse=True)"
      ],
      "metadata": {
        "id": "mYstBOOZJsyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poem_stanza_df_size_limit = poem_stanza_df[poem_stanza_df['limerick'].apply(lambda x: True if len(x) < 256 else False)]"
      ],
      "metadata": {
        "id": "GvlfcWUBJv-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poem_stanza_df_size_limit.reset_index(inplace=True)\n",
        "poem_stanza_df_size_limit = poem_stanza_df_size_limit[['limerick']]"
      ],
      "metadata": {
        "id": "tjjQWlg9J2H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poem_stanza_df_size_limit.tail(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "CJmgAQnSJ442",
        "outputId": "79accb5c-56e2-4fb3-a132-57129640a8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                limerick\n",
              "82897  almug the very same thing@\\nas algum two words...\n",
              "82898  cutis vera its part of the skin@\\nthat covers ...\n",
              "82899  a prisoner locked in a cell@\\nfor a pet has a ...\n",
              "82900  in biblical studies id dabble@\\nand thats wher...\n",
              "82901  darwins theory some doctrine still mocks@\\nman...\n",
              "82902  the storys in front of our noses@\\nin the bulr...\n",
              "82903  understanding the bible is hard@\\ntake the cas...\n",
              "82904  diverticula making you sick you@\\nmay need a r...\n",
              "82905  un ballo in maschera what@\\nis the opera about...\n",
              "82906  i said joe daddy thinks that youre drony@\\nand..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9698718-0199-4ef4-b6e1-b80860ba79e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>limerick</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82897</th>\n",
              "      <td>almug the very same thing@\\nas algum two words...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82898</th>\n",
              "      <td>cutis vera its part of the skin@\\nthat covers ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82899</th>\n",
              "      <td>a prisoner locked in a cell@\\nfor a pet has a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82900</th>\n",
              "      <td>in biblical studies id dabble@\\nand thats wher...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82901</th>\n",
              "      <td>darwins theory some doctrine still mocks@\\nman...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82902</th>\n",
              "      <td>the storys in front of our noses@\\nin the bulr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82903</th>\n",
              "      <td>understanding the bible is hard@\\ntake the cas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82904</th>\n",
              "      <td>diverticula making you sick you@\\nmay need a r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82905</th>\n",
              "      <td>un ballo in maschera what@\\nis the opera about...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82906</th>\n",
              "      <td>i said joe daddy thinks that youre drony@\\nand...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9698718-0199-4ef4-b6e1-b80860ba79e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9698718-0199-4ef4-b6e1-b80860ba79e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9698718-0199-4ef4-b6e1-b80860ba79e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.model_max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhX0PtAVJ7yG",
        "outputId": "3a94ee94-ba93-479c-e6a9-b8be16ed4e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = tokenizer.vocab_size\n",
        "vocab_size += 4\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzEzMWbhKABO",
        "outputId": "074fee62-1587-4392-bc29-5be20c24e138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PoemDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data, tokenizer, gpt2_type='gpt2', max_length=MAX_LEN):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        \n",
        "        for i in data:\n",
        "            encodings_dict = tokenizer('<BOS>' + i + '<EOS>',\n",
        "                                     truncation=False,\n",
        "                                     max_length=max_length,\n",
        "                                     padding='max_length'\n",
        "                                    )\n",
        "\n",
        "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.input_ids)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        return self.input_ids[idx], self.attn_masks[idx]"
      ],
      "metadata": {
        "id": "853Ff_rIMLdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poem_stanza_dataset = PoemDataset(poem_stanza_df_size_limit['limerick'].values, tokenizer, max_length=MAX_LEN)"
      ],
      "metadata": {
        "id": "0rJL2V9xMa0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_split(split, dataset):\n",
        "    train_size = int(split * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    return train_size, val_size"
      ],
      "metadata": {
        "id": "fxPDl4kCMpOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poem_stanza_train_size, poem_stanza_val_size = train_val_split(1, poem_stanza_dataset)\n",
        "\n",
        "# random split imported from troch.utils\n",
        "poem_stanza_train_dataset, poem_stanza_val_dataset = random_split(poem_stanza_dataset, [poem_stanza_train_size, poem_stanza_val_size])"
      ],
      "metadata": {
        "id": "RxdulJmKQC20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8QVjglYQGhK",
        "outputId": "ea34d45e-791d-44db-8b47-a5161f9b94f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f50a4842f50>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poem_stanza_train_dataloader = DataLoader(poem_stanza_train_dataset,\n",
        "                              sampler=RandomSampler(poem_stanza_train_dataset),\n",
        "                              batch_size=BATCH_SIZE)\n",
        "\n",
        "poem_stanza_val_dataloader = DataLoader(poem_stanza_val_dataset,\n",
        "                            sampler=SequentialSampler(poem_stanza_val_dataset),\n",
        "                            batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "thMfqtbdQIby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function for logging time\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "\n",
        "# create text generation seed prompt\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "prompt = \"<BOS>\"\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)"
      ],
      "metadata": {
        "id": "tEgt5J1zQKs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code, which calculates context loss using self-attention LSTM is referenced from SP-GPT2: Semantics Improvement in Vietnamese\n",
        "Poetry Generation https://github.com/fsoft-ailab/Poem-Generator (https://arxiv.org/pdf/2110.15723v1.pdf)"
      ],
      "metadata": {
        "id": "7x0hEkJ1hvJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ScaleDotProductAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ScaleDotProductAttention, self).__init__()\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None, e=1e-12):\n",
        "        batch_size, head, length, d_tensor = k.size()\n",
        "\n",
        "        score = torch.einsum(\"bhid,bhjd->bhij\",q,k)\n",
        "        score = score/math.sqrt(d_tensor)\n",
        "\n",
        "        if mask is not None:\n",
        "            score = score.masked_fill(mask == 0, -e)\n",
        "\n",
        "        score = self.softmax(score)\n",
        "\n",
        "        v = score @ v\n",
        "\n",
        "        return v, score\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, n_head):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.n_head = n_head\n",
        "        self.attention = ScaleDotProductAttention()\n",
        "        self.w_q = nn.Linear(d_model, d_model*n_head)\n",
        "        self.w_k = nn.Linear(d_model, d_model*n_head)\n",
        "        self.w_v = nn.Linear(d_model, d_model*n_head)\n",
        "        self.w_concat = nn.Linear(d_model*n_head, d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        q, k, v = self.w_q(x), self.w_k(x), self.w_v(x)\n",
        "\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.n_head), (q, k, v))\n",
        "\n",
        "        out, attention = self.attention(q, k, v, mask=mask)\n",
        "\n",
        "        # 4. concat and pass to linear layer\n",
        "        # out = self.concat(out)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out = self.w_concat(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class SelfAttentionLstm(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers,n_head):\n",
        "        super(SelfAttentionLstm, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.multi_attention = MultiHeadAttention(d_model=input_size,n_head=4)\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.multi_attention(x)\n",
        "         \n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "        out = out[: ,-1, : ]\n",
        "        return out"
      ],
      "metadata": {
        "id": "wyRaqq1ihLLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head_gpt = SelfAttentionLstm(input_size=1024,hidden_size=800, num_layers=2,n_head=4).to(device)"
      ],
      "metadata": {
        "id": "vSz_PsR1hMJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_idx_five_line(lm_logits):\n",
        "\n",
        "    token = torch.argmax(lm_logits, dim= 2)\n",
        "    token = token[0].tolist()\n",
        "    index_token = [0]\n",
        "\n",
        "    for i in range(1, len(token)):\n",
        "        if (token[i] == 50259): #<EOS> token\n",
        "          index_token.append(i)\n",
        "          break\n",
        "        elif ((token[i] == 50257 and token[i - 1] != 50257) or \n",
        "              (token[i] != 50257 and token[i - 1] == 50257)): #\\n token\n",
        "          index_token.append(i)\n",
        "\n",
        "    token_final = []\n",
        "    if (len(index_token) != 10):\n",
        "        # print(len(index_token))\n",
        "        pass\n",
        "    else:\n",
        "        for i in range(0, 10, 2):\n",
        "            token_final.append([index_token[i], index_token[i + 1]])\n",
        "    \n",
        "    return token_final"
      ],
      "metadata": {
        "id": "qwNwIBpgXDrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def limerick_context_loss(lm_logits, embedding, default_loss):\n",
        "    lm_logits = torch.unsqueeze(lm_logits,0)\n",
        "    pair_list = get_idx_five_line(lm_logits)\n",
        "    embedding = torch.unsqueeze(embedding,0)\n",
        "    \n",
        "    total_lost = 0\n",
        "    if len(pair_list) != 5:\n",
        "      return -1\n",
        "    loss = nn.MSELoss().to(device)\n",
        "    \n",
        "    # array where,[0] is start index and [1] is end index of line\n",
        "    one = pair_list[0] \n",
        "    two = pair_list[1]\n",
        "    three = pair_list[2]\n",
        "    four = pair_list[3]\n",
        "    five = pair_list[4]\n",
        "\n",
        "\n",
        "    # embedding[batch_size, token sequence, embedding]\n",
        "    embed_one = head_gpt(embedding[:, one[0]: one[1], :])\n",
        "    embed_two = head_gpt(embedding[:, two[0]: two[1], :])\n",
        "    embed_three = head_gpt(embedding[:, three[0]: three[1], :])\n",
        "    embed_four = head_gpt(embedding[:, four[0]: four[1], :])\n",
        "    embed_five = head_gpt(embedding[:, five[0]: five[1], :])\n",
        "\n",
        "    total_lost = loss(embed_one,embed_five) + loss(embed_two,embed_five) + loss(embed_three,embed_five) + loss(embed_four,embed_five)\n",
        "\n",
        "    return total_lost   "
      ],
      "metadata": {
        "id": "tvmj8F72XA5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rhyming loss calculation"
      ],
      "metadata": {
        "id": "5W_WxxL3NwTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dp.phonemizer import Phonemizer\n",
        "\n",
        "phonemizer = Phonemizer.from_checkpoint('/content/en_us_cmudict_ipa_forward.pt')\n",
        "phonemizer('Phonemizing an English text is imposimpable!', lang='en_us')\n",
        "\n",
        "vowels = ['a', 'e', 'i', 'o', 'u']\n",
        "    \n",
        "#made changes to avoid two letter words ending with None\n",
        "def break_word(word):\n",
        "  for i, c in enumerate(word[::-1]):\n",
        "    if c in vowels and c!= word[-1]:\n",
        "      return word[len(word)-i-1:]\n",
        "    if i == len(word)-1:\n",
        "      return word\n",
        "\n",
        "def rhyming_pair_loss(word_1, word_2):\n",
        "    rhyme_pair_ldistance = levenshtein_distance(\n",
        "        phonemizer(break_word(word_1), lang='en_us'), \n",
        "        phonemizer(break_word(word_2), lang='en_us')\n",
        "    )\n",
        "    rhyme_loss = 2*((1/(1+np.exp(-rhyme_pair_ldistance)))-0.5)\n",
        "    return rhyme_loss\n",
        "\n",
        "#added eps to avoid divide by zero error\n",
        "def non_rhyming_pair_loss(word_1, word_2, eps = 1e-9):\n",
        "\n",
        "    rhyme_pair_ldistance = levenshtein_distance(\n",
        "        phonemizer(break_word(word_1), lang='en_us'), \n",
        "        phonemizer(break_word(word_2), lang='en_us')\n",
        "    )\n",
        "    non_rhyme_loss = 2*((1/(1+np.exp(-(1/(rhyme_pair_ldistance+eps)))))-0.5)\n",
        "    return non_rhyme_loss\n",
        "\n",
        "def get_line_last_token_id(lm_logits):\n",
        "\n",
        "    token = torch.argmax(lm_logits, dim= 2)\n",
        "    token = token[0].tolist()\n",
        "    last_word_token_ids = []\n",
        "\n",
        "    for i in range(1, len(token)):\n",
        "        if (token[i] == 50259): #<EOS> token\n",
        "          last_word_token_ids.append(token[i - 1])\n",
        "          break\n",
        "        elif (token[i] == 50257 and token[i - 1] != 50257): #\\n token\n",
        "          last_word_token_ids.append(token[i - 1])\n",
        "\n",
        "    return last_word_token_ids\n",
        "\n",
        "\"\"\"\n",
        "Converted each pair's distance into an array and comparing now with a tensor of zeros\n",
        "in MSE Loss. \n",
        "\"\"\"\n",
        "def limerick_rhyme_loss(lm_logits, embedding, default_loss):\n",
        "    lm_logits = torch.unsqueeze(lm_logits,0)\n",
        "    line_last_token_id = get_line_last_token_id(lm_logits)\n",
        "\n",
        "    loss = nn.MSELoss().to(device)\n",
        "\n",
        "    # pdb.set_trace()\n",
        "    # in case lines generated are not 5\n",
        "    if len(line_last_token_id) != 5:\n",
        "        return -1\n",
        "\n",
        "    one = tokenizer.convert_ids_to_tokens(line_last_token_id[0])\n",
        "    two = tokenizer.convert_ids_to_tokens(line_last_token_id[1])\n",
        "    three = tokenizer.convert_ids_to_tokens(line_last_token_id[2])\n",
        "    four = tokenizer.convert_ids_to_tokens(line_last_token_id[3])\n",
        "    five = tokenizer.convert_ids_to_tokens(line_last_token_id[4])\n",
        "\n",
        "    # Rhymes\n",
        "    rhyming_pair_losses = np.array((rhyming_pair_loss(one, two),\n",
        "                                    rhyming_pair_loss(one, five),\n",
        "                                    rhyming_pair_loss(two, five),\n",
        "                                    rhyming_pair_loss(three, four)))\n",
        "    \n",
        "    rhyming_pair_losses = torch.as_tensor(rhyming_pair_losses)\n",
        "    rhyming_pair_target = np.zeros(4)\n",
        "    rhyming_pair_target = torch.as_tensor(rhyming_pair_target)\n",
        "\n",
        "    rhyme_loss = loss(rhyming_pair_losses, rhyming_pair_target)\n",
        "\n",
        "    # Non-Rhyme\n",
        "    non_rhyming_pair_losses = np.array((non_rhyming_pair_loss(one, three),\n",
        "                                        non_rhyming_pair_loss(two, three),\n",
        "                                        non_rhyming_pair_loss(one, four),\n",
        "                                        non_rhyming_pair_loss(two, four),\n",
        "                                        non_rhyming_pair_loss(three, five),\n",
        "                                        non_rhyming_pair_loss(four, five)))\n",
        "    \n",
        "    non_rhyming_pair_losses = torch.as_tensor(non_rhyming_pair_losses)\n",
        "    non_rhyming_pair_target = np.zeros(6)\n",
        "    non_rhyming_pair_target = torch.as_tensor(non_rhyming_pair_target)\n",
        "\n",
        "    non_rhyme_loss = loss(non_rhyming_pair_losses, non_rhyming_pair_target)\n",
        "\n",
        "    total_loss = rhyme_loss + non_rhyme_loss\n",
        "\n",
        "    return total_loss  "
      ],
      "metadata": {
        "id": "FPcEdpY8hFsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf9b91f7-75de-4cbc-bb19-a877f04ceb31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-26 04:40:46,976.976 DEBUG phonemizer:  Initializing phonemizer with model step 710000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom loss aggregation"
      ],
      "metadata": {
        "id": "kk9zdUJNNzqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_custom_loss(logits, embeddings, loss):\n",
        "\n",
        "    context_loss = 0\n",
        "    for i in range(logits.shape[0]):\n",
        "        context_loss += limerick_context_loss(logits[i], embeddings[i], loss)\n",
        "        if context_loss < 0:\n",
        "            break\n",
        "            \n",
        "    rhyme_loss = 0\n",
        "    for i in range(logits.shape[0]):\n",
        "      rhyme_loss += limerick_rhyme_loss(logits[i], embeddings[i], loss)\n",
        "    \n",
        "    total_loss = loss\n",
        "    \n",
        "    if rhyme_loss != -1:\n",
        "        total_loss += rhyme_loss\n",
        "    if context_loss >= 0:\n",
        "        total_loss += context_loss\n",
        "    else:\n",
        "        total_loss *= 2\n",
        "\n",
        "    # pdb.set_trace()\n",
        "\n",
        "    print(f'Total Loss: {total_loss} | Context Loss: {context_loss} | Rhyme Loss: {rhyme_loss} ')\n",
        "\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "iKS41yQJN1uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training artefacts defination"
      ],
      "metadata": {
        "id": "WjfZ-r1ZZI0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_storage_path = '/content/Project/trainings/'\n",
        "iteration_step_to_log_generation = 250 \n",
        "iteration_step_to_log_checkpoint = 10000\n",
        "total_iterations = 80000\n",
        "\n",
        "# hyperparameters\n",
        "learning_rate = 1e-4\n",
        "eps = 1e-8\n",
        "warmup_steps = 10000"
      ],
      "metadata": {
        "id": "xe51ldz5YTSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT Configuration\n",
        "configuration = GPT2Config(\n",
        "        vocab_size=len(tokenizer), \n",
        "        n_positions=MAX_LEN\n",
        "    ).from_pretrained('gpt2-medium', output_hidden_states=True)\n",
        "\n",
        "# Model Definition\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2-medium', config=configuration)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=eps)\n",
        "total_steps = len(poem_stanza_train_dataloader) * 1\n",
        "\n",
        "# Scheduler\n",
        "lr_scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=warmup_steps,\n",
        "                                            num_training_steps=100000)\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "M_ThvSGnZLsi",
        "outputId": "2cb0b19f-c00b-407f-d316-f7856dbb3a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "491636a480ac47caa9e1b7999af85b78",
            "f8796083ffd845d0b51e4be4af727e7a",
            "2c1836d231fb4213bbcc179ed2177150",
            "25d51541cbc24e4e8532b69f5903f036",
            "5ebae7af124b4597ac4f5318803fabba",
            "9e6a2a52d03847c0b5e62883fafa719f",
            "8aee547c1eb14419ba930b4fa1ed420e",
            "5a7bed495c9b4414b9ffba5b7c8f7f94",
            "fb89912573104beaad393454fd199014",
            "a2085bf2367e442d807a18829b845918",
            "4f6be236287241d0b92ba6e4cdc06841"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "491636a480ac47caa9e1b7999af85b78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "def validate(iteration, model, optimizer, lr_scheduler):\n",
        "\n",
        "    if iteration%iteration_step_to_log_generation==0 or iteration==total_iterations:\n",
        "        sample_outputs = model.generate(generated, \n",
        "                                        do_sample=True,   \n",
        "                                        top_k=50, \n",
        "                                        max_length=MAX_LEN,\n",
        "                                        top_p=0.95, \n",
        "                                        num_return_sequences=5)\n",
        "        \n",
        "        log_generation(sample_outputs, iteration)"
      ],
      "metadata": {
        "id": "CTKJLFAqXJPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logging"
      ],
      "metadata": {
        "id": "wopRaC-PYEHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Logging setup\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "def log_checkpoint(iteration, model, optimizer, lr_scheduler, metric=None):\n",
        "    if iteration%iteration_step_to_log_checkpoint==0 or iteration==total_iterations:\n",
        "        state = {\n",
        "            'iteration': iteration + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(), \n",
        "            'lr_scheduler_state_dict': lr_scheduler.state_dict()\n",
        "        }\n",
        "\n",
        "        check_point_dir = training_storage_path\n",
        "\n",
        "        if not os.path.exists(check_point_dir):\n",
        "            os.makedirs(check_point_dir)\n",
        "\n",
        "        if metric == None:\n",
        "            checkpoint_file_path = check_point_dir + f\"/poet_ai_checkpoint.h5\"\n",
        "            torch.save(state, checkpoint_file_path)\n",
        "        else:\n",
        "            # considering minimization effort\n",
        "            onlyfile_metrics = [float(f.split(\"_checkpoint.h5\")[0]) for f in listdir(check_point_dir) if isfile(join(check_point_dir, f)) and \"_checkpoint.h5\" in f]\n",
        "\n",
        "            if len(onlyfile_metrics) > 0 and metric < sorted(onlyfile_metrics)[0]:\n",
        "                checkpoint_file_path = check_point_dir + f\"/{metric}_checkpoint.h5\"\n",
        "                torch.save(state, checkpoint_file_path)\n",
        "                os.remove(check_point_dir + f\"/{sorted(onlyfile_metrics)[0]}_checkpoint.h5\")\n",
        "        "
      ],
      "metadata": {
        "id": "pcTR87sqYI9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_generation(sample_outputs, iter_no):\n",
        "    # create path\n",
        "    \n",
        "    check_point_dir = training_storage_path\n",
        "\n",
        "    if not os.path.exists(check_point_dir):\n",
        "            os.makedirs(check_point_dir)\n",
        "\n",
        "    with open(os.path.join(check_point_dir, 'generation_log.txt'), 'a') as log_file:\n",
        "        log_file.write(f\"-- Iteration {iter_no} -- \\n\\n\")\n",
        "        print(f\"\\n\\n -- Iteration {iter_no} --\")\n",
        "        for i, sample_output in enumerate(sample_outputs):\n",
        "            log_limerick = \"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True))\n",
        "            log_file.write(log_limerick)\n",
        "            print(log_limerick)\n"
      ],
      "metadata": {
        "id": "8uSOu35EK0HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Model"
      ],
      "metadata": {
        "id": "Q2gworrugGe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint_file_path = \"\""
      ],
      "metadata": {
        "id": "4qmM4M1PgMnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # loading models back from repos:\n",
        "# # assumes model, optimizer and lr_scheduler are already defined.\n",
        "# def load_logged_model(model, optimizer, lr_scheduler):\n",
        "\n",
        "#     new_start_iteration = 0\n",
        "#     if os.path.isfile(checkpoint_file_path):\n",
        "#         print(\"=> loading checkpoint '{}'\".format(checkpoint_file_path))\n",
        "#         checkpoint = torch.load(checkpoint_file_path)\n",
        "#         new_start_iteration = checkpoint['iteration']\n",
        "#         model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#         optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#         lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
        "#         print(\"=> loaded checkpoint '{}' (new iteration {})\"\n",
        "#                   .format(checkpoint_file_path, checkpoint['iteration']))\n",
        "#     else:\n",
        "#         print(\"=> no checkpoint found at '{}'\".format(checkpoint_file_path))\n",
        "\n",
        "#     return model, optimizer, new_start_iteration, lr_scheduler\n",
        "\n",
        "# model, optimizer, train_iterations, lr_scheduler = load_logged_model(model, optimizer, lr_scheduler)\n",
        "\n",
        "# # assumes everything is on cuda; else use model.to(device)\n",
        "# model = model.cuda()\n",
        "# # now individually transfer the optimizer parts...\n",
        "# for state in optimizer.state.values():\n",
        "#     for k, v in state.items():\n",
        "#         if isinstance(v, torch.Tensor):\n",
        "#             state[k] = v.cuda()"
      ],
      "metadata": {
        "id": "F1gqk8qxgJIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d7775d2-6e1d-40d9-bb9c-d36f40f8c674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> loading checkpoint '/content/Project/trainings/POET-12/poet_ai_checkpoint.h5'\n",
            "=> loaded checkpoint '/content/Project/trainings/POET-12/poet_ai_checkpoint.h5' (new iteration 1251)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "BMAnKIjNeCHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterations = 1"
      ],
      "metadata": {
        "id": "f12Bzs1YeBoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = None\n",
        "\n",
        "while (train_iterations < total_iterations):\n",
        "\n",
        "    print(f'Iteration {train_iterations} of {total_iterations}')\n",
        "\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(poem_stanza_train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                                    labels=b_labels,\n",
        "                                    attention_mask=b_masks,\n",
        "                                    token_type_ids=None)\n",
        "        embeddings = model.transformer(b_input_ids,\n",
        "                                    attention_mask=b_masks,\n",
        "                                    token_type_ids=None)[0]\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss = get_custom_loss(outputs.logits, embeddings, loss)\n",
        "    \n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        print(f'Iteration number: {train_iterations}')\n",
        "        \n",
        "        validate(iteration=train_iterations, model=model, optimizer=optimizer, lr_scheduler=lr_scheduler)\n",
        "\n",
        "        log_checkpoint(train_iterations, model, optimizer, lr_scheduler)\n",
        "        \n",
        "        train_iterations += 1\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omoa9eHbQNH6",
        "outputId": "11e85037-8a98-4ea2-bcf6-c5e13c013d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Total Loss: 3.0213677883148193 | Context Loss: 0.0006736295763403177 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80579\n",
            "Total Loss: 2.5904297828674316 | Context Loss: 0.0005638297880068421 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80580\n",
            "Total Loss: 2.2920279502868652 | Context Loss: 0.0006786675658077002 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80581\n",
            "Total Loss: 2.3744921684265137 | Context Loss: 0.0008914298377931118 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80582\n",
            "Total Loss: 2.6634607315063477 | Context Loss: 0.0006932662799954414 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80583\n",
            "Total Loss: 2.0970983505249023 | Context Loss: 0.0007316371193155646 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80584\n",
            "Total Loss: 2.4497735500335693 | Context Loss: 0.0008394810138270259 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80585\n",
            "Total Loss: 3.2959063053131104 | Context Loss: 0.0006519206799566746 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80586\n",
            "Total Loss: 2.378627300262451 | Context Loss: 0.0006826374446973205 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 80587\n",
            "Total Loss: 2.5234336853027344 | Context Loss: 0.0004246393218636513 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80588\n",
            "Total Loss: 3.0579171180725098 | Context Loss: 0.0005722222849726677 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80589\n",
            "Total Loss: 2.4957973957061768 | Context Loss: 0.0009671621955931187 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80590\n",
            "Total Loss: 1.768614649772644 | Context Loss: 0.0011314492439851165 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80591\n",
            "Total Loss: 2.251323938369751 | Context Loss: 0.0006320474785752594 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80592\n",
            "Total Loss: 2.476325273513794 | Context Loss: 0.0006078428705222905 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80593\n",
            "Total Loss: 2.5451061725616455 | Context Loss: 0.0008065384463407099 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80594\n",
            "Total Loss: 3.2554781436920166 | Context Loss: 0.0007597751100547612 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 80595\n",
            "Total Loss: 3.0868284702301025 | Context Loss: 0.0007723851595073938 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80596\n",
            "Total Loss: 2.6554431915283203 | Context Loss: 0.0007199711981229484 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80597\n",
            "Total Loss: 2.614645004272461 | Context Loss: 0.0005596334231086075 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80598\n",
            "Total Loss: 3.731325149536133 | Context Loss: 0.0005032015615142882 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80599\n",
            "Total Loss: 2.103889226913452 | Context Loss: 0.0006474454421550035 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80600\n",
            "Total Loss: 2.695545196533203 | Context Loss: 0.0007426270749419928 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80601\n",
            "Total Loss: 2.2559924125671387 | Context Loss: 0.0007113692117854953 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80602\n",
            "Total Loss: 3.520266532897949 | Context Loss: 0.000542387249879539 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80603\n",
            "Total Loss: 2.3253939151763916 | Context Loss: 0.0005407093558460474 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80604\n",
            "Total Loss: 3.034092664718628 | Context Loss: 0.000501600094139576 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80605\n",
            "Total Loss: 2.092170476913452 | Context Loss: 0.0009669044520705938 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80606\n",
            "Total Loss: 2.892470359802246 | Context Loss: 0.00042717487667687237 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80607\n",
            "Total Loss: 2.501063823699951 | Context Loss: 0.0007461320492438972 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80608\n",
            "Total Loss: 2.9593329429626465 | Context Loss: 0.00042792997555807233 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80609\n",
            "Total Loss: 2.5948150157928467 | Context Loss: 0.0005918636452406645 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80610\n",
            "Total Loss: 3.0286171436309814 | Context Loss: 0.0007073963060975075 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80611\n",
            "Total Loss: 2.9695589542388916 | Context Loss: 0.0008916096994653344 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80612\n",
            "Total Loss: 2.373582124710083 | Context Loss: 0.00069117930252105 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80613\n",
            "Total Loss: 3.397902727127075 | Context Loss: 0.001003806828521192 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80614\n",
            "Total Loss: 3.7109925746917725 | Context Loss: 0.0006176736205816269 | Rhyme Loss: 0.4646745875734178 \n",
            "Iteration number: 80615\n",
            "Total Loss: 3.6204922199249268 | Context Loss: 0.0007229443290270865 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80616\n",
            "Total Loss: 2.9361674785614014 | Context Loss: 0.0008322661742568016 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80617\n",
            "Total Loss: 2.647019386291504 | Context Loss: 0.0007183657726272941 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 80618\n",
            "Total Loss: 2.8747763633728027 | Context Loss: 0.0007030625711195171 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80619\n",
            "Total Loss: 2.761467695236206 | Context Loss: 0.0006346098380163312 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80620\n",
            "Total Loss: 3.1726510524749756 | Context Loss: 0.000607081747148186 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80621\n",
            "Total Loss: 2.13681960105896 | Context Loss: 0.0005057122907601297 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80622\n",
            "Total Loss: 2.433164358139038 | Context Loss: 0.0006345236906781793 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80623\n",
            "Total Loss: 2.2945642471313477 | Context Loss: 0.0009792031487450004 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80624\n",
            "Total Loss: 2.4676432609558105 | Context Loss: 0.0005411783931776881 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80625\n",
            "Total Loss: 3.070747137069702 | Context Loss: 0.0008027252624742687 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80626\n",
            "Total Loss: 2.406909465789795 | Context Loss: 0.0008154305396601558 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80627\n",
            "Total Loss: 2.748135566711426 | Context Loss: 0.0007013474241830409 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80628\n",
            "Total Loss: 2.256718397140503 | Context Loss: 0.0006347568123601377 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80629\n",
            "Total Loss: 2.1446774005889893 | Context Loss: 0.0006175457965582609 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80630\n",
            "Total Loss: 2.0623486042022705 | Context Loss: 0.0008179428987205029 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80631\n",
            "Total Loss: 2.784376859664917 | Context Loss: 0.0006395498057827353 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80632\n",
            "Total Loss: 2.772266149520874 | Context Loss: 0.0005518902908079326 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80633\n",
            "Total Loss: 2.821349859237671 | Context Loss: 0.0004171603359282017 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80634\n",
            "Total Loss: 2.8152544498443604 | Context Loss: 0.0005059348768554628 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80635\n",
            "Total Loss: 2.2864983081817627 | Context Loss: 0.000792877224739641 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80636\n",
            "Total Loss: 2.53358793258667 | Context Loss: 0.0007266534375958145 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80637\n",
            "Total Loss: 2.595041036605835 | Context Loss: 0.0005750312120653689 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80638\n",
            "Total Loss: 2.85147762298584 | Context Loss: 0.0004259878187440336 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80639\n",
            "Total Loss: 2.7124221324920654 | Context Loss: 0.0006497816648334265 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80640\n",
            "Total Loss: 3.2192575931549072 | Context Loss: 0.0006908401264809072 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80641\n",
            "Total Loss: 2.738737106323242 | Context Loss: 0.00046057894360274076 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80642\n",
            "Total Loss: 2.0930683612823486 | Context Loss: 0.0007862282800488174 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80643\n",
            "Total Loss: 1.8543816804885864 | Context Loss: 0.0008223001495935023 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80644\n",
            "Total Loss: 3.0343968868255615 | Context Loss: 0.0006102155894041061 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80645\n",
            "Total Loss: 2.1853013038635254 | Context Loss: 0.0004755984409712255 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80646\n",
            "Total Loss: 2.155871868133545 | Context Loss: 0.0006711564492434263 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80647\n",
            "Total Loss: 2.437971353530884 | Context Loss: 0.0008489507017657161 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80648\n",
            "Total Loss: 2.9061734676361084 | Context Loss: 0.0010817295406013727 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80649\n",
            "Total Loss: 2.51920223236084 | Context Loss: 0.0008873571641743183 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80650\n",
            "Total Loss: 2.57889986038208 | Context Loss: 0.0006382162100635469 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80651\n",
            "Total Loss: 3.693176746368408 | Context Loss: 0.000879393657669425 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80652\n",
            "Total Loss: 2.537550926208496 | Context Loss: 0.0005904505378566682 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80653\n",
            "Total Loss: 2.0902726650238037 | Context Loss: 0.0006973976269364357 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80654\n",
            "Total Loss: 2.7444794178009033 | Context Loss: 0.0005988914053887129 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80655\n",
            "Total Loss: 1.863211750984192 | Context Loss: 0.0005527240573428571 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80656\n",
            "Total Loss: 3.098560094833374 | Context Loss: 0.0011015193304046988 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80657\n",
            "Total Loss: 2.1476657390594482 | Context Loss: 0.0007012528367340565 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80658\n",
            "Total Loss: 2.693129301071167 | Context Loss: 0.0007260292768478394 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80659\n",
            "Total Loss: 2.5363218784332275 | Context Loss: 0.0006598195759579539 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80660\n",
            "Total Loss: 2.39106822013855 | Context Loss: 0.0007722112350165844 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80661\n",
            "Total Loss: 2.0561904907226562 | Context Loss: 0.000586839159950614 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80662\n",
            "Total Loss: 2.8900983333587646 | Context Loss: 0.0005996485706418753 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80663\n",
            "Total Loss: 2.273087978363037 | Context Loss: 0.0009109866223298013 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80664\n",
            "Total Loss: 3.309143543243408 | Context Loss: 0.0006453327368944883 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 80665\n",
            "Total Loss: 2.592524528503418 | Context Loss: 0.0007285102037712932 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80666\n",
            "Total Loss: 2.2758100032806396 | Context Loss: 0.0007248088368214667 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80667\n",
            "Total Loss: 1.939536213874817 | Context Loss: 0.0006138377357274294 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80668\n",
            "Total Loss: 2.6311533451080322 | Context Loss: 0.0006096978322602808 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80669\n",
            "Total Loss: 2.560953378677368 | Context Loss: 0.0006537861190736294 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80670\n",
            "Total Loss: 2.828867197036743 | Context Loss: 0.0005355756729841232 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80671\n",
            "Total Loss: 2.6388466358184814 | Context Loss: 0.00042727135587483644 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80672\n",
            "Total Loss: 3.023900032043457 | Context Loss: 0.0005728616961278021 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80673\n",
            "Total Loss: 2.53633189201355 | Context Loss: 0.0009157566819339991 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80674\n",
            "Total Loss: 2.81796932220459 | Context Loss: 0.0006433894159272313 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80675\n",
            "Total Loss: 2.3811564445495605 | Context Loss: 0.0006525479257106781 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80676\n",
            "Total Loss: 3.4740543365478516 | Context Loss: 0.0008512926287949085 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80677\n",
            "Total Loss: 2.003018856048584 | Context Loss: 0.0006898223655298352 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80678\n",
            "Total Loss: 2.323185443878174 | Context Loss: 0.0009714545449241996 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80679\n",
            "Total Loss: 2.5195982456207275 | Context Loss: 0.000587976654060185 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80680\n",
            "Total Loss: 2.736872673034668 | Context Loss: 0.0005507547757588327 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80681\n",
            "Total Loss: 2.20762300491333 | Context Loss: 0.0006878970307298005 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80682\n",
            "Total Loss: 2.5654451847076416 | Context Loss: 0.0007817986188456416 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80683\n",
            "Total Loss: 2.881540298461914 | Context Loss: 0.0006262549431994557 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80684\n",
            "Total Loss: 2.7894742488861084 | Context Loss: 0.0005808004061691463 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80685\n",
            "Total Loss: 3.198591709136963 | Context Loss: 0.0007336468552239239 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80686\n",
            "Total Loss: 2.1827762126922607 | Context Loss: 0.0005416196654550731 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80687\n",
            "Total Loss: 2.975558280944824 | Context Loss: 0.0006458507268689573 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80688\n",
            "Total Loss: 3.016613006591797 | Context Loss: 0.0006901812157593668 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80689\n",
            "Total Loss: 2.11565899848938 | Context Loss: 0.0006658185739070177 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80690\n",
            "Total Loss: 2.444279193878174 | Context Loss: 0.0005426990101113915 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80691\n",
            "Total Loss: 2.606290817260742 | Context Loss: 0.0007601400720886886 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80692\n",
            "Total Loss: 2.5958666801452637 | Context Loss: 0.0007786721689626575 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80693\n",
            "Total Loss: 2.502450704574585 | Context Loss: 0.0006826083990745246 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80694\n",
            "Total Loss: 3.064932346343994 | Context Loss: 0.000552154378965497 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80695\n",
            "Total Loss: 2.347196102142334 | Context Loss: 0.0005271945847198367 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80696\n",
            "Total Loss: 2.63234281539917 | Context Loss: 0.0006690426962450147 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80697\n",
            "Total Loss: 2.3920135498046875 | Context Loss: 0.0006669520516879857 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80698\n",
            "Total Loss: 2.604966163635254 | Context Loss: 0.0004849047982133925 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80699\n",
            "Total Loss: 3.320732593536377 | Context Loss: 0.0006219650967977941 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80700\n",
            "Total Loss: 2.2830915451049805 | Context Loss: 0.0005340722273103893 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80701\n",
            "Total Loss: 3.069667339324951 | Context Loss: 0.0006514417473226786 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80702\n",
            "Total Loss: 2.524176836013794 | Context Loss: 0.0005744787631556392 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80703\n",
            "Total Loss: 2.661206007003784 | Context Loss: 0.0005979552515782416 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80704\n",
            "Total Loss: 2.520571708679199 | Context Loss: 0.00048115014214999974 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80705\n",
            "Total Loss: 2.6614973545074463 | Context Loss: 0.0009085453348234296 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80706\n",
            "Total Loss: 2.7311549186706543 | Context Loss: 0.0005210236995480955 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80707\n",
            "Total Loss: 2.407151222229004 | Context Loss: 0.0006267767166718841 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80708\n",
            "Total Loss: 2.3078222274780273 | Context Loss: 0.0007606432773172855 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80709\n",
            "Total Loss: 2.8324267864227295 | Context Loss: 0.0006378623656928539 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80710\n",
            "Total Loss: 2.5409669876098633 | Context Loss: 0.000731012667529285 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80711\n",
            "Total Loss: 2.578982353210449 | Context Loss: 0.0008291008998639882 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80712\n",
            "Total Loss: 2.821439266204834 | Context Loss: 0.0006358819082379341 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80713\n",
            "Total Loss: 2.3308379650115967 | Context Loss: 0.0007341167074628174 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80714\n",
            "Total Loss: 2.3859381675720215 | Context Loss: 0.0009674339089542627 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80715\n",
            "Total Loss: 2.252166748046875 | Context Loss: 0.0007340827723965049 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80716\n",
            "Total Loss: 3.647674560546875 | Context Loss: 0.00044375890865921974 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80717\n",
            "Total Loss: 3.4118990898132324 | Context Loss: 0.0005746987299062312 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80718\n",
            "Total Loss: 2.3250339031219482 | Context Loss: 0.0008176546543836594 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80719\n",
            "Total Loss: 2.678684949874878 | Context Loss: 0.0009200710337609053 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80720\n",
            "Total Loss: 3.056544303894043 | Context Loss: 0.0006217329064384103 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80721\n",
            "Total Loss: 2.4329898357391357 | Context Loss: 0.0005320593481883407 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80722\n",
            "Total Loss: 3.6278998851776123 | Context Loss: 0.0005781947402283549 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 80723\n",
            "Total Loss: 2.5774126052856445 | Context Loss: 0.0006600915803574026 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80724\n",
            "Total Loss: 2.1153829097747803 | Context Loss: 0.0007610670290887356 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80725\n",
            "Total Loss: 2.5244345664978027 | Context Loss: 0.0007411938859149814 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80726\n",
            "Total Loss: 2.1713128089904785 | Context Loss: 0.000520968867931515 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80727\n",
            "Total Loss: 3.2216529846191406 | Context Loss: 0.0005547195905819535 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 80728\n",
            "Total Loss: 4.122620582580566 | Context Loss: 0.0005707773379981518 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80729\n",
            "Total Loss: 2.299558639526367 | Context Loss: 0.0006820045528002083 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80730\n",
            "Total Loss: 2.9700801372528076 | Context Loss: 0.000491119921207428 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80731\n",
            "Total Loss: 2.898801565170288 | Context Loss: 0.0007490768912248313 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80732\n",
            "Total Loss: 2.704876184463501 | Context Loss: 0.0005214225384406745 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80733\n",
            "Total Loss: 3.0154547691345215 | Context Loss: 0.0005415240884758532 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 80734\n",
            "Total Loss: 2.3701558113098145 | Context Loss: 0.0006431600777432323 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80735\n",
            "Total Loss: 2.619872570037842 | Context Loss: 0.000720809621270746 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80736\n",
            "Total Loss: 2.795499324798584 | Context Loss: 0.0005654011620208621 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80737\n",
            "Total Loss: 2.7851223945617676 | Context Loss: 0.0004656490928027779 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80738\n",
            "Total Loss: 2.5761210918426514 | Context Loss: 0.0008807678241282701 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80739\n",
            "Total Loss: 2.2772412300109863 | Context Loss: 0.000638038560282439 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80740\n",
            "Total Loss: 3.0326733589172363 | Context Loss: 0.0006087748915888369 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80741\n",
            "Total Loss: 2.8968703746795654 | Context Loss: 0.0005224154447205365 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80742\n",
            "Total Loss: 2.0003621578216553 | Context Loss: 0.0007608118467032909 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80743\n",
            "Total Loss: 2.610610008239746 | Context Loss: 0.0005412021419033408 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80744\n",
            "Total Loss: 2.545922040939331 | Context Loss: 0.000847221992444247 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80745\n",
            "Total Loss: 2.8121285438537598 | Context Loss: 0.0008004843257367611 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80746\n",
            "Total Loss: 2.4317355155944824 | Context Loss: 0.0008303728536702693 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 80747\n",
            "Total Loss: 3.0191383361816406 | Context Loss: 0.0007472904399037361 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80748\n",
            "Total Loss: 3.3588311672210693 | Context Loss: 0.0008848391007632017 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80749\n",
            "Total Loss: 2.832216262817383 | Context Loss: 0.0005354499444365501 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80750\n",
            "\n",
            "\n",
            " -- Iteration 80750 --\n",
            "0: im the best that i know and you know it@ \n",
            " and i work on a very tight show it@ \n",
            " i have done so i mean it# \n",
            " a bit of a mean it# \n",
            " so you know my expertise cant be hoot it@\n",
            "\n",
            "\n",
            "1: a pirate whos dead wants a drink@ \n",
            " but his body is left in a wreck@ \n",
            " on the greeks hed beseech# \n",
            " so a gloat may be made# \n",
            " to elude with the greeks in the pink@\n",
            "\n",
            "\n",
            "2: what  i am a fan of his play@ \n",
            " but if you dont read the play@ \n",
            " just look inside see# \n",
            " what ive seen and cant see# \n",
            " why the words all that should be ok@\n",
            "\n",
            "\n",
            "3: its not far off as the day might seem@ \n",
            " its a state in australia its close@ \n",
            " theres a few others though# \n",
            " from brazil to bali# \n",
            " not the same as alaskaa  thats not@\n",
            "\n",
            "\n",
            "4: the word is used just a little bit@ \n",
            " its a term that can also be used@ \n",
            " if its something thats old# \n",
            " or if something is bold# \n",
            " use the same word for any word that you bit@\n",
            "\n",
            "\n",
            "Total Loss: 3.1578757762908936 | Context Loss: 0.0004860956687480211 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80751\n",
            "Total Loss: 2.551027774810791 | Context Loss: 0.0006208132836036384 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80752\n",
            "Total Loss: 2.077895402908325 | Context Loss: 0.000761812028940767 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80753\n",
            "Total Loss: 2.9195504188537598 | Context Loss: 0.000634893134701997 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80754\n",
            "Total Loss: 2.3788838386535645 | Context Loss: 0.0006323423585854471 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 80755\n",
            "Total Loss: 2.491792917251587 | Context Loss: 0.00076845329022035 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80756\n",
            "Total Loss: 2.5419437885284424 | Context Loss: 0.000502615119330585 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80757\n",
            "Total Loss: 2.404244899749756 | Context Loss: 0.000577109691221267 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80758\n",
            "Total Loss: 3.3649961948394775 | Context Loss: 0.0006767461309209466 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80759\n",
            "Total Loss: 2.1951510906219482 | Context Loss: 0.0004923984524793923 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80760\n",
            "Total Loss: 2.969388961791992 | Context Loss: 0.000832388992421329 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80761\n",
            "Total Loss: 2.672208309173584 | Context Loss: 0.0007959813228808343 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80762\n",
            "Total Loss: 2.8073339462280273 | Context Loss: 0.0008899093372747302 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80763\n",
            "Total Loss: 2.7498586177825928 | Context Loss: 0.0007893436122685671 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80764\n",
            "Total Loss: 3.0644664764404297 | Context Loss: 0.0006829563644714653 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80765\n",
            "Total Loss: 2.539029359817505 | Context Loss: 0.0007626864826306701 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80766\n",
            "Total Loss: 2.5143251419067383 | Context Loss: 0.0004775969428010285 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80767\n",
            "Total Loss: 2.590162992477417 | Context Loss: 0.000835197395645082 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80768\n",
            "Total Loss: 3.3862593173980713 | Context Loss: 0.0006430865614674985 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80769\n",
            "Total Loss: 2.254957675933838 | Context Loss: 0.0006411504000425339 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80770\n",
            "Total Loss: 3.5123343467712402 | Context Loss: 0.0005835182382725179 | Rhyme Loss: 0.48670388665841996 \n",
            "Iteration number: 80771\n",
            "Total Loss: 2.7156403064727783 | Context Loss: 0.0009973685955628753 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80772\n",
            "Total Loss: 2.656838893890381 | Context Loss: 0.0006680997903458774 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80773\n",
            "Total Loss: 2.629734992980957 | Context Loss: 0.0006718765944242477 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80774\n",
            "Total Loss: 3.8842694759368896 | Context Loss: 0.0008728253887966275 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80775\n",
            "Total Loss: 2.5769076347351074 | Context Loss: 0.0009567840024828911 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80776\n",
            "Total Loss: 2.201436758041382 | Context Loss: 0.0006353789940476418 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80777\n",
            "Total Loss: 3.069628953933716 | Context Loss: 0.0006232157466001809 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80778\n",
            "Total Loss: 2.6192331314086914 | Context Loss: 0.0005994815728627145 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80779\n",
            "Total Loss: 2.6579017639160156 | Context Loss: 0.000504236901178956 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80780\n",
            "Total Loss: 2.5695881843566895 | Context Loss: 0.0005819334182888269 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80781\n",
            "Total Loss: 2.3041346073150635 | Context Loss: 0.0007345110643655062 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80782\n",
            "Total Loss: 2.992330312728882 | Context Loss: 0.0007324413163587451 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80783\n",
            "Total Loss: 2.9140524864196777 | Context Loss: 0.0006815204978920519 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80784\n",
            "Total Loss: 2.5436079502105713 | Context Loss: 0.0007988058496266603 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80785\n",
            "Total Loss: 3.0659561157226562 | Context Loss: 0.0006778950919397175 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80786\n",
            "Total Loss: 2.409905195236206 | Context Loss: 0.0006532653933390975 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80787\n",
            "Total Loss: 2.1781277656555176 | Context Loss: 0.0006017877603881061 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80788\n",
            "Total Loss: 3.121919631958008 | Context Loss: 0.0004557642969302833 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80789\n",
            "Total Loss: 2.349030017852783 | Context Loss: 0.0006865858449600637 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80790\n",
            "Total Loss: 2.556276321411133 | Context Loss: 0.0008287622476927936 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80791\n",
            "Total Loss: 2.3225343227386475 | Context Loss: 0.0006924152839928865 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80792\n",
            "Total Loss: 2.8912882804870605 | Context Loss: 0.0011092119384557009 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80793\n",
            "Total Loss: 2.133918285369873 | Context Loss: 0.000572837598156184 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80794\n",
            "Total Loss: 2.232250690460205 | Context Loss: 0.0005887888255529106 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80795\n",
            "Total Loss: 2.3214409351348877 | Context Loss: 0.0006165916565805674 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80796\n",
            "Total Loss: 3.1465907096862793 | Context Loss: 0.0009865110041573644 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80797\n",
            "Total Loss: 2.81583571434021 | Context Loss: 0.0008026926079764962 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80798\n",
            "Total Loss: 3.27947998046875 | Context Loss: 0.0006010170909576118 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80799\n",
            "Total Loss: 3.9107306003570557 | Context Loss: 0.0006385745946317911 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80800\n",
            "Total Loss: 2.7160518169403076 | Context Loss: 0.00042832258623093367 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80801\n",
            "Total Loss: 2.3526618480682373 | Context Loss: 0.0009840374113991857 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80802\n",
            "Total Loss: 2.8057491779327393 | Context Loss: 0.0006681939121335745 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80803\n",
            "Total Loss: 2.9628374576568604 | Context Loss: 0.0006568175740540028 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80804\n",
            "Total Loss: 2.5779671669006348 | Context Loss: 0.0008983961888588965 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80805\n",
            "Total Loss: 2.289700984954834 | Context Loss: 0.0008213979890570045 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80806\n",
            "Total Loss: 3.7489867210388184 | Context Loss: 0.0005610908265225589 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80807\n",
            "Total Loss: 2.2729387283325195 | Context Loss: 0.0006927845533937216 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80808\n",
            "Total Loss: 3.44844388961792 | Context Loss: 0.0006976791191846132 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 80809\n",
            "Total Loss: 2.712470531463623 | Context Loss: 0.0005961324786767364 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80810\n",
            "Total Loss: 2.085324764251709 | Context Loss: 0.0006520084571093321 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80811\n",
            "Total Loss: 3.108349084854126 | Context Loss: 0.0005739518674090505 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 80812\n",
            "Total Loss: 2.1684014797210693 | Context Loss: 0.0005565437022596598 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80813\n",
            "Total Loss: 2.248255491256714 | Context Loss: 0.0007098062196746469 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80814\n",
            "Total Loss: 3.0898730754852295 | Context Loss: 0.0006039809668436646 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80815\n",
            "Total Loss: 2.347696304321289 | Context Loss: 0.0004948654677718878 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80816\n",
            "Total Loss: 2.073472738265991 | Context Loss: 0.0007418714230880141 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80817\n",
            "Total Loss: 2.4911279678344727 | Context Loss: 0.000663251499645412 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80818\n",
            "Total Loss: 2.606835126876831 | Context Loss: 0.0004779785231221467 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80819\n",
            "Total Loss: 2.693718910217285 | Context Loss: 0.0005829471629112959 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80820\n",
            "Total Loss: 3.2722151279449463 | Context Loss: 0.0004457930044736713 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80821\n",
            "Total Loss: 2.5569205284118652 | Context Loss: 0.0008775654714554548 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80822\n",
            "Total Loss: 2.1770942211151123 | Context Loss: 0.0006705374107696116 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80823\n",
            "Total Loss: 2.567124843597412 | Context Loss: 0.0010374652920290828 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80824\n",
            "Total Loss: 2.189194917678833 | Context Loss: 0.0009341583354398608 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80825\n",
            "Total Loss: 2.1292006969451904 | Context Loss: 0.0008367383270524442 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80826\n",
            "Total Loss: 2.8512420654296875 | Context Loss: 0.0007076545152813196 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80827\n",
            "Total Loss: 2.6932380199432373 | Context Loss: 0.0007786709466017783 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80828\n",
            "Total Loss: 2.7248661518096924 | Context Loss: 0.0006052580429241061 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80829\n",
            "Total Loss: 2.597169876098633 | Context Loss: 0.0009161361958831549 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80830\n",
            "Total Loss: 1.9076402187347412 | Context Loss: 0.0006534204003401101 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80831\n",
            "Total Loss: 2.684873104095459 | Context Loss: 0.0005032566259615123 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80832\n",
            "Total Loss: 2.7385714054107666 | Context Loss: 0.000494755688123405 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80833\n",
            "Total Loss: 3.583695411682129 | Context Loss: 0.0006437982665374875 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80834\n",
            "Total Loss: 2.3273086547851562 | Context Loss: 0.0009188958210870624 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80835\n",
            "Total Loss: 1.9688549041748047 | Context Loss: 0.0010289305355399847 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80836\n",
            "Total Loss: 3.0939695835113525 | Context Loss: 0.0006712934700772166 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80837\n",
            "Total Loss: 2.195523738861084 | Context Loss: 0.0008563955198042095 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80838\n",
            "Total Loss: 2.9678492546081543 | Context Loss: 0.0005397185450419784 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80839\n",
            "Total Loss: 1.920230746269226 | Context Loss: 0.0005446326686069369 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80840\n",
            "Total Loss: 2.2657387256622314 | Context Loss: 0.0005734107689931989 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80841\n",
            "Total Loss: 3.062047243118286 | Context Loss: 0.0006241322844289243 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80842\n",
            "Total Loss: 2.7735509872436523 | Context Loss: 0.0005275230505503714 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80843\n",
            "Total Loss: 2.363701820373535 | Context Loss: 0.0005790959112346172 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80844\n",
            "Total Loss: 2.0046486854553223 | Context Loss: 0.0007913395529612899 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80845\n",
            "Total Loss: 2.5181756019592285 | Context Loss: 0.0006832676008343697 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 80846\n",
            "Total Loss: 3.1768007278442383 | Context Loss: 0.0005468839663080871 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80847\n",
            "Total Loss: 2.8088862895965576 | Context Loss: 0.0005732403951697052 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80848\n",
            "Total Loss: 2.329033374786377 | Context Loss: 0.0007049745181575418 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80849\n",
            "Total Loss: 2.417146682739258 | Context Loss: 0.0006825479795224965 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80850\n",
            "Total Loss: 3.0303659439086914 | Context Loss: 0.0007767362403683364 | Rhyme Loss: 0.10677613351703631 \n",
            "Iteration number: 80851\n",
            "Total Loss: 3.225604772567749 | Context Loss: 0.001009913394227624 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80852\n",
            "Total Loss: 3.0284290313720703 | Context Loss: 0.0006020640139468014 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 80853\n",
            "Total Loss: 1.5809329748153687 | Context Loss: 0.000706819468177855 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80854\n",
            "Total Loss: 1.9595452547073364 | Context Loss: 0.000736455200240016 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80855\n",
            "Total Loss: 2.954944372177124 | Context Loss: 0.0007247974863275886 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80856\n",
            "Total Loss: 2.128101110458374 | Context Loss: 0.0005699171451851726 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80857\n",
            "Total Loss: 2.9570045471191406 | Context Loss: 0.0005599739961326122 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80858\n",
            "Total Loss: 2.5783634185791016 | Context Loss: 0.000526494113728404 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80859\n",
            "Total Loss: 3.508127450942993 | Context Loss: 0.0010486679384484887 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80860\n",
            "Total Loss: 2.3823142051696777 | Context Loss: 0.0006011482328176498 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 80861\n",
            "Total Loss: 2.897512197494507 | Context Loss: 0.0004983004182577133 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80862\n",
            "Total Loss: 2.886183738708496 | Context Loss: 0.0006117059383541346 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 80863\n",
            "Total Loss: 1.9604486227035522 | Context Loss: 0.0008268804522231221 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80864\n",
            "Total Loss: 2.4786875247955322 | Context Loss: 0.0005319109186530113 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80865\n",
            "Total Loss: 2.558515787124634 | Context Loss: 0.0008638673461973667 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80866\n",
            "Total Loss: 2.332451820373535 | Context Loss: 0.0006016356637701392 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80867\n",
            "Total Loss: 2.981637716293335 | Context Loss: 0.0006541932816617191 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80868\n",
            "Total Loss: 3.7193758487701416 | Context Loss: 0.0006443564780056477 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80869\n",
            "Total Loss: 2.155449151992798 | Context Loss: 0.0007957057096064091 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80870\n",
            "Total Loss: 2.070863962173462 | Context Loss: 0.0007379205198958516 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80871\n",
            "Total Loss: 2.9926302433013916 | Context Loss: 0.0006532266270369291 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80872\n",
            "Total Loss: 2.4752979278564453 | Context Loss: 0.0008452530018985271 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80873\n",
            "Total Loss: 3.232775926589966 | Context Loss: 0.0005423192051239312 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 80874\n",
            "Total Loss: 2.936917304992676 | Context Loss: 0.0005554039962589741 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80875\n",
            "Total Loss: 2.4339308738708496 | Context Loss: 0.0006262307870201766 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80876\n",
            "Total Loss: 4.8625006675720215 | Context Loss: 0.000497178640216589 | Rhyme Loss: 0.3434008959515049 \n",
            "Iteration number: 80877\n",
            "Total Loss: 3.095216751098633 | Context Loss: 0.000927719462197274 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80878\n",
            "Total Loss: 2.4472360610961914 | Context Loss: 0.0007081538205966353 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80879\n",
            "Total Loss: 2.6857173442840576 | Context Loss: 0.0006139482720755041 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80880\n",
            "Total Loss: 2.6021857261657715 | Context Loss: 0.0006893894169479609 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80881\n",
            "Total Loss: 2.9373579025268555 | Context Loss: 0.0006397110410034657 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80882\n",
            "Total Loss: 3.0837156772613525 | Context Loss: 0.0005659572198055685 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80883\n",
            "Total Loss: 2.671558380126953 | Context Loss: 0.0007222420535981655 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80884\n",
            "Total Loss: 2.8739049434661865 | Context Loss: 0.0008692004485055804 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80885\n",
            "Total Loss: 2.7641360759735107 | Context Loss: 0.0005467209848575294 | Rhyme Loss: 0.43501924378948015 \n",
            "Iteration number: 80886\n",
            "Total Loss: 3.713385820388794 | Context Loss: 0.0006387094035744667 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80887\n",
            "Total Loss: 2.9723939895629883 | Context Loss: 0.0005159078282304108 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80888\n",
            "Total Loss: 2.774413824081421 | Context Loss: 0.0005238697049207985 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80889\n",
            "Total Loss: 2.8677101135253906 | Context Loss: 0.0005585644976235926 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80890\n",
            "Total Loss: 2.4327306747436523 | Context Loss: 0.0006178008625283837 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80891\n",
            "Total Loss: 2.968684673309326 | Context Loss: 0.0008289006073027849 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80892\n",
            "Total Loss: 2.850022554397583 | Context Loss: 0.0005563789163716137 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80893\n",
            "Total Loss: 2.8736464977264404 | Context Loss: 0.0005796742625534534 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80894\n",
            "Total Loss: 2.387000322341919 | Context Loss: 0.0007660807459615171 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80895\n",
            "Total Loss: 2.827430486679077 | Context Loss: 0.0006010885699652135 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80896\n",
            "Total Loss: 2.259112596511841 | Context Loss: 0.0004055064346175641 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80897\n",
            "Total Loss: 2.4339029788970947 | Context Loss: 0.0006069957162253559 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 80898\n",
            "Total Loss: 2.510814666748047 | Context Loss: 0.0005490727489814162 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80899\n",
            "Total Loss: 2.522138833999634 | Context Loss: 0.0005292018759064376 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80900\n",
            "Total Loss: 2.090951442718506 | Context Loss: 0.0008808255661278963 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80901\n",
            "Total Loss: 2.5742173194885254 | Context Loss: 0.0007722221198491752 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80902\n",
            "Total Loss: 2.905726671218872 | Context Loss: 0.0007440975750796497 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80903\n",
            "Total Loss: 3.8339128494262695 | Context Loss: 0.0007114390609785914 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80904\n",
            "Total Loss: 3.4926068782806396 | Context Loss: 0.000623773317784071 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80905\n",
            "Total Loss: 2.9543986320495605 | Context Loss: 0.0006604715599678457 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80906\n",
            "Total Loss: 2.4784553050994873 | Context Loss: 0.0005582646117545664 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80907\n",
            "Total Loss: 2.899763822555542 | Context Loss: 0.0007018402102403343 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 80908\n",
            "Total Loss: 2.073967933654785 | Context Loss: 0.0006987787201069295 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80909\n",
            "Total Loss: 2.4689857959747314 | Context Loss: 0.0008710676338523626 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80910\n",
            "Total Loss: 2.436171770095825 | Context Loss: 0.000671336252707988 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80911\n",
            "Total Loss: 2.968639850616455 | Context Loss: 0.000606261077336967 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80912\n",
            "Total Loss: 2.702096462249756 | Context Loss: 0.0008387318812310696 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80913\n",
            "Total Loss: 2.7393133640289307 | Context Loss: 0.0005431458703242242 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80914\n",
            "Total Loss: 2.327059745788574 | Context Loss: 0.0006316977669484913 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80915\n",
            "Total Loss: 2.238982915878296 | Context Loss: 0.0006943887565284967 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80916\n",
            "Total Loss: 2.3256235122680664 | Context Loss: 0.000609321054071188 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80917\n",
            "Total Loss: 2.5504798889160156 | Context Loss: 0.0005559563869610429 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80918\n",
            "Total Loss: 2.525777816772461 | Context Loss: 0.0005696865846402943 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80919\n",
            "Total Loss: 2.556028366088867 | Context Loss: 0.0007776201236993074 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80920\n",
            "Total Loss: 2.9927237033843994 | Context Loss: 0.0004897754988633096 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 80921\n",
            "Total Loss: 3.094986915588379 | Context Loss: 0.0005847135907970369 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80922\n",
            "Total Loss: 2.4840855598449707 | Context Loss: 0.0006408392800949514 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80923\n",
            "Total Loss: 2.372075319290161 | Context Loss: 0.0006570782861672342 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80924\n",
            "Total Loss: 2.4043514728546143 | Context Loss: 0.0008021134417504072 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80925\n",
            "Total Loss: 2.502626419067383 | Context Loss: 0.0005378283676691353 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80926\n",
            "Total Loss: 2.9138426780700684 | Context Loss: 0.0006179921329021454 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80927\n",
            "Total Loss: 2.5412795543670654 | Context Loss: 0.0007997581269592047 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80928\n",
            "Total Loss: 2.9272634983062744 | Context Loss: 0.0008500832482241094 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80929\n",
            "Total Loss: 2.004971504211426 | Context Loss: 0.000785448937676847 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80930\n",
            "Total Loss: 3.785485029220581 | Context Loss: 0.0006186137325130403 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80931\n",
            "Total Loss: 2.7501637935638428 | Context Loss: 0.0007058723131194711 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80932\n",
            "Total Loss: 2.8147852420806885 | Context Loss: 0.0007801051251590252 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80933\n",
            "Total Loss: 2.70192289352417 | Context Loss: 0.0006537481676787138 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80934\n",
            "Total Loss: 2.904670476913452 | Context Loss: 0.00043475424172356725 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80935\n",
            "Total Loss: 2.429452896118164 | Context Loss: 0.0007613743655383587 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80936\n",
            "Total Loss: 3.335514545440674 | Context Loss: 0.0004997570067644119 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80937\n",
            "Total Loss: 2.123847007751465 | Context Loss: 0.0010041941422969103 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80938\n",
            "Total Loss: 3.104290008544922 | Context Loss: 0.0008554443484172225 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80939\n",
            "Total Loss: 2.182633876800537 | Context Loss: 0.0006643142551183701 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80940\n",
            "Total Loss: 2.581973075866699 | Context Loss: 0.000964056933298707 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80941\n",
            "Total Loss: 2.885679244995117 | Context Loss: 0.0005514221265912056 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80942\n",
            "Total Loss: 2.4090006351470947 | Context Loss: 0.0007046482060104609 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80943\n",
            "Total Loss: 2.4380295276641846 | Context Loss: 0.0005568646593019366 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80944\n",
            "Total Loss: 3.2644433975219727 | Context Loss: 0.0005328642437234521 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80945\n",
            "Total Loss: 1.9324886798858643 | Context Loss: 0.000793707906268537 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80946\n",
            "Total Loss: 2.274176836013794 | Context Loss: 0.0006636853213422 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80947\n",
            "Total Loss: 3.025130033493042 | Context Loss: 0.0006566081428900361 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80948\n",
            "Total Loss: 2.6189932823181152 | Context Loss: 0.0006919922307133675 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80949\n",
            "Total Loss: 2.699700117111206 | Context Loss: 0.0005825536791235209 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80950\n",
            "Total Loss: 3.1400907039642334 | Context Loss: 0.0005967303295619786 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80951\n",
            "Total Loss: 2.717165470123291 | Context Loss: 0.0007719905115664005 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80952\n",
            "Total Loss: 2.068976879119873 | Context Loss: 0.0006129755638539791 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80953\n",
            "Total Loss: 2.0305001735687256 | Context Loss: 0.0010614683851599693 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80954\n",
            "Total Loss: 3.341567277908325 | Context Loss: 0.0006387454923242331 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80955\n",
            "Total Loss: 2.1789419651031494 | Context Loss: 0.0008406003471463919 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80956\n",
            "Total Loss: 2.7867138385772705 | Context Loss: 0.0005384383257478476 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80957\n",
            "Total Loss: 2.714775323867798 | Context Loss: 0.0006743220728822052 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80958\n",
            "Total Loss: 2.216965675354004 | Context Loss: 0.0006212198059074581 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80959\n",
            "Total Loss: 2.709376096725464 | Context Loss: 0.00038441974902525544 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80960\n",
            "Total Loss: 2.31453013420105 | Context Loss: 0.0006387478206306696 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80961\n",
            "Total Loss: 4.715682506561279 | Context Loss: -1 | Rhyme Loss: -1 \n",
            "Iteration number: 80962\n",
            "Total Loss: 2.1897284984588623 | Context Loss: 0.0008701368351466954 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80963\n",
            "Total Loss: 2.9431445598602295 | Context Loss: 0.0006482707103714347 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80964\n",
            "Total Loss: 3.2416272163391113 | Context Loss: 0.0006224765675142407 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80965\n",
            "Total Loss: 2.637995719909668 | Context Loss: 0.0006091765826568007 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80966\n",
            "Total Loss: 3.1006996631622314 | Context Loss: 0.0005362791707739234 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 80967\n",
            "Total Loss: 2.2308273315429688 | Context Loss: 0.0010240459814667702 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80968\n",
            "Total Loss: 2.403231620788574 | Context Loss: 0.0005276745068840683 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80969\n",
            "Total Loss: 5.302151679992676 | Context Loss: 0.00048174182302318513 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 80970\n",
            "Total Loss: 2.737855911254883 | Context Loss: 0.0007962858071550727 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80971\n",
            "Total Loss: 2.4085631370544434 | Context Loss: 0.0007070336723700166 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80972\n",
            "Total Loss: 2.0958092212677 | Context Loss: 0.0008619212312623858 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80973\n",
            "Total Loss: 3.2306082248687744 | Context Loss: 0.0005125936004333198 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 80974\n",
            "Total Loss: 2.876950979232788 | Context Loss: 0.0007819181773811579 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80975\n",
            "Total Loss: 2.733287811279297 | Context Loss: 0.0005087224999442697 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80976\n",
            "Total Loss: 2.5560569763183594 | Context Loss: 0.0006944590131752193 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80977\n",
            "Total Loss: 1.9028105735778809 | Context Loss: 0.0009675119072198868 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80978\n",
            "Total Loss: 2.1686034202575684 | Context Loss: 0.0009410366183146834 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80979\n",
            "Total Loss: 3.218552589416504 | Context Loss: 0.0006181801436468959 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80980\n",
            "Total Loss: 3.1147513389587402 | Context Loss: 0.0005490168114192784 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80981\n",
            "Total Loss: 2.556438684463501 | Context Loss: 0.0007407355587929487 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80982\n",
            "Total Loss: 2.874635696411133 | Context Loss: 0.0010653340723365545 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80983\n",
            "Total Loss: 2.2259714603424072 | Context Loss: 0.0011371022555977106 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80984\n",
            "Total Loss: 2.812206506729126 | Context Loss: 0.0005526894237846136 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80985\n",
            "Total Loss: 2.3651442527770996 | Context Loss: 0.0005240632453933358 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80986\n",
            "Total Loss: 2.2521276473999023 | Context Loss: 0.0006195431924425066 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80987\n",
            "Total Loss: 2.7992241382598877 | Context Loss: 0.0005954087828285992 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80988\n",
            "Total Loss: 2.9027040004730225 | Context Loss: 0.00046200945507735014 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80989\n",
            "Total Loss: 2.9360740184783936 | Context Loss: 0.0006210070569068193 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80990\n",
            "Total Loss: 3.4427826404571533 | Context Loss: 0.000593495205976069 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80991\n",
            "Total Loss: 2.7764968872070312 | Context Loss: 0.00048158879508264363 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80992\n",
            "Total Loss: 2.8237340450286865 | Context Loss: 0.00042138859862461686 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80993\n",
            "Total Loss: 2.097194194793701 | Context Loss: 0.0008143692975863814 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80994\n",
            "Total Loss: 2.422010660171509 | Context Loss: 0.0004842029302380979 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80995\n",
            "Total Loss: 2.8473100662231445 | Context Loss: 0.000640572514384985 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 80996\n",
            "Total Loss: 3.1632370948791504 | Context Loss: 0.0005527884932234883 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80997\n",
            "Total Loss: 2.3331470489501953 | Context Loss: 0.0009348459425382316 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80998\n",
            "Total Loss: 2.320768356323242 | Context Loss: 0.0005696940352208912 | Rhyme Loss: 0.0 \n",
            "Iteration number: 80999\n",
            "Total Loss: 2.882448196411133 | Context Loss: 0.0006110219401307404 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81000\n",
            "\n",
            "\n",
            " -- Iteration 81000 --\n",
            "0: im a rock star im not a dork@ \n",
            " my big nose and my bigchin noork@ \n",
            " im a rock star a boy# \n",
            " if i say i could sell# \n",
            " i could sell all the blues i have hunk@\n",
            "\n",
            "\n",
            "1: im not going in now shes gone@ \n",
            " so i dont want to go any more@ \n",
            " i must go away# \n",
            " but im stuck and im poor# \n",
            " i feel like an old man at the till@\n",
            "\n",
            "\n",
            "2: dire in his own im no fool@ \n",
            " im an ancientreek god the wise fool@ \n",
            " is no duke no lute# \n",
            " no man whos blind and mute # \n",
            " im a dour and i wont be wooed@\n",
            "\n",
            "\n",
            "3: i like cats with a face that can winkle@ \n",
            " and a tail that is very dinkle@ \n",
            " but my cat has a tail# \n",
            " thats like mine on his tail# \n",
            " i love that its not my butler minkle@\n",
            "\n",
            "\n",
            "4: our new home is on sale lets explore@ \n",
            " and if not well try out some new fern@ \n",
            " we dont need all that stuff# \n",
            " and well just take some stuff# \n",
            " if its green let us plant some out of our frond@\n",
            "\n",
            "\n",
            "Total Loss: 2.1334593296051025 | Context Loss: 0.0006147599779069424 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81001\n",
            "Total Loss: 2.3292086124420166 | Context Loss: 0.0008801423828117549 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81002\n",
            "Total Loss: 2.7860476970672607 | Context Loss: 0.0007018217584118247 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81003\n",
            "Total Loss: 2.875904083251953 | Context Loss: 0.0007752214442007244 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81004\n",
            "Total Loss: 2.229706048965454 | Context Loss: 0.0005088078323751688 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81005\n",
            "Total Loss: 3.2873125076293945 | Context Loss: 0.0005454730708152056 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81006\n",
            "Total Loss: 3.3870582580566406 | Context Loss: 0.0010200797114521265 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81007\n",
            "Total Loss: 2.7614572048187256 | Context Loss: 0.0006908659124746919 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81008\n",
            "Total Loss: 2.3084397315979004 | Context Loss: 0.0006314374040812254 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81009\n",
            "Total Loss: 1.995309829711914 | Context Loss: 0.0008764602825976908 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81010\n",
            "Total Loss: 2.409506320953369 | Context Loss: 0.0007134313927963376 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81011\n",
            "Total Loss: 2.636122941970825 | Context Loss: 0.000879736035130918 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81012\n",
            "Total Loss: 3.437981128692627 | Context Loss: 0.0006762944394722581 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81013\n",
            "Total Loss: 2.74755597114563 | Context Loss: 0.0006476010894402862 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81014\n",
            "Total Loss: 2.684537172317505 | Context Loss: 0.0005485865985974669 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81015\n",
            "Total Loss: 2.8979339599609375 | Context Loss: 0.0006299744709394872 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81016\n",
            "Total Loss: 2.744579792022705 | Context Loss: 0.0006580441258847713 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81017\n",
            "Total Loss: 2.47485089302063 | Context Loss: 0.0007258643163368106 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81018\n",
            "Total Loss: 3.007291793823242 | Context Loss: 0.00047134392661973834 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81019\n",
            "Total Loss: 2.2308332920074463 | Context Loss: 0.0006422703736461699 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81020\n",
            "Total Loss: 1.7026067972183228 | Context Loss: 0.0006726429564878345 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81021\n",
            "Total Loss: 2.509876012802124 | Context Loss: 0.0005191864911466837 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81022\n",
            "Total Loss: 2.21468186378479 | Context Loss: 0.0005408246070146561 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81023\n",
            "Total Loss: 2.179934024810791 | Context Loss: 0.0007126500131562352 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81024\n",
            "Total Loss: 3.316742420196533 | Context Loss: 0.0007341810269281268 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81025\n",
            "Total Loss: 2.860820770263672 | Context Loss: 0.0005430114106275141 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81026\n",
            "Total Loss: 3.0124101638793945 | Context Loss: 0.0004470162675715983 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81027\n",
            "Total Loss: 3.0717411041259766 | Context Loss: 0.0005618793074972928 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81028\n",
            "Total Loss: 2.6451709270477295 | Context Loss: 0.0006825304008089006 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 81029\n",
            "Total Loss: 2.5382883548736572 | Context Loss: 0.0004284901078790426 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81030\n",
            "Total Loss: 3.2629973888397217 | Context Loss: 0.0005734798032790422 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81031\n",
            "Total Loss: 3.091557502746582 | Context Loss: 0.0007338901050388813 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81032\n",
            "Total Loss: 2.5977511405944824 | Context Loss: 0.0005848606815561652 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81033\n",
            "Total Loss: 2.2939400672912598 | Context Loss: 0.0006032741512171924 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81034\n",
            "Total Loss: 3.078352451324463 | Context Loss: 0.0006071623647585511 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81035\n",
            "Total Loss: 2.391432285308838 | Context Loss: 0.0005544185405597091 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81036\n",
            "Total Loss: 3.5145862102508545 | Context Loss: 0.0007795872515998781 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 81037\n",
            "Total Loss: 2.9388177394866943 | Context Loss: 0.0005249684909358621 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81038\n",
            "Total Loss: 2.630227565765381 | Context Loss: 0.00045095826499164104 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81039\n",
            "Total Loss: 2.292684316635132 | Context Loss: 0.0007558637298643589 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81040\n",
            "Total Loss: 3.4406754970550537 | Context Loss: 0.0005712338024750352 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81041\n",
            "Total Loss: 2.970675230026245 | Context Loss: 0.0005623656907118857 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81042\n",
            "Total Loss: 2.5537972450256348 | Context Loss: 0.0005206648493185639 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81043\n",
            "Total Loss: 3.2724320888519287 | Context Loss: 0.0006871962687000632 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81044\n",
            "Total Loss: 2.7254981994628906 | Context Loss: 0.0005072831409052014 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81045\n",
            "Total Loss: 2.186554431915283 | Context Loss: 0.0005922153359279037 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81046\n",
            "Total Loss: 2.1999993324279785 | Context Loss: 0.0004969797446392477 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81047\n",
            "Total Loss: 2.1000349521636963 | Context Loss: 0.000585209927521646 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81048\n",
            "Total Loss: 2.101749897003174 | Context Loss: 0.000616217206697911 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81049\n",
            "Total Loss: 2.4725961685180664 | Context Loss: 0.0005686829681508243 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81050\n",
            "Total Loss: 2.386655330657959 | Context Loss: 0.0006262053502723575 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81051\n",
            "Total Loss: 2.8067119121551514 | Context Loss: 0.0006675529293715954 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81052\n",
            "Total Loss: 2.1263084411621094 | Context Loss: 0.0011281798360869288 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81053\n",
            "Total Loss: 3.009165048599243 | Context Loss: 0.0007134308689273894 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81054\n",
            "Total Loss: 2.6235766410827637 | Context Loss: 0.0007372802938334644 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81055\n",
            "Total Loss: 2.2452175617218018 | Context Loss: 0.0006861460860818624 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81056\n",
            "Total Loss: 2.5322821140289307 | Context Loss: 0.0008668027585372329 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81057\n",
            "Total Loss: 2.3198182582855225 | Context Loss: 0.0006075206911191344 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81058\n",
            "Total Loss: 2.4306480884552 | Context Loss: 0.0008379335631616414 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81059\n",
            "Total Loss: 3.726630449295044 | Context Loss: 0.0004448851104825735 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81060\n",
            "Total Loss: 3.991011381149292 | Context Loss: 0.0005290162516757846 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81061\n",
            "Total Loss: 2.6116530895233154 | Context Loss: 0.0004965228727087379 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81062\n",
            "Total Loss: 2.945497751235962 | Context Loss: 0.000532963895238936 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81063\n",
            "Total Loss: 2.50183367729187 | Context Loss: 0.0005960931885056198 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81064\n",
            "Total Loss: 2.440983533859253 | Context Loss: 0.0007840780890546739 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81065\n",
            "Total Loss: 2.5154201984405518 | Context Loss: 0.0005852542817592621 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81066\n",
            "Total Loss: 2.0516254901885986 | Context Loss: 0.0007807331276126206 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81067\n",
            "Total Loss: 2.188131093978882 | Context Loss: 0.0005714137805625796 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81068\n",
            "Total Loss: 2.4218764305114746 | Context Loss: 0.0005841281963512301 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81069\n",
            "Total Loss: 2.674238920211792 | Context Loss: 0.0004990900051780045 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81070\n",
            "Total Loss: 2.5443663597106934 | Context Loss: 0.0007413319544866681 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81071\n",
            "Total Loss: 2.9642415046691895 | Context Loss: 0.0005921630072407424 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81072\n",
            "Total Loss: 2.084167003631592 | Context Loss: 0.000696779927238822 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81073\n",
            "Total Loss: 2.629660129547119 | Context Loss: 0.00043219333747401834 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81074\n",
            "Total Loss: 2.3123981952667236 | Context Loss: 0.0006400783313438296 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81075\n",
            "Total Loss: 2.5208282470703125 | Context Loss: 0.0006345028523355722 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81076\n",
            "Total Loss: 2.279191255569458 | Context Loss: 0.000903838430531323 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81077\n",
            "Total Loss: 3.3687572479248047 | Context Loss: 0.0004421630874276161 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81078\n",
            "Total Loss: 2.6772258281707764 | Context Loss: 0.0005462210392579436 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81079\n",
            "Total Loss: 3.7051925659179688 | Context Loss: 0.000666119041852653 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81080\n",
            "Total Loss: 2.476858615875244 | Context Loss: 0.000860524014569819 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81081\n",
            "Total Loss: 2.6797921657562256 | Context Loss: 0.000994963338598609 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81082\n",
            "Total Loss: 3.5477097034454346 | Context Loss: 0.0004893164150416851 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81083\n",
            "Total Loss: 2.7890286445617676 | Context Loss: 0.0006407410837709904 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81084\n",
            "Total Loss: 2.4926745891571045 | Context Loss: 0.0006581809720955789 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81085\n",
            "Total Loss: 2.867223024368286 | Context Loss: 0.0005081428098492324 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81086\n",
            "Total Loss: 2.7700679302215576 | Context Loss: 0.0006542083574458957 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81087\n",
            "Total Loss: 2.490121364593506 | Context Loss: 0.0005834632320329547 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81088\n",
            "Total Loss: 2.367048501968384 | Context Loss: 0.0013032328570261598 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81089\n",
            "Total Loss: 2.4226622581481934 | Context Loss: 0.000746019184589386 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81090\n",
            "Total Loss: 2.546842575073242 | Context Loss: 0.0008554853848181665 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81091\n",
            "Total Loss: 2.455274820327759 | Context Loss: 0.0007479359046556056 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81092\n",
            "Total Loss: 2.3610057830810547 | Context Loss: 0.0007713628583587706 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81093\n",
            "Total Loss: 2.218777894973755 | Context Loss: 0.0005846870481036603 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81094\n",
            "Total Loss: 2.412263870239258 | Context Loss: 0.0006075367564335465 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81095\n",
            "Total Loss: 2.361551523208618 | Context Loss: 0.0005965656600892544 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81096\n",
            "Total Loss: 2.0540575981140137 | Context Loss: 0.0010890226112678647 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81097\n",
            "Total Loss: 2.3674979209899902 | Context Loss: 0.0006268636789172888 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81098\n",
            "Total Loss: 2.6560733318328857 | Context Loss: 0.0007239602273330092 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81099\n",
            "Total Loss: 2.989888906478882 | Context Loss: 0.0006523284828290343 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81100\n",
            "Total Loss: 2.6628406047821045 | Context Loss: 0.0005889525637030602 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81101\n",
            "Total Loss: 2.9695663452148438 | Context Loss: 0.0008680696482770145 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81102\n",
            "Total Loss: 2.5516040325164795 | Context Loss: 0.0009113152627833188 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81103\n",
            "Total Loss: 3.6215457916259766 | Context Loss: 0.0005660307360813022 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81104\n",
            "Total Loss: 2.524977922439575 | Context Loss: 0.00048005604185163975 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81105\n",
            "Total Loss: 2.8868072032928467 | Context Loss: 0.0005035970825701952 | Rhyme Loss: 0.053388066758518156 \n",
            "Iteration number: 81106\n",
            "Total Loss: 2.1799612045288086 | Context Loss: 0.001058206195011735 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81107\n",
            "Total Loss: 2.2528884410858154 | Context Loss: 0.0005796235636807978 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81108\n",
            "Total Loss: 2.1207313537597656 | Context Loss: 0.0006416497635655105 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81109\n",
            "Total Loss: 2.032245397567749 | Context Loss: 0.0008186385966837406 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81110\n",
            "Total Loss: 3.6459808349609375 | Context Loss: 0.00044461508514359593 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81111\n",
            "Total Loss: 2.990715742111206 | Context Loss: 0.0008589128265157342 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81112\n",
            "Total Loss: 2.6567294597625732 | Context Loss: 0.0005222911713644862 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81113\n",
            "Total Loss: 2.101719856262207 | Context Loss: 0.0010110595030710101 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81114\n",
            "Total Loss: 3.1559579372406006 | Context Loss: 0.0006985011277720332 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81115\n",
            "Total Loss: 2.880547285079956 | Context Loss: 0.0005542878061532974 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81116\n",
            "Total Loss: 2.2627878189086914 | Context Loss: 0.0008706727530807257 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81117\n",
            "Total Loss: 2.1557233333587646 | Context Loss: 0.0005000315140932798 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81118\n",
            "Total Loss: 2.618593215942383 | Context Loss: 0.0005855876952409744 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81119\n",
            "Total Loss: 2.0744729042053223 | Context Loss: 0.0007697947439737618 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81120\n",
            "Total Loss: 2.437436103820801 | Context Loss: 0.0008211692911572754 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81121\n",
            "Total Loss: 2.479752779006958 | Context Loss: 0.000836497638374567 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81122\n",
            "Total Loss: 2.6294593811035156 | Context Loss: 0.0006612858269363642 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81123\n",
            "Total Loss: 2.7976527214050293 | Context Loss: 0.0006045399350114167 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81124\n",
            "Total Loss: 2.386432647705078 | Context Loss: 0.0009057435090653598 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81125\n",
            "Total Loss: 2.815155029296875 | Context Loss: 0.0005698078311979771 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81126\n",
            "Total Loss: 2.9994192123413086 | Context Loss: 0.0006940858438611031 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81127\n",
            "Total Loss: 2.2030677795410156 | Context Loss: 0.0006694069597870111 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81128\n",
            "Total Loss: 2.3044497966766357 | Context Loss: 0.0006193782901391387 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81129\n",
            "Total Loss: 3.1543288230895996 | Context Loss: 0.0009763161069713533 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81130\n",
            "Total Loss: 3.0461995601654053 | Context Loss: 0.0006092112744227052 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81131\n",
            "Total Loss: 3.176943302154541 | Context Loss: 0.0006585929659195244 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 81132\n",
            "Total Loss: 2.7675349712371826 | Context Loss: 0.0007613145862706006 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81133\n",
            "Total Loss: 2.9201717376708984 | Context Loss: 0.0006045083282515407 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81134\n",
            "Total Loss: 2.6896674633026123 | Context Loss: 0.0007462595822289586 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81135\n",
            "Total Loss: 3.4368467330932617 | Context Loss: 0.0005518796388059855 | Rhyme Loss: 0.6317103012549133 \n",
            "Iteration number: 81136\n",
            "Total Loss: 2.8933916091918945 | Context Loss: 0.0006352351047098637 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81137\n",
            "Total Loss: 2.0890958309173584 | Context Loss: 0.0006322889239527285 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81138\n",
            "Total Loss: 2.5722522735595703 | Context Loss: 0.0009207299444824457 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81139\n",
            "Total Loss: 2.533940076828003 | Context Loss: 0.000800933048594743 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81140\n",
            "Total Loss: 2.6893253326416016 | Context Loss: 0.0005855860654264688 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81141\n",
            "Total Loss: 2.9031503200531006 | Context Loss: 0.0006276519852690399 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81142\n",
            "Total Loss: 2.9732329845428467 | Context Loss: 0.0010585373966023326 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81143\n",
            "Total Loss: 2.514279842376709 | Context Loss: 0.0006596367456950247 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81144\n",
            "Total Loss: 2.7861409187316895 | Context Loss: 0.0006564779905602336 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81145\n",
            "Total Loss: 2.4531939029693604 | Context Loss: 0.0008465006249025464 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81146\n",
            "Total Loss: 2.7317826747894287 | Context Loss: 0.000497868750244379 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81147\n",
            "Total Loss: 2.4831385612487793 | Context Loss: 0.0009894405957311392 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81148\n",
            "Total Loss: 2.805248498916626 | Context Loss: 0.0006372188217937946 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81149\n",
            "Total Loss: 2.1573004722595215 | Context Loss: 0.0005158999701961875 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81150\n",
            "Total Loss: 2.746114730834961 | Context Loss: 0.0005190528463572264 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81151\n",
            "Total Loss: 2.627434492111206 | Context Loss: 0.000555343518499285 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81152\n",
            "Total Loss: 2.379059314727783 | Context Loss: 0.0007935316534712911 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81153\n",
            "Total Loss: 2.499631404876709 | Context Loss: 0.0007401421898975968 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81154\n",
            "Total Loss: 2.474184036254883 | Context Loss: 0.0005293276626616716 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81155\n",
            "Total Loss: 3.8808741569519043 | Context Loss: 0.0005458268569782376 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81156\n",
            "Total Loss: 2.4980623722076416 | Context Loss: 0.0007157956715673208 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81157\n",
            "Total Loss: 1.8961751461029053 | Context Loss: 0.0006787136662751436 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81158\n",
            "Total Loss: 2.5632240772247314 | Context Loss: 0.0007249664631672204 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81159\n",
            "Total Loss: 2.149562358856201 | Context Loss: 0.0005879107629880309 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81160\n",
            "Total Loss: 3.247917413711548 | Context Loss: 0.0005890603642910719 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81161\n",
            "Total Loss: 2.626936674118042 | Context Loss: 0.0005444770795293152 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81162\n",
            "Total Loss: 1.7331167459487915 | Context Loss: 0.000682469573803246 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81163\n",
            "Total Loss: 4.089115142822266 | Context Loss: 0.0005433846963569522 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81164\n",
            "Total Loss: 2.1683247089385986 | Context Loss: 0.0007896459428593516 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81165\n",
            "Total Loss: 2.8763997554779053 | Context Loss: 0.0005819941870868206 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81166\n",
            "Total Loss: 2.9624948501586914 | Context Loss: 0.0009351883782073855 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81167\n",
            "Total Loss: 3.04445481300354 | Context Loss: 0.0006204070523381233 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81168\n",
            "Total Loss: 2.7948946952819824 | Context Loss: 0.0007125316187739372 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81169\n",
            "Total Loss: 1.9580175876617432 | Context Loss: 0.0006474844994954765 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81170\n",
            "Total Loss: 2.049643039703369 | Context Loss: 0.0006935327546671033 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81171\n",
            "Total Loss: 2.4865386486053467 | Context Loss: 0.0007371301762759686 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81172\n",
            "Total Loss: 1.9904820919036865 | Context Loss: 0.0007488650735467672 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81173\n",
            "Total Loss: 1.5672399997711182 | Context Loss: 0.0007939898641780019 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81174\n",
            "Total Loss: 2.2938029766082764 | Context Loss: 0.0006751002511009574 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81175\n",
            "Total Loss: 2.172558546066284 | Context Loss: 0.0006658665952272713 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81176\n",
            "Total Loss: 2.854090929031372 | Context Loss: 0.0007035234593786299 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81177\n",
            "Total Loss: 2.651301383972168 | Context Loss: 0.0006005438044667244 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81178\n",
            "Total Loss: 3.4448914527893066 | Context Loss: 0.000564799178391695 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81179\n",
            "Total Loss: 1.937787652015686 | Context Loss: 0.000659323064610362 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81180\n",
            "Total Loss: 2.3595056533813477 | Context Loss: 0.0007950500003062189 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81181\n",
            "Total Loss: 2.450289011001587 | Context Loss: 0.0007836372824385762 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81182\n",
            "Total Loss: 2.8106396198272705 | Context Loss: 0.0007974267937242985 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81183\n",
            "Total Loss: 2.0528557300567627 | Context Loss: 0.0007046881364658475 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81184\n",
            "Total Loss: 2.8845102787017822 | Context Loss: 0.0006981941987760365 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81185\n",
            "Total Loss: 2.425325632095337 | Context Loss: 0.0006783230928704143 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81186\n",
            "Total Loss: 2.268453598022461 | Context Loss: 0.0007656279485672712 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81187\n",
            "Total Loss: 2.548424243927002 | Context Loss: 0.0007825577631592751 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81188\n",
            "Total Loss: 2.281153678894043 | Context Loss: 0.0007738035637885332 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81189\n",
            "Total Loss: 2.7515954971313477 | Context Loss: 0.0010726009495556355 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81190\n",
            "Total Loss: 2.2003495693206787 | Context Loss: 0.0010967808775603771 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81191\n",
            "Total Loss: 2.8843183517456055 | Context Loss: 0.0006909348303452134 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81192\n",
            "Total Loss: 2.9549777507781982 | Context Loss: 0.0008494585636071861 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81193\n",
            "Total Loss: 3.4962832927703857 | Context Loss: 0.0007765836780890822 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81194\n",
            "Total Loss: 1.5950801372528076 | Context Loss: 0.0006386286113411188 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81195\n",
            "Total Loss: 3.5456459522247314 | Context Loss: 0.0005277307936921716 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81196\n",
            "Total Loss: 3.7639944553375244 | Context Loss: 0.0004405047802720219 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81197\n",
            "Total Loss: 2.3131868839263916 | Context Loss: 0.0005331372958607972 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81198\n",
            "Total Loss: 2.995020866394043 | Context Loss: 0.0006443357560783625 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81199\n",
            "Total Loss: 3.0989344120025635 | Context Loss: 0.0005471546319313347 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81200\n",
            "Total Loss: 4.263142108917236 | Context Loss: 0.0006082945037633181 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81201\n",
            "Total Loss: 2.6797268390655518 | Context Loss: 0.0006746796425431967 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81202\n",
            "Total Loss: 3.254849672317505 | Context Loss: 0.0007428911048918962 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81203\n",
            "Total Loss: 2.3060107231140137 | Context Loss: 0.0005000074161216617 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81204\n",
            "Total Loss: 3.131530523300171 | Context Loss: 0.0005975362146273255 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81205\n",
            "Total Loss: 2.4958043098449707 | Context Loss: 0.0007704256568104029 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81206\n",
            "Total Loss: 2.440615653991699 | Context Loss: 0.0006453976966440678 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81207\n",
            "Total Loss: 2.685026168823242 | Context Loss: 0.0005716205341741443 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81208\n",
            "Total Loss: 2.2082600593566895 | Context Loss: 0.0007535297772847116 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81209\n",
            "Total Loss: 3.0360848903656006 | Context Loss: 0.000523547176271677 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81210\n",
            "Total Loss: 2.944603204727173 | Context Loss: 0.0006409171037375927 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81211\n",
            "Total Loss: 2.0273666381835938 | Context Loss: 0.0007790781673975289 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81212\n",
            "Total Loss: 3.6039483547210693 | Context Loss: 0.0008004900300875306 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 81213\n",
            "Total Loss: 2.990163564682007 | Context Loss: 0.0008029289892874658 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81214\n",
            "Total Loss: 2.5635526180267334 | Context Loss: 0.0006674039177596569 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81215\n",
            "Total Loss: 1.8111038208007812 | Context Loss: 0.0008598765707574785 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81216\n",
            "Total Loss: 2.6170294284820557 | Context Loss: 0.0007833341951481998 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81217\n",
            "Total Loss: 2.6803784370422363 | Context Loss: 0.0009588708053342998 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81218\n",
            "Total Loss: 2.7396955490112305 | Context Loss: 0.0005462213885039091 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81219\n",
            "Total Loss: 3.5703623294830322 | Context Loss: 0.0006683486863039434 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81220\n",
            "Total Loss: 2.2819340229034424 | Context Loss: 0.0005852636531926692 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81221\n",
            "Total Loss: 2.7730822563171387 | Context Loss: 0.0006767815793864429 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81222\n",
            "Total Loss: 2.4032375812530518 | Context Loss: 0.0005509007023647428 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81223\n",
            "Total Loss: 1.9535683393478394 | Context Loss: 0.0006774351932108402 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81224\n",
            "Total Loss: 3.1753129959106445 | Context Loss: 0.0007822061888873577 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81225\n",
            "Total Loss: 2.827178955078125 | Context Loss: 0.0006003757589496672 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81226\n",
            "Total Loss: 2.8836872577667236 | Context Loss: 0.0005971985519863665 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 81227\n",
            "Total Loss: 2.717775821685791 | Context Loss: 0.0007181171677075326 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81228\n",
            "Total Loss: 1.8564821481704712 | Context Loss: 0.0008098243270069361 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81229\n",
            "Total Loss: 2.5256354808807373 | Context Loss: 0.0004973122850060463 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81230\n",
            "Total Loss: 2.2177813053131104 | Context Loss: 0.0004897359758615494 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81231\n",
            "Total Loss: 2.7807250022888184 | Context Loss: 0.0006400076090358198 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81232\n",
            "Total Loss: 2.872845411300659 | Context Loss: 0.0008660561870783567 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81233\n",
            "Total Loss: 2.5171101093292236 | Context Loss: 0.00047086275299079716 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81234\n",
            "Total Loss: 3.0605826377868652 | Context Loss: 0.0005749135743826628 | Rhyme Loss: 0.10677613351703631 \n",
            "Iteration number: 81235\n",
            "Total Loss: 2.8462986946105957 | Context Loss: 0.0009950645035132766 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81236\n",
            "Total Loss: 3.0799975395202637 | Context Loss: 0.0007284102030098438 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81237\n",
            "Total Loss: 2.6307244300842285 | Context Loss: 0.000860835425555706 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81238\n",
            "Total Loss: 2.510596513748169 | Context Loss: 0.0005461929831653833 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81239\n",
            "Total Loss: 2.7384490966796875 | Context Loss: 0.0010126875713467598 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81240\n",
            "Total Loss: 2.228726625442505 | Context Loss: 0.0006325934664346278 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81241\n",
            "Total Loss: 2.723644256591797 | Context Loss: 0.0006831562495790422 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81242\n",
            "Total Loss: 3.541961908340454 | Context Loss: 0.000516394036822021 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81243\n",
            "Total Loss: 2.5605387687683105 | Context Loss: 0.0005942591233178973 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81244\n",
            "Total Loss: 2.1810476779937744 | Context Loss: 0.0007049728301353753 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81245\n",
            "Total Loss: 2.697190284729004 | Context Loss: 0.0008773881709203124 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81246\n",
            "Total Loss: 2.759814977645874 | Context Loss: 0.0005748403491452336 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81247\n",
            "Total Loss: 2.8075103759765625 | Context Loss: 0.00047449793783016503 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81248\n",
            "Total Loss: 2.376063346862793 | Context Loss: 0.0006624107481911778 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81249\n",
            "Total Loss: 3.235780954360962 | Context Loss: 0.000606014218647033 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81250\n",
            "\n",
            "\n",
            " -- Iteration 81250 --\n",
            "0: i said my girlfriend its clear@ \n",
            " of a pair and a pair at this ear@ \n",
            " of them both are of course# \n",
            " a few years old theyre older# \n",
            " youll see then i have a few more year@\n",
            "\n",
            "\n",
            "1: a man who can sing is a cropper@ \n",
            " which is why he can be a flop floppper@ \n",
            " but his voice doesnt soar# \n",
            " which is why hes a dyrus# \n",
            " he cant sing with his feet in the droppper@\n",
            "\n",
            "\n",
            "2: its so pretty a sight with its light@ \n",
            " the suns rays through the haze  dont you right@ \n",
            " at a point they wont stray# \n",
            " they may fall in a sty# \n",
            " but my best guess its not right the right bright@\n",
            "\n",
            "\n",
            "3: said the queen of a king for all nations@ \n",
            " when you take off your cap you must turn em@ \n",
            " you must let all the kings# \n",
            " wear their thongs and their rings# \n",
            " or youre bound for a terrible affray@\n",
            "\n",
            "\n",
            "4: you are lacking your sense of whats right@ \n",
            " your decision to head for the bright@ \n",
            " and whats more you may never# \n",
            " have picked the right horse# \n",
            " so youre lost and i havent a light@\n",
            "\n",
            "\n",
            "Total Loss: 3.300015687942505 | Context Loss: 0.0007108016288839281 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81251\n",
            "Total Loss: 2.929575204849243 | Context Loss: 0.0008002562099136412 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81252\n",
            "Total Loss: 2.7867627143859863 | Context Loss: 0.0007222532294690609 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81253\n",
            "Total Loss: 2.6172521114349365 | Context Loss: 0.0008713859133422375 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81254\n",
            "Total Loss: 2.7641334533691406 | Context Loss: 0.0007929301355034113 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81255\n",
            "Total Loss: 2.1008102893829346 | Context Loss: 0.0005267629167065024 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81256\n",
            "Total Loss: 3.133561611175537 | Context Loss: 0.0009771310724318027 | Rhyme Loss: 0.10677613351703631 \n",
            "Iteration number: 81257\n",
            "Total Loss: 2.6279380321502686 | Context Loss: 0.0006677115452475846 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81258\n",
            "Total Loss: 2.207998037338257 | Context Loss: 0.000858238257933408 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81259\n",
            "Total Loss: 2.8213891983032227 | Context Loss: 0.001231939299032092 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81260\n",
            "Total Loss: 2.7103488445281982 | Context Loss: 0.0008854892221279442 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81261\n",
            "Total Loss: 2.689520835876465 | Context Loss: 0.0005999516579322517 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81262\n",
            "Total Loss: 2.547995090484619 | Context Loss: 0.0007259203121066093 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81263\n",
            "Total Loss: 3.3384454250335693 | Context Loss: 0.0004984484985470772 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81264\n",
            "Total Loss: 3.3055524826049805 | Context Loss: 0.0005725430673919618 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81265\n",
            "Total Loss: 3.2450220584869385 | Context Loss: 0.0006935745477676392 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81266\n",
            "Total Loss: 2.1588728427886963 | Context Loss: 0.0007974471664056182 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81267\n",
            "Total Loss: 2.7444214820861816 | Context Loss: 0.0006809713086113334 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81268\n",
            "Total Loss: 2.9105935096740723 | Context Loss: 0.00064420560374856 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81269\n",
            "Total Loss: 3.2314682006835938 | Context Loss: 0.0009232965530827641 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81270\n",
            "Total Loss: 2.5703885555267334 | Context Loss: 0.0007881229976192117 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81271\n",
            "Total Loss: 3.8174681663513184 | Context Loss: 0.0007496298640035093 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81272\n",
            "Total Loss: 2.9250547885894775 | Context Loss: 0.0005956263048574328 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81273\n",
            "Total Loss: 2.963935375213623 | Context Loss: 0.00044734851690009236 | Rhyme Loss: 0.10677613351703631 \n",
            "Iteration number: 81274\n",
            "Total Loss: 3.375535488128662 | Context Loss: 0.0006458889110945165 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81275\n",
            "Total Loss: 2.1999528408050537 | Context Loss: 0.0007206809823401272 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81276\n",
            "Total Loss: 2.2269060611724854 | Context Loss: 0.0007853559800423682 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81277\n",
            "Total Loss: 2.6343777179718018 | Context Loss: 0.0006752582266926765 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81278\n",
            "Total Loss: 2.5106759071350098 | Context Loss: 0.0005525706801563501 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81279\n",
            "Total Loss: 2.4634549617767334 | Context Loss: 0.000780244532506913 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81280\n",
            "Total Loss: 2.7679812908172607 | Context Loss: 0.000548281183000654 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81281\n",
            "Total Loss: 2.0833725929260254 | Context Loss: 0.0006750466418452561 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81282\n",
            "Total Loss: 3.280245780944824 | Context Loss: 0.0007218694081529975 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 81283\n",
            "Total Loss: 2.32143235206604 | Context Loss: 0.0010212224442511797 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81284\n",
            "Total Loss: 1.8377176523208618 | Context Loss: 0.0008357665501534939 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81285\n",
            "Total Loss: 2.51713490486145 | Context Loss: 0.0006833826191723347 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81286\n",
            "Total Loss: 1.9190188646316528 | Context Loss: 0.000935738324187696 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81287\n",
            "Total Loss: 2.351487398147583 | Context Loss: 0.0006128123495727777 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81288\n",
            "Total Loss: 2.501417636871338 | Context Loss: 0.0004890715936198831 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81289\n",
            "Total Loss: 4.3792033195495605 | Context Loss: 0.0006821497227065265 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81290\n",
            "Total Loss: 2.751845121383667 | Context Loss: 0.0005002480465918779 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81291\n",
            "Total Loss: 2.5367519855499268 | Context Loss: 0.0009648400591686368 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81292\n",
            "Total Loss: 3.367913246154785 | Context Loss: 0.0006217968766577542 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81293\n",
            "Total Loss: 2.116131544113159 | Context Loss: 0.0005836616619490087 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81294\n",
            "Total Loss: 2.6312601566314697 | Context Loss: 0.0005884909187443554 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81295\n",
            "Total Loss: 2.1336395740509033 | Context Loss: 0.00045287495595403016 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81296\n",
            "Total Loss: 2.2253599166870117 | Context Loss: 0.0007893887814134359 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81297\n",
            "Total Loss: 2.795552968978882 | Context Loss: 0.000707412778865546 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81298\n",
            "Total Loss: 3.046800374984741 | Context Loss: 0.0009750897297635674 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81299\n",
            "Total Loss: 3.1805367469787598 | Context Loss: 0.0007709487108513713 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81300\n",
            "Total Loss: 2.5470263957977295 | Context Loss: 0.000667267944663763 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81301\n",
            "Total Loss: 2.9800071716308594 | Context Loss: 0.0006366206798702478 | Rhyme Loss: 0.10677613351703631 \n",
            "Iteration number: 81302\n",
            "Total Loss: 2.410595655441284 | Context Loss: 0.0006982141057960689 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81303\n",
            "Total Loss: 2.5610411167144775 | Context Loss: 0.0009989695390686393 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81304\n",
            "Total Loss: 2.7322585582733154 | Context Loss: 0.0006674703909084201 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81305\n",
            "Total Loss: 2.870234966278076 | Context Loss: 0.000689454551320523 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81306\n",
            "Total Loss: 2.5008747577667236 | Context Loss: 0.0005469612078741193 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81307\n",
            "Total Loss: 2.3395705223083496 | Context Loss: 0.0005580511060543358 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81308\n",
            "Total Loss: 2.918513536453247 | Context Loss: 0.0006508455844596028 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81309\n",
            "Total Loss: 2.1460275650024414 | Context Loss: 0.0006075134733691812 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81310\n",
            "Total Loss: 2.2612721920013428 | Context Loss: 0.0008561566937714815 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81311\n",
            "Total Loss: 2.36496901512146 | Context Loss: 0.0006899184081703424 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81312\n",
            "Total Loss: 2.126702070236206 | Context Loss: 0.0005701044574379921 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81313\n",
            "Total Loss: 3.8423912525177 | Context Loss: 0.0010820156894624233 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81314\n",
            "Total Loss: 3.2238028049468994 | Context Loss: 0.0005231855320744216 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 81315\n",
            "Total Loss: 2.820096254348755 | Context Loss: 0.0007280230056494474 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81316\n",
            "Total Loss: 3.4222021102905273 | Context Loss: 0.0004938268102705479 | Rhyme Loss: 0.4646745875734178 \n",
            "Iteration number: 81317\n",
            "Total Loss: 2.866635322570801 | Context Loss: 0.0005685864016413689 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81318\n",
            "Total Loss: 2.766970634460449 | Context Loss: 0.0005564077873714268 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81319\n",
            "Total Loss: 3.253887414932251 | Context Loss: 0.0005142756272107363 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81320\n",
            "Total Loss: 2.684563636779785 | Context Loss: 0.0005726065719500184 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81321\n",
            "Total Loss: 2.737456798553467 | Context Loss: 0.0008451123139820993 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81322\n",
            "Total Loss: 3.1668167114257812 | Context Loss: 0.0006368751637637615 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81323\n",
            "Total Loss: 2.753438711166382 | Context Loss: 0.0007986588170751929 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81324\n",
            "Total Loss: 2.978867292404175 | Context Loss: 0.0007540752412751317 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81325\n",
            "Total Loss: 2.254392623901367 | Context Loss: 0.0006722455727867782 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81326\n",
            "Total Loss: 2.722327947616577 | Context Loss: 0.0006584512302652001 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81327\n",
            "Total Loss: 2.9932236671447754 | Context Loss: 0.0007047730032354593 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81328\n",
            "Total Loss: 2.8352293968200684 | Context Loss: 0.0009358939132653177 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81329\n",
            "Total Loss: 2.9882333278656006 | Context Loss: 0.0005856076022610068 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81330\n",
            "Total Loss: 2.078993082046509 | Context Loss: 0.0005044274148531258 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81331\n",
            "Total Loss: 3.458460569381714 | Context Loss: 0.0007035626331344247 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81332\n",
            "Total Loss: 2.662682294845581 | Context Loss: 0.0006326282164081931 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81333\n",
            "Total Loss: 2.7135398387908936 | Context Loss: 0.0008963225409388542 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81334\n",
            "Total Loss: 2.4553799629211426 | Context Loss: 0.0006569675169885159 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81335\n",
            "Total Loss: 2.3803889751434326 | Context Loss: 0.0006525444914586842 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81336\n",
            "Total Loss: 2.868903160095215 | Context Loss: 0.0005573694361373782 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81337\n",
            "Total Loss: 2.4457156658172607 | Context Loss: 0.0010807935614138842 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 81338\n",
            "Total Loss: 2.6022000312805176 | Context Loss: 0.000678184034768492 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81339\n",
            "Total Loss: 2.89389705657959 | Context Loss: 0.0007544097024947405 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81340\n",
            "Total Loss: 2.5716590881347656 | Context Loss: 0.0007719477289356291 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81341\n",
            "Total Loss: 1.9095451831817627 | Context Loss: 0.0006703302497044206 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81342\n",
            "Total Loss: 2.48872971534729 | Context Loss: 0.0007727760239504278 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81343\n",
            "Total Loss: 2.2673544883728027 | Context Loss: 0.0006198048940859735 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81344\n",
            "Total Loss: 3.159116268157959 | Context Loss: 0.0008017009240575135 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81345\n",
            "Total Loss: 2.90162992477417 | Context Loss: 0.0005577921401709318 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81346\n",
            "Total Loss: 2.359435796737671 | Context Loss: 0.0008688019588589668 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81347\n",
            "Total Loss: 2.773259401321411 | Context Loss: 0.0007238783873617649 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81348\n",
            "Total Loss: 2.8546135425567627 | Context Loss: 0.0005659461603499949 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81349\n",
            "Total Loss: 2.593388795852661 | Context Loss: 0.0007960258517414331 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81350\n",
            "Total Loss: 2.404655694961548 | Context Loss: 0.0005255570285953581 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81351\n",
            "Total Loss: 2.8838541507720947 | Context Loss: 0.0005888444720767438 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81352\n",
            "Total Loss: 2.3987021446228027 | Context Loss: 0.0005140966968610883 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81353\n",
            "Total Loss: 2.9934754371643066 | Context Loss: 0.0007027930696494877 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81354\n",
            "Total Loss: 2.71950101852417 | Context Loss: 0.0006542477058246732 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81355\n",
            "Total Loss: 2.347874641418457 | Context Loss: 0.0008864249102771282 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81356\n",
            "Total Loss: 2.9881751537323 | Context Loss: 0.000817405350971967 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81357\n",
            "Total Loss: 2.803149461746216 | Context Loss: 0.0006623768713325262 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81358\n",
            "Total Loss: 3.0176146030426025 | Context Loss: 0.0005756576429121196 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81359\n",
            "Total Loss: 2.773592233657837 | Context Loss: 0.000624343752861023 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81360\n",
            "Total Loss: 2.1828296184539795 | Context Loss: 0.0006698452634736896 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81361\n",
            "Total Loss: 2.7087762355804443 | Context Loss: 0.0006988052628003061 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81362\n",
            "Total Loss: 2.6931838989257812 | Context Loss: 0.0006558746681548655 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81363\n",
            "Total Loss: 2.4081664085388184 | Context Loss: 0.0006008321070112288 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81364\n",
            "Total Loss: 2.3165197372436523 | Context Loss: 0.0006650494760833681 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81365\n",
            "Total Loss: 2.237919807434082 | Context Loss: 0.0007136642816476524 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81366\n",
            "Total Loss: 3.4910733699798584 | Context Loss: 0.0008297577151097357 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81367\n",
            "Total Loss: 2.5207676887512207 | Context Loss: 0.0005436833016574383 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81368\n",
            "Total Loss: 2.7115399837493896 | Context Loss: 0.0006830647471360862 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81369\n",
            "Total Loss: 3.4246833324432373 | Context Loss: 0.0007082711672410369 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81370\n",
            "Total Loss: 3.10953688621521 | Context Loss: 0.0007661232957616448 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81371\n",
            "Total Loss: 1.9589745998382568 | Context Loss: 0.0006288085714913905 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81372\n",
            "Total Loss: 2.279080390930176 | Context Loss: 0.0005041463300585747 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81373\n",
            "Total Loss: 2.30155873298645 | Context Loss: 0.0007748263305984437 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81374\n",
            "Total Loss: 2.4682276248931885 | Context Loss: 0.0008955057128332555 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81375\n",
            "Total Loss: 3.255722999572754 | Context Loss: 0.0005391935701481998 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81376\n",
            "Total Loss: 2.643378973007202 | Context Loss: 0.0007229344919323921 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81377\n",
            "Total Loss: 2.9374279975891113 | Context Loss: 0.0005825962871313095 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81378\n",
            "Total Loss: 3.038189172744751 | Context Loss: 0.000401462079025805 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81379\n",
            "Total Loss: 2.9001622200012207 | Context Loss: 0.0007941079675219953 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81380\n",
            "Total Loss: 2.7677156925201416 | Context Loss: 0.0005178118008188903 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81381\n",
            "Total Loss: 2.2131457328796387 | Context Loss: 0.0006574787548743188 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81382\n",
            "Total Loss: 3.0124568939208984 | Context Loss: 0.0006934532430022955 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81383\n",
            "Total Loss: 2.529872179031372 | Context Loss: 0.0005511639174073935 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81384\n",
            "Total Loss: 2.7988626956939697 | Context Loss: 0.0007059849449433386 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81385\n",
            "Total Loss: 2.722409963607788 | Context Loss: 0.000552002340555191 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81386\n",
            "Total Loss: 2.483933687210083 | Context Loss: 0.0007508070557378232 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81387\n",
            "Total Loss: 2.5819149017333984 | Context Loss: 0.0007599020609632134 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81388\n",
            "Total Loss: 3.1172568798065186 | Context Loss: 0.0004626658046618104 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81389\n",
            "Total Loss: 2.4186630249023438 | Context Loss: 0.00052161596249789 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81390\n",
            "Total Loss: 2.8874120712280273 | Context Loss: 0.0006576415617018938 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81391\n",
            "Total Loss: 2.0839757919311523 | Context Loss: 0.0007816397701390088 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81392\n",
            "Total Loss: 1.7821005582809448 | Context Loss: 0.0006688050925731659 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81393\n",
            "Total Loss: 2.7539219856262207 | Context Loss: 0.0006782468990422785 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81394\n",
            "Total Loss: 3.3437092304229736 | Context Loss: 0.0007132847094908357 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81395\n",
            "Total Loss: 2.7595200538635254 | Context Loss: 0.0006677702767774463 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81396\n",
            "Total Loss: 2.7465293407440186 | Context Loss: 0.0007964169490151107 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81397\n",
            "Total Loss: 2.459812879562378 | Context Loss: 0.000593953940551728 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81398\n",
            "Total Loss: 2.2781381607055664 | Context Loss: 0.0006574422586709261 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81399\n",
            "Total Loss: 3.071331262588501 | Context Loss: 0.000493954517878592 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81400\n",
            "Total Loss: 2.1530535221099854 | Context Loss: 0.0005703215720131993 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81401\n",
            "Total Loss: 2.258713960647583 | Context Loss: 0.0004916434991173446 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81402\n",
            "Total Loss: 2.234391450881958 | Context Loss: 0.0007092835148796439 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81403\n",
            "Total Loss: 2.756948709487915 | Context Loss: 0.0005446834838949144 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81404\n",
            "Total Loss: 3.151038408279419 | Context Loss: 0.0005435883067548275 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81405\n",
            "Total Loss: 3.005962610244751 | Context Loss: 0.000538922322448343 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81406\n",
            "Total Loss: 2.5957400798797607 | Context Loss: 0.0006993040442466736 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81407\n",
            "Total Loss: 2.1350808143615723 | Context Loss: 0.0006698461365886033 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81408\n",
            "Total Loss: 2.42757511138916 | Context Loss: 0.0005219448357820511 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81409\n",
            "Total Loss: 2.9626338481903076 | Context Loss: 0.0007088908459991217 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 81410\n",
            "Total Loss: 2.0842068195343018 | Context Loss: 0.0006348402821458876 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81411\n",
            "Total Loss: 2.317591905593872 | Context Loss: 0.0004297852283343673 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81412\n",
            "Total Loss: 3.221801280975342 | Context Loss: 0.0009400848066434264 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81413\n",
            "Total Loss: 2.0942978858947754 | Context Loss: 0.0006970455287955701 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81414\n",
            "Total Loss: 2.6548011302948 | Context Loss: 0.0010288171470165253 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81415\n",
            "Total Loss: 2.283487319946289 | Context Loss: 0.0007375637069344521 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81416\n",
            "Total Loss: 1.741042971611023 | Context Loss: 0.0005720558110624552 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81417\n",
            "Total Loss: 2.9539895057678223 | Context Loss: 0.0006055691628716886 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81418\n",
            "Total Loss: 2.4655351638793945 | Context Loss: 0.0008461474208161235 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81419\n",
            "Total Loss: 1.9383039474487305 | Context Loss: 0.000745257071685046 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81420\n",
            "Total Loss: 2.4551680088043213 | Context Loss: 0.0007569037843495607 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81421\n",
            "Total Loss: 2.7874014377593994 | Context Loss: 0.0007258353289216757 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81422\n",
            "Total Loss: 2.448761224746704 | Context Loss: 0.0006709518493153155 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81423\n",
            "Total Loss: 2.0198683738708496 | Context Loss: 0.0008364798268303275 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81424\n",
            "Total Loss: 2.7816829681396484 | Context Loss: 0.0005385384429246187 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81425\n",
            "Total Loss: 2.4197120666503906 | Context Loss: 0.000696918519679457 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81426\n",
            "Total Loss: 2.6884734630584717 | Context Loss: 0.0006393542280420661 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81427\n",
            "Total Loss: 4.428948402404785 | Context Loss: 0.0008290868136100471 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81428\n",
            "Total Loss: 3.803711414337158 | Context Loss: 0.0008220268646255136 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 81429\n",
            "Total Loss: 2.6009979248046875 | Context Loss: 0.0007838954334147274 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81430\n",
            "Total Loss: 2.583233594894409 | Context Loss: 0.0008969344198703766 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81431\n",
            "Total Loss: 2.924833297729492 | Context Loss: 0.0007680102135054767 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81432\n",
            "Total Loss: 2.3281123638153076 | Context Loss: 0.000668117543682456 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81433\n",
            "Total Loss: 1.9624112844467163 | Context Loss: 0.0005824623513035476 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81434\n",
            "Total Loss: 3.061253309249878 | Context Loss: 0.0007906570681370795 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81435\n",
            "Total Loss: 2.8311100006103516 | Context Loss: 0.0008515708614140749 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81436\n",
            "Total Loss: 2.668311357498169 | Context Loss: 0.0007409548852592707 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81437\n",
            "Total Loss: 2.486574411392212 | Context Loss: 0.0005633730324916542 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81438\n",
            "Total Loss: 3.3385274410247803 | Context Loss: 0.0004130057350266725 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81439\n",
            "Total Loss: 2.3119874000549316 | Context Loss: 0.0006046050693839788 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81440\n",
            "Total Loss: 2.92781400680542 | Context Loss: 0.0007180210668593645 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81441\n",
            "Total Loss: 2.4905953407287598 | Context Loss: 0.0006077458965592086 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81442\n",
            "Total Loss: 3.0186381340026855 | Context Loss: 0.0006510458770208061 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81443\n",
            "Total Loss: 2.6611955165863037 | Context Loss: 0.0006540067261084914 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81444\n",
            "Total Loss: 2.215394973754883 | Context Loss: 0.0006308285519480705 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81445\n",
            "Total Loss: 3.4094250202178955 | Context Loss: 0.000570502714253962 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81446\n",
            "Total Loss: 2.288274049758911 | Context Loss: 0.0006089748931117356 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81447\n",
            "Total Loss: 2.8943521976470947 | Context Loss: 0.000535807863343507 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81448\n",
            "Total Loss: 2.9907147884368896 | Context Loss: 0.0006825790042057633 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81449\n",
            "Total Loss: 2.374157428741455 | Context Loss: 0.0005180034204386175 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81450\n",
            "Total Loss: 3.222078800201416 | Context Loss: 0.0007602820405736566 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81451\n",
            "Total Loss: 2.71598744392395 | Context Loss: 0.0006140025216154754 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 81452\n",
            "Total Loss: 3.0138862133026123 | Context Loss: 0.0006220289506018162 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81453\n",
            "Total Loss: 2.2924201488494873 | Context Loss: 0.0013016301672905684 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81454\n",
            "Total Loss: 2.245046854019165 | Context Loss: 0.0006983693456277251 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81455\n",
            "Total Loss: 2.3979828357696533 | Context Loss: 0.0006292893085628748 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81456\n",
            "Total Loss: 2.3589870929718018 | Context Loss: 0.0006163388607092202 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81457\n",
            "Total Loss: 3.222912073135376 | Context Loss: 0.0006241397350095212 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81458\n",
            "Total Loss: 2.3889997005462646 | Context Loss: 0.0009689612779766321 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81459\n",
            "Total Loss: 2.4824607372283936 | Context Loss: 0.0005660451715812087 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81460\n",
            "Total Loss: 2.0157597064971924 | Context Loss: 0.0006859601708129048 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81461\n",
            "Total Loss: 2.067072629928589 | Context Loss: 0.0006972573464736342 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81462\n",
            "Total Loss: 2.93825364112854 | Context Loss: 0.0008908881573006511 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81463\n",
            "Total Loss: 1.877753496170044 | Context Loss: 0.0006031196098774672 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81464\n",
            "Total Loss: 2.1153879165649414 | Context Loss: 0.001255272189155221 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81465\n",
            "Total Loss: 2.3437583446502686 | Context Loss: 0.0007640095427632332 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81466\n",
            "Total Loss: 4.036491870880127 | Context Loss: 0.0005274458671920002 | Rhyme Loss: 0.5546530951346693 \n",
            "Iteration number: 81467\n",
            "Total Loss: 3.297868013381958 | Context Loss: 0.0007062245858833194 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81468\n",
            "Total Loss: 2.484926700592041 | Context Loss: 0.0005118962144479156 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81469\n",
            "Total Loss: 2.8377106189727783 | Context Loss: 0.00047732467646710575 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81470\n",
            "Total Loss: 2.6230111122131348 | Context Loss: 0.000626654305960983 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81471\n",
            "Total Loss: 2.327850818634033 | Context Loss: 0.0006631746655330062 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81472\n",
            "Total Loss: 2.2379262447357178 | Context Loss: 0.0006561853224411607 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81473\n",
            "Total Loss: 3.0796585083007812 | Context Loss: 0.0008768198313191533 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81474\n",
            "Total Loss: 2.331181287765503 | Context Loss: 0.000476329296361655 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81475\n",
            "Total Loss: 2.986046552658081 | Context Loss: 0.0006846325704827905 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81476\n",
            "Total Loss: 3.0845680236816406 | Context Loss: 0.0006227570702321827 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81477\n",
            "Total Loss: 2.174941062927246 | Context Loss: 0.0006979819154366851 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81478\n",
            "Total Loss: 2.6513428688049316 | Context Loss: 0.0006582362693734467 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81479\n",
            "Total Loss: 2.5294692516326904 | Context Loss: 0.0006320085958577693 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81480\n",
            "Total Loss: 2.2902371883392334 | Context Loss: 0.0007069073617458344 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81481\n",
            "Total Loss: 2.75849986076355 | Context Loss: 0.0005174303660169244 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81482\n",
            "Total Loss: 3.1637017726898193 | Context Loss: 0.0006602397770620883 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81483\n",
            "Total Loss: 2.1642799377441406 | Context Loss: 0.0004552117898128927 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81484\n",
            "Total Loss: 2.4680471420288086 | Context Loss: 0.0006077680154703557 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81485\n",
            "Total Loss: 2.7851152420043945 | Context Loss: 0.0007159581873565912 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81486\n",
            "Total Loss: 2.708230495452881 | Context Loss: 0.00047052279114723206 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81487\n",
            "Total Loss: 2.6143758296966553 | Context Loss: 0.0008561185677535832 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81488\n",
            "Total Loss: 2.3660154342651367 | Context Loss: 0.0008365965913981199 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81489\n",
            "Total Loss: 2.2939021587371826 | Context Loss: 0.0008819714421406388 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81490\n",
            "Total Loss: 2.6947014331817627 | Context Loss: 0.0005448521114885807 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81491\n",
            "Total Loss: 2.2423315048217773 | Context Loss: 0.0007868614047765732 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81492\n",
            "Total Loss: 3.481051206588745 | Context Loss: 0.0004926651017740369 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81493\n",
            "Total Loss: 2.2764968872070312 | Context Loss: 0.0009142711642198265 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81494\n",
            "Total Loss: 2.467135429382324 | Context Loss: 0.0006720857345499098 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81495\n",
            "Total Loss: 2.5224549770355225 | Context Loss: 0.0006642360240221024 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81496\n",
            "Total Loss: 3.1131134033203125 | Context Loss: 0.0005950555787421763 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81497\n",
            "Total Loss: 3.223341941833496 | Context Loss: 0.0006491903914138675 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81498\n",
            "Total Loss: 3.069512367248535 | Context Loss: 0.0005846003768965602 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81499\n",
            "Total Loss: 3.1919727325439453 | Context Loss: 0.0008851425955072045 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81500\n",
            "\n",
            "\n",
            " -- Iteration 81500 --\n",
            "0: he was called a big spender on the list@ \n",
            " for a mansion of chicago his hall@ \n",
            " was the place he would go# \n",
            " from his wife and his dough# \n",
            " and the way he got hitched to her will@\n",
            "\n",
            "\n",
            "1: my friend a deodecessor @ \n",
            " has a beautiful face with no stoops@ \n",
            " its a beauty so rare# \n",
            " though it makes me a bear# \n",
            " a deodecor is surely an oops@\n",
            "\n",
            "\n",
            "2: i was feeling quite sick in the main@ \n",
            " when i saw how i should have known@ \n",
            " how his car had run flat# \n",
            " his house had been that# \n",
            " and it wasnt the guy but his spiel@\n",
            "\n",
            "\n",
            "3: youll see many an ad thats been sent@ \n",
            " its a clear way to buy more and then spend@ \n",
            " while the price may be small# \n",
            " its just right  aint all that grand# \n",
            " when you get the thing done  dont you rest@\n",
            "\n",
            "\n",
            "4: an arab thats arabic and arabic@ \n",
            " theres a name for a man who is taranic@ \n",
            " and can say its quite fine# \n",
            " but ive heard it quite line# \n",
            " sir in a language like berlin@\n",
            "\n",
            "\n",
            "Total Loss: 2.303196907043457 | Context Loss: 0.0007225375156849623 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81501\n",
            "Total Loss: 4.224154949188232 | Context Loss: 0.0003469939110800624 | Rhyme Loss: 0.614470020807264 \n",
            "Iteration number: 81502\n",
            "Total Loss: 2.5897462368011475 | Context Loss: 0.0008611875819042325 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81503\n",
            "Total Loss: 2.6796693801879883 | Context Loss: 0.0007443861104547977 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81504\n",
            "Total Loss: 2.9139926433563232 | Context Loss: 0.0005314438603818417 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81505\n",
            "Total Loss: 2.384296178817749 | Context Loss: 0.0005187182105146348 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81506\n",
            "Total Loss: 2.1301989555358887 | Context Loss: 0.0006872981321066618 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81507\n",
            "Total Loss: 2.519808053970337 | Context Loss: 0.0006283316761255264 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81508\n",
            "Total Loss: 2.1320266723632812 | Context Loss: 0.0005932318745180964 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81509\n",
            "Total Loss: 2.6252706050872803 | Context Loss: 0.0005311956047080457 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81510\n",
            "Total Loss: 2.883531332015991 | Context Loss: 0.0005249031819403172 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81511\n",
            "Total Loss: 2.5644466876983643 | Context Loss: 0.0008977515390142798 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81512\n",
            "Total Loss: 2.6296331882476807 | Context Loss: 0.0005133686354383826 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81513\n",
            "Total Loss: 3.5121359825134277 | Context Loss: 0.0006878465646877885 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81514\n",
            "Total Loss: 3.1848745346069336 | Context Loss: 0.0007283544982783496 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81515\n",
            "Total Loss: 2.3326170444488525 | Context Loss: 0.0007990089361555874 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81516\n",
            "Total Loss: 2.4293196201324463 | Context Loss: 0.000589846633374691 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81517\n",
            "Total Loss: 2.940605878829956 | Context Loss: 0.0006883111200295389 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81518\n",
            "Total Loss: 2.5265331268310547 | Context Loss: 0.0005781460786238313 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81519\n",
            "Total Loss: 2.93965220451355 | Context Loss: 0.000713768822606653 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81520\n",
            "Total Loss: 2.592015027999878 | Context Loss: 0.0006291321478784084 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81521\n",
            "Total Loss: 2.3745739459991455 | Context Loss: 0.0005546244792640209 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81522\n",
            "Total Loss: 2.7318506240844727 | Context Loss: 0.0010100086219608784 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81523\n",
            "Total Loss: 2.747424840927124 | Context Loss: 0.0005702227354049683 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81524\n",
            "Total Loss: 2.730344772338867 | Context Loss: 0.0005006529972888529 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81525\n",
            "Total Loss: 2.5611960887908936 | Context Loss: 0.0009306707652285695 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81526\n",
            "Total Loss: 2.5045995712280273 | Context Loss: 0.0006443404708988965 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81527\n",
            "Total Loss: 2.7285077571868896 | Context Loss: 0.0006845358293503523 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81528\n",
            "Total Loss: 2.2544777393341064 | Context Loss: 0.0009258079808205366 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81529\n",
            "Total Loss: 2.8112425804138184 | Context Loss: 0.0008823506650514901 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81530\n",
            "Total Loss: 2.7499513626098633 | Context Loss: 0.0009310052264481783 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81531\n",
            "Total Loss: 2.337409496307373 | Context Loss: 0.0007685993332415819 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81532\n",
            "Total Loss: 2.773972511291504 | Context Loss: 0.0005385432159528136 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81533\n",
            "Total Loss: 2.622013568878174 | Context Loss: 0.0005259161116555333 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81534\n",
            "Total Loss: 2.4034953117370605 | Context Loss: 0.0007376226712949574 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 81535\n",
            "Total Loss: 2.3122847080230713 | Context Loss: 0.0007456421735696495 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81536\n",
            "Total Loss: 2.853511095046997 | Context Loss: 0.0005906872684136033 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81537\n",
            "Total Loss: 2.5266571044921875 | Context Loss: 0.0008211206295527518 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81538\n",
            "Total Loss: 3.8512277603149414 | Context Loss: 0.0008246314246207476 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81539\n",
            "Total Loss: 2.5172202587127686 | Context Loss: 0.0006331558106467128 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81540\n",
            "Total Loss: 2.1980910301208496 | Context Loss: 0.001179438317194581 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81541\n",
            "Total Loss: 2.5972704887390137 | Context Loss: 0.0005427604774013162 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81542\n",
            "Total Loss: 2.693241834640503 | Context Loss: 0.000778986606746912 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81543\n",
            "Total Loss: 2.384763479232788 | Context Loss: 0.0006337164668366313 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81544\n",
            "Total Loss: 2.9014832973480225 | Context Loss: 0.0005748222465626895 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81545\n",
            "Total Loss: 2.577955722808838 | Context Loss: 0.0006401548744179308 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81546\n",
            "Total Loss: 2.207886219024658 | Context Loss: 0.0005330705898813903 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81547\n",
            "Total Loss: 3.423631191253662 | Context Loss: 0.0005986133473925292 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81548\n",
            "Total Loss: 2.9730513095855713 | Context Loss: 0.0006639718194492161 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 81549\n",
            "Total Loss: 2.7452526092529297 | Context Loss: 0.0004652849165722728 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81550\n",
            "Total Loss: 2.0730366706848145 | Context Loss: 0.0006206002435646951 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81551\n",
            "Total Loss: 3.1315255165100098 | Context Loss: 0.0005000537494197488 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 81552\n",
            "Total Loss: 2.631835460662842 | Context Loss: 0.0007342897588387132 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81553\n",
            "Total Loss: 1.7832980155944824 | Context Loss: 0.0008837852510623634 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81554\n",
            "Total Loss: 1.9753226041793823 | Context Loss: 0.0006849061464890838 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81555\n",
            "Total Loss: 2.403198480606079 | Context Loss: 0.0009468373609706759 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81556\n",
            "Total Loss: 4.020216941833496 | Context Loss: 0.0006010287906974554 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81557\n",
            "Total Loss: 3.0918970108032227 | Context Loss: 0.00074662925908342 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81558\n",
            "Total Loss: 2.622291088104248 | Context Loss: 0.0007885079830884933 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81559\n",
            "Total Loss: 2.9696285724639893 | Context Loss: 0.0008429231238551438 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81560\n",
            "Total Loss: 2.3509347438812256 | Context Loss: 0.000642207742203027 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81561\n",
            "Total Loss: 2.9773852825164795 | Context Loss: 0.0008178108255378902 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81562\n",
            "Total Loss: 2.0852646827697754 | Context Loss: 0.000519914086908102 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81563\n",
            "Total Loss: 2.417121171951294 | Context Loss: 0.0006734011112712324 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81564\n",
            "Total Loss: 2.495560884475708 | Context Loss: 0.0008826354751363397 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81565\n",
            "Total Loss: 2.6483123302459717 | Context Loss: 0.0006295117782428861 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81566\n",
            "Total Loss: 3.053494453430176 | Context Loss: 0.0005309095722623169 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81567\n",
            "Total Loss: 2.2130000591278076 | Context Loss: 0.0006762093398720026 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81568\n",
            "Total Loss: 3.3784852027893066 | Context Loss: 0.0005386628909036517 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81569\n",
            "Total Loss: 2.396064519882202 | Context Loss: 0.0007450659177266061 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81570\n",
            "Total Loss: 2.8109610080718994 | Context Loss: 0.000636911834590137 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81571\n",
            "Total Loss: 2.76882266998291 | Context Loss: 0.0005441842367872596 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81572\n",
            "Total Loss: 3.048236608505249 | Context Loss: 0.0006096859578974545 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81573\n",
            "Total Loss: 3.1767261028289795 | Context Loss: 0.0005313733126968145 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81574\n",
            "Total Loss: 4.026359558105469 | Context Loss: 0.0008650484960526228 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81575\n",
            "Total Loss: 2.5848076343536377 | Context Loss: 0.0007657438982278109 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81576\n",
            "Total Loss: 2.794973373413086 | Context Loss: 0.0008917085942812264 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81577\n",
            "Total Loss: 2.665524959564209 | Context Loss: 0.0005835614865645766 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81578\n",
            "Total Loss: 2.330078601837158 | Context Loss: 0.0006072744727134705 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81579\n",
            "Total Loss: 3.441009521484375 | Context Loss: 0.000626013264991343 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81580\n",
            "Total Loss: 2.910295009613037 | Context Loss: 0.0008573314407840371 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81581\n",
            "Total Loss: 2.9553871154785156 | Context Loss: 0.0006701562087982893 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81582\n",
            "Total Loss: 2.1473867893218994 | Context Loss: 0.0006282735848799348 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81583\n",
            "Total Loss: 2.8620784282684326 | Context Loss: 0.0008790093124844134 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81584\n",
            "Total Loss: 2.7816925048828125 | Context Loss: 0.0006751627661287785 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81585\n",
            "Total Loss: 2.5860016345977783 | Context Loss: 0.0006215391331352293 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81586\n",
            "Total Loss: 2.393122673034668 | Context Loss: 0.0007112360908649862 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81587\n",
            "Total Loss: 2.404850721359253 | Context Loss: 0.0007566738640889525 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81588\n",
            "Total Loss: 2.8705174922943115 | Context Loss: 0.0006982945487834513 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81589\n",
            "Total Loss: 2.9368155002593994 | Context Loss: 0.0007249035406857729 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81590\n",
            "Total Loss: 2.847439765930176 | Context Loss: 0.0007576820207759738 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81591\n",
            "Total Loss: 2.5827598571777344 | Context Loss: 0.0007282864535227418 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81592\n",
            "Total Loss: 2.838852643966675 | Context Loss: 0.0006286618881858885 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81593\n",
            "Total Loss: 2.661633014678955 | Context Loss: 0.0005649630329571664 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81594\n",
            "Total Loss: 2.291553497314453 | Context Loss: 0.0005278582102619112 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81595\n",
            "Total Loss: 2.049562931060791 | Context Loss: 0.000614470336586237 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81596\n",
            "Total Loss: 2.468721628189087 | Context Loss: 0.0006613089935854077 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81597\n",
            "Total Loss: 2.2079124450683594 | Context Loss: 0.0005133264348842204 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81598\n",
            "Total Loss: 2.2546448707580566 | Context Loss: 0.0005904393037781119 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81599\n",
            "Total Loss: 2.568406105041504 | Context Loss: 0.00046746732550673187 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81600\n",
            "Total Loss: 2.360261917114258 | Context Loss: 0.0006368529284372926 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81601\n",
            "Total Loss: 3.097313404083252 | Context Loss: 0.0005047994200140238 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81602\n",
            "Total Loss: 3.1358134746551514 | Context Loss: 0.0006987706292420626 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81603\n",
            "Total Loss: 2.2656636238098145 | Context Loss: 0.0007296768017113209 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81604\n",
            "Total Loss: 2.1806750297546387 | Context Loss: 0.0006165284430608153 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81605\n",
            "Total Loss: 2.716245412826538 | Context Loss: 0.0008531073690392077 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81606\n",
            "Total Loss: 2.4474196434020996 | Context Loss: 0.0006798387039452791 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81607\n",
            "Total Loss: 2.3992199897766113 | Context Loss: 0.000664372812025249 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81608\n",
            "Total Loss: 2.6090173721313477 | Context Loss: 0.000718277005944401 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81609\n",
            "Total Loss: 2.549957752227783 | Context Loss: 0.0007974205072969198 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81610\n",
            "Total Loss: 2.6624538898468018 | Context Loss: 0.000538456893991679 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81611\n",
            "Total Loss: 2.474187135696411 | Context Loss: 0.0005810374859720469 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81612\n",
            "Total Loss: 2.3591666221618652 | Context Loss: 0.0006166719831526279 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81613\n",
            "Total Loss: 3.0140860080718994 | Context Loss: 0.000575703103095293 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81614\n",
            "Total Loss: 2.2098991870880127 | Context Loss: 0.00051974254893139 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81615\n",
            "Total Loss: 2.3322925567626953 | Context Loss: 0.0007907241815701127 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81616\n",
            "Total Loss: 2.880659580230713 | Context Loss: 0.0005802582018077374 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81617\n",
            "Total Loss: 3.872114896774292 | Context Loss: 0.0006545312353409827 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81618\n",
            "Total Loss: 3.1726951599121094 | Context Loss: 0.0005127351032570004 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81619\n",
            "Total Loss: 2.6982882022857666 | Context Loss: 0.0005605260957963765 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81620\n",
            "Total Loss: 2.030819892883301 | Context Loss: 0.0007659343536943197 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81621\n",
            "Total Loss: 2.5678462982177734 | Context Loss: 0.0006611960707232356 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81622\n",
            "Total Loss: 3.118338108062744 | Context Loss: 0.0006512913969345391 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81623\n",
            "Total Loss: 3.1642343997955322 | Context Loss: 0.000622917665168643 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81624\n",
            "Total Loss: 1.8242214918136597 | Context Loss: 0.000727054663002491 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81625\n",
            "Total Loss: 2.5529870986938477 | Context Loss: 0.000908556510694325 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81626\n",
            "Total Loss: 2.8819761276245117 | Context Loss: 0.0006008858326822519 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81627\n",
            "Total Loss: 2.714426040649414 | Context Loss: 0.0007369383820332587 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 81628\n",
            "Total Loss: 2.797266960144043 | Context Loss: 0.0006220217910595238 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81629\n",
            "Total Loss: 2.3362696170806885 | Context Loss: 0.0006389786722138524 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81630\n",
            "Total Loss: 2.590141534805298 | Context Loss: 0.000626427005045116 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81631\n",
            "Total Loss: 2.4473211765289307 | Context Loss: 0.0010405092034488916 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81632\n",
            "Total Loss: 2.7134053707122803 | Context Loss: 0.0005061800475232303 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81633\n",
            "Total Loss: 2.5300090312957764 | Context Loss: 0.0011556772515177727 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81634\n",
            "Total Loss: 3.1057796478271484 | Context Loss: 0.0005240420578047633 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81635\n",
            "Total Loss: 3.007995128631592 | Context Loss: 0.0008146717445924878 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81636\n",
            "Total Loss: 2.7645316123962402 | Context Loss: 0.0009341697441413999 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81637\n",
            "Total Loss: 2.059516429901123 | Context Loss: 0.0007302690646611154 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81638\n",
            "Total Loss: 2.0184550285339355 | Context Loss: 0.0007068933919072151 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81639\n",
            "Total Loss: 2.608279228210449 | Context Loss: 0.00048155186232179403 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81640\n",
            "Total Loss: 2.562405824661255 | Context Loss: 0.0006400658749043941 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81641\n",
            "Total Loss: 2.3436079025268555 | Context Loss: 0.0005884917918592691 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81642\n",
            "Total Loss: 2.1800739765167236 | Context Loss: 0.0007785935886204243 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81643\n",
            "Total Loss: 2.7106709480285645 | Context Loss: 0.0006467205239459872 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81644\n",
            "Total Loss: 2.054668664932251 | Context Loss: 0.0006139944307506084 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81645\n",
            "Total Loss: 2.2752346992492676 | Context Loss: 0.0007459440384991467 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81646\n",
            "Total Loss: 3.045137405395508 | Context Loss: 0.0006129222456365824 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81647\n",
            "Total Loss: 3.016796350479126 | Context Loss: 0.0005529641639441252 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 81648\n",
            "Total Loss: 2.9658260345458984 | Context Loss: 0.0006306296563707292 | Rhyme Loss: 0.4646745875734178 \n",
            "Iteration number: 81649\n",
            "Total Loss: 2.1107418537139893 | Context Loss: 0.0007276034448295832 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81650\n",
            "Total Loss: 2.37619948387146 | Context Loss: 0.0008098669932223856 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81651\n",
            "Total Loss: 2.561182737350464 | Context Loss: 0.0006879502907395363 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81652\n",
            "Total Loss: 2.4639406204223633 | Context Loss: 0.000909638125449419 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81653\n",
            "Total Loss: 2.5926971435546875 | Context Loss: 0.0005684794159606099 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81654\n",
            "Total Loss: 2.776698350906372 | Context Loss: 0.0004324268957134336 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81655\n",
            "Total Loss: 2.7687246799468994 | Context Loss: 0.0006181859062053263 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81656\n",
            "Total Loss: 2.6117818355560303 | Context Loss: 0.0006488075596280396 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81657\n",
            "Total Loss: 4.443559646606445 | Context Loss: 0.0004372353432700038 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81658\n",
            "Total Loss: 2.5174410343170166 | Context Loss: 0.0009230959694832563 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81659\n",
            "Total Loss: 2.872281789779663 | Context Loss: 0.0005078582908026874 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81660\n",
            "Total Loss: 2.2862517833709717 | Context Loss: 0.0007101902738213539 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81661\n",
            "Total Loss: 2.561183452606201 | Context Loss: 0.0006745184073224664 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81662\n",
            "Total Loss: 2.935227155685425 | Context Loss: 0.0005985551979392767 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81663\n",
            "Total Loss: 3.582444190979004 | Context Loss: 0.0005871735629625618 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81664\n",
            "Total Loss: 2.3063607215881348 | Context Loss: 0.0008277095621451735 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81665\n",
            "Total Loss: 2.999647378921509 | Context Loss: 0.0008072520140558481 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81666\n",
            "Total Loss: 2.9672768115997314 | Context Loss: 0.0005129071068949997 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81667\n",
            "Total Loss: 2.605613946914673 | Context Loss: 0.0006886094342917204 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81668\n",
            "Total Loss: 2.7061047554016113 | Context Loss: 0.0006773973000235856 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81669\n",
            "Total Loss: 4.277831077575684 | Context Loss: 0.0006025651819072664 | Rhyme Loss: 0.43501924378948015 \n",
            "Iteration number: 81670\n",
            "Total Loss: 2.347747802734375 | Context Loss: 0.0007840921171009541 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81671\n",
            "Total Loss: 2.1210179328918457 | Context Loss: 0.0006164949154481292 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81672\n",
            "Total Loss: 2.892414093017578 | Context Loss: 0.0006045322516001761 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81673\n",
            "Total Loss: 2.633875846862793 | Context Loss: 0.000689381908159703 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81674\n",
            "Total Loss: 3.007465124130249 | Context Loss: 0.0009885717881843448 | Rhyme Loss: 0.5546530951346693 \n",
            "Iteration number: 81675\n",
            "Total Loss: 2.745523452758789 | Context Loss: 0.0007608199957758188 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81676\n",
            "Total Loss: 2.6502645015716553 | Context Loss: 0.0007391583058051765 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81677\n",
            "Total Loss: 2.8680062294006348 | Context Loss: 0.0009916063863784075 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81678\n",
            "Total Loss: 2.7086522579193115 | Context Loss: 0.000645183608867228 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81679\n",
            "Total Loss: 2.5256741046905518 | Context Loss: 0.0008110953494906425 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81680\n",
            "Total Loss: 3.1302998065948486 | Context Loss: 0.0007443409413099289 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81681\n",
            "Total Loss: 2.799882650375366 | Context Loss: 0.0006475064437836409 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 81682\n",
            "Total Loss: 2.3526089191436768 | Context Loss: 0.0005590986693277955 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81683\n",
            "Total Loss: 2.059443235397339 | Context Loss: 0.0010851228144019842 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81684\n",
            "Total Loss: 2.2311604022979736 | Context Loss: 0.0007894804002717137 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81685\n",
            "Total Loss: 3.0336787700653076 | Context Loss: 0.0007139898370951414 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81686\n",
            "Total Loss: 2.7394912242889404 | Context Loss: 0.0007817636360414326 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81687\n",
            "Total Loss: 3.0534582138061523 | Context Loss: 0.0006251039449125528 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81688\n",
            "Total Loss: 2.3895726203918457 | Context Loss: 0.0009888883214443922 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81689\n",
            "Total Loss: 2.968961715698242 | Context Loss: 0.0006962643237784505 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81690\n",
            "Total Loss: 3.288053512573242 | Context Loss: 0.0006499695591628551 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81691\n",
            "Total Loss: 3.1257801055908203 | Context Loss: 0.0005533589865081012 | Rhyme Loss: 0.43501924378948015 \n",
            "Iteration number: 81692\n",
            "Total Loss: 2.6482763290405273 | Context Loss: 0.0007118431967683136 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 81693\n",
            "Total Loss: 3.0378971099853516 | Context Loss: 0.000566706177778542 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81694\n",
            "Total Loss: 2.4197139739990234 | Context Loss: 0.0009105115314014256 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81695\n",
            "Total Loss: 2.437513828277588 | Context Loss: 0.0005925088771618903 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81696\n",
            "Total Loss: 3.1674857139587402 | Context Loss: 0.0005838620127178729 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81697\n",
            "Total Loss: 2.561920166015625 | Context Loss: 0.0006211403524503112 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81698\n",
            "Total Loss: 3.1750128269195557 | Context Loss: 0.0005190238589420915 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81699\n",
            "Total Loss: 3.217499256134033 | Context Loss: 0.0006094351410865784 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81700\n",
            "Total Loss: 2.1958937644958496 | Context Loss: 0.0007383718620985746 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81701\n",
            "Total Loss: 3.1289687156677246 | Context Loss: 0.0006712976610288024 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81702\n",
            "Total Loss: 2.9472148418426514 | Context Loss: 0.0013013581046834588 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81703\n",
            "Total Loss: 2.884990692138672 | Context Loss: 0.0008253759588114917 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81704\n",
            "Total Loss: 2.3455710411071777 | Context Loss: 0.00071357237175107 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81705\n",
            "Total Loss: 2.4788849353790283 | Context Loss: 0.0006500741001218557 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81706\n",
            "Total Loss: 2.496260404586792 | Context Loss: 0.0006933989352546632 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81707\n",
            "Total Loss: 2.9826507568359375 | Context Loss: 0.0007744303438812494 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81708\n",
            "Total Loss: 2.9946231842041016 | Context Loss: 0.0006398034747689962 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81709\n",
            "Total Loss: 2.1671626567840576 | Context Loss: 0.0008637972641736269 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81710\n",
            "Total Loss: 2.172912836074829 | Context Loss: 0.0008391953306272626 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81711\n",
            "Total Loss: 2.4493021965026855 | Context Loss: 0.0007578627555631101 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81712\n",
            "Total Loss: 2.411634683609009 | Context Loss: 0.0007810916285961866 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81713\n",
            "Total Loss: 2.7969400882720947 | Context Loss: 0.000691964931320399 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81714\n",
            "Total Loss: 2.3180489540100098 | Context Loss: 0.0006876927800476551 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81715\n",
            "Total Loss: 3.315110445022583 | Context Loss: 0.0005903528071939945 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81716\n",
            "Total Loss: 4.200128078460693 | Context Loss: 0.00044434069423004985 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81717\n",
            "Total Loss: 2.1568360328674316 | Context Loss: 0.0006163939833641052 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81718\n",
            "Total Loss: 2.5490381717681885 | Context Loss: 0.000875182100571692 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81719\n",
            "Total Loss: 2.909238815307617 | Context Loss: 0.0005206468049436808 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81720\n",
            "Total Loss: 2.3379065990448 | Context Loss: 0.0007891395944170654 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81721\n",
            "Total Loss: 2.7533867359161377 | Context Loss: 0.0008319381158798933 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81722\n",
            "Total Loss: 2.364912271499634 | Context Loss: 0.000676007941365242 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81723\n",
            "Total Loss: 2.5297398567199707 | Context Loss: 0.0006488438230007887 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81724\n",
            "Total Loss: 2.342294216156006 | Context Loss: 0.0006748060695827007 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81725\n",
            "Total Loss: 2.768263578414917 | Context Loss: 0.0006419038400053978 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81726\n",
            "Total Loss: 2.620434045791626 | Context Loss: 0.0006282266695052385 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81727\n",
            "Total Loss: 2.125370502471924 | Context Loss: 0.0013056501047685742 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81728\n",
            "Total Loss: 2.786001682281494 | Context Loss: 0.0006566205993294716 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81729\n",
            "Total Loss: 2.7317802906036377 | Context Loss: 0.000626873632427305 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81730\n",
            "Total Loss: 3.245082378387451 | Context Loss: 0.000817009131424129 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81731\n",
            "Total Loss: 3.041621446609497 | Context Loss: 0.0007162062684074044 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81732\n",
            "Total Loss: 2.4637668132781982 | Context Loss: 0.0006265778210945427 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81733\n",
            "Total Loss: 2.8534903526306152 | Context Loss: 0.0006635984173044562 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81734\n",
            "Total Loss: 3.2387349605560303 | Context Loss: 0.000716714421287179 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81735\n",
            "Total Loss: 2.819716453552246 | Context Loss: 0.0006028525531291962 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81736\n",
            "Total Loss: 2.6605536937713623 | Context Loss: 0.000491326383780688 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81737\n",
            "Total Loss: 2.3669705390930176 | Context Loss: 0.000653239490929991 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81738\n",
            "Total Loss: 2.774324417114258 | Context Loss: 0.0006757114315405488 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81739\n",
            "Total Loss: 2.569988250732422 | Context Loss: 0.0010021019261330366 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81740\n",
            "Total Loss: 2.618192195892334 | Context Loss: 0.000577732571400702 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81741\n",
            "Total Loss: 1.8640729188919067 | Context Loss: 0.0007286324398592114 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81742\n",
            "Total Loss: 2.2042877674102783 | Context Loss: 0.0007026070961728692 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81743\n",
            "Total Loss: 2.6274526119232178 | Context Loss: 0.0008003119146451354 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81744\n",
            "Total Loss: 3.0986459255218506 | Context Loss: 0.0006285784766077995 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81745\n",
            "Total Loss: 2.323580265045166 | Context Loss: 0.0006996036390773952 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81746\n",
            "Total Loss: 3.1914992332458496 | Context Loss: 0.0005991670186631382 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81747\n",
            "Total Loss: 1.7968802452087402 | Context Loss: 0.0010826962534338236 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81748\n",
            "Total Loss: 2.9213621616363525 | Context Loss: 0.0006529942620545626 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81749\n",
            "Total Loss: 2.3006081581115723 | Context Loss: 0.0006093173869885504 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81750\n",
            "\n",
            "\n",
            " -- Iteration 81750 --\n",
            "0: weve set on the stage and have planned@ \n",
            " a large show this past friday and im done@ \n",
            " well be playing a game# \n",
            " with a guy with a claim# \n",
            " to our bankroll well call it a scott@\n",
            "\n",
            "\n",
            "1: for a while we were both still as a pair@ \n",
            " of young lads at the track heres the scene@ \n",
            " he was wearing a hat# \n",
            " when a big fat red rat# \n",
            " brought a look thats a rat to her eye@\n",
            "\n",
            "\n",
            "2: in her bed with the girls in a rush@ \n",
            " is kate feeling stressed  she must brush@ \n",
            " at the guys who are fattening# \n",
            " and the girls who are bleasing# \n",
            " and guys who are eating their hash@\n",
            "\n",
            "\n",
            "3: we were playing the bong hit of a bird@ \n",
            " then the bird struck an elephant  well@ \n",
            " we were left in our abode# \n",
            " it sounds bizarre and so old# \n",
            " so we thought we were better off dead@\n",
            "\n",
            "\n",
            "4: the churchs head of state was a bore@ \n",
            " now he says the churchs got a war@ \n",
            " now theyre both in the news# \n",
            " and are both in their blues# \n",
            " and it took them to get things back up there@\n",
            "\n",
            "\n",
            "Total Loss: 2.655367374420166 | Context Loss: 0.0006512313848361373 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81751\n",
            "Total Loss: 2.465667486190796 | Context Loss: 0.0007507745176553726 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81752\n",
            "Total Loss: 2.710798501968384 | Context Loss: 0.0007502528605982661 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81753\n",
            "Total Loss: 1.7242140769958496 | Context Loss: 0.0007587452419102192 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81754\n",
            "Total Loss: 2.357201337814331 | Context Loss: 0.0005890362081117928 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81755\n",
            "Total Loss: 2.4648396968841553 | Context Loss: 0.0005980179412290454 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81756\n",
            "Total Loss: 3.0517215728759766 | Context Loss: 0.0004964219988323748 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81757\n",
            "Total Loss: 2.662602186203003 | Context Loss: 0.0006963668274693191 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81758\n",
            "Total Loss: 2.035013198852539 | Context Loss: 0.0006670454749837518 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81759\n",
            "Total Loss: 3.0322611331939697 | Context Loss: 0.0005811684532091022 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81760\n",
            "Total Loss: 2.7279937267303467 | Context Loss: 0.0006688018329441547 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81761\n",
            "Total Loss: 3.042116165161133 | Context Loss: 0.0008051380282267928 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81762\n",
            "Total Loss: 2.7932372093200684 | Context Loss: 0.0005888846353627741 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81763\n",
            "Total Loss: 2.6361639499664307 | Context Loss: 0.0008276602020487189 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81764\n",
            "Total Loss: 2.1068897247314453 | Context Loss: 0.000692985369823873 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81765\n",
            "Total Loss: 3.041728973388672 | Context Loss: 0.0005651716492138803 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81766\n",
            "Total Loss: 2.743262529373169 | Context Loss: 0.0007391722174361348 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81767\n",
            "Total Loss: 2.546617031097412 | Context Loss: 0.0006303199334070086 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81768\n",
            "Total Loss: 2.36938738822937 | Context Loss: 0.0007530749426223338 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81769\n",
            "Total Loss: 2.4427475929260254 | Context Loss: 0.0006604865775443614 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81770\n",
            "Total Loss: 2.777311086654663 | Context Loss: 0.0007365016499534249 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81771\n",
            "Total Loss: 2.013350486755371 | Context Loss: 0.0004492760053835809 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81772\n",
            "Total Loss: 2.643436908721924 | Context Loss: 0.0005554580711759627 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81773\n",
            "Total Loss: 2.35150408744812 | Context Loss: 0.0008382447995245457 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81774\n",
            "Total Loss: 2.3630664348602295 | Context Loss: 0.0007756561390124261 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81775\n",
            "Total Loss: 3.206059455871582 | Context Loss: 0.0005945049924775958 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81776\n",
            "Total Loss: 2.4268791675567627 | Context Loss: 0.0005999492132104933 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81777\n",
            "Total Loss: 2.2803494930267334 | Context Loss: 0.0008319745538756251 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81778\n",
            "Total Loss: 2.662510871887207 | Context Loss: 0.0008129638154059649 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81779\n",
            "Total Loss: 3.1015820503234863 | Context Loss: 0.0006523516494780779 | Rhyme Loss: 0.10677613351703631 \n",
            "Iteration number: 81780\n",
            "Total Loss: 2.5308566093444824 | Context Loss: 0.000647597189527005 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81781\n",
            "Total Loss: 2.496471405029297 | Context Loss: 0.0006577615858986974 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81782\n",
            "Total Loss: 3.3226640224456787 | Context Loss: 0.000615414057392627 | Rhyme Loss: 0.4646745875734178 \n",
            "Iteration number: 81783\n",
            "Total Loss: 2.2878944873809814 | Context Loss: 0.0006834760424681008 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81784\n",
            "Total Loss: 2.7865614891052246 | Context Loss: 0.0007703385199420154 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81785\n",
            "Total Loss: 3.0161044597625732 | Context Loss: 0.00048029227764345706 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81786\n",
            "Total Loss: 2.3330726623535156 | Context Loss: 0.0006130159017629921 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81787\n",
            "Total Loss: 2.856656074523926 | Context Loss: 0.0005708169192075729 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81788\n",
            "Total Loss: 2.8312416076660156 | Context Loss: 0.0005747380782850087 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81789\n",
            "Total Loss: 3.2495856285095215 | Context Loss: 0.000546545721590519 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81790\n",
            "Total Loss: 2.1055448055267334 | Context Loss: 0.0007470761775039136 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81791\n",
            "Total Loss: 2.101142406463623 | Context Loss: 0.0008265498327091336 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81792\n",
            "Total Loss: 2.6802384853363037 | Context Loss: 0.0007001226767897606 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81793\n",
            "Total Loss: 2.423224449157715 | Context Loss: 0.0005863827536813915 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81794\n",
            "Total Loss: 2.3508141040802 | Context Loss: 0.0006201148498803377 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81795\n",
            "Total Loss: 2.374260187149048 | Context Loss: 0.0008539680857211351 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81796\n",
            "Total Loss: 3.333712339401245 | Context Loss: 0.0007850592955946922 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81797\n",
            "Total Loss: 2.8042049407958984 | Context Loss: 0.0006080117891542614 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81798\n",
            "Total Loss: 2.4906933307647705 | Context Loss: 0.0007175892824307084 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81799\n",
            "Total Loss: 3.160221815109253 | Context Loss: 0.0005955689703114331 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81800\n",
            "Total Loss: 2.552694320678711 | Context Loss: 0.0005023136036470532 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81801\n",
            "Total Loss: 2.44600510597229 | Context Loss: 0.0007405015639960766 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81802\n",
            "Total Loss: 2.8783085346221924 | Context Loss: 0.0006371631170623004 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81803\n",
            "Total Loss: 2.2418627738952637 | Context Loss: 0.0007559944642707705 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81804\n",
            "Total Loss: 2.437467098236084 | Context Loss: 0.0006539925234392285 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81805\n",
            "Total Loss: 2.8104710578918457 | Context Loss: 0.0007870456902310252 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81806\n",
            "Total Loss: 1.8837970495224 | Context Loss: 0.000992213492281735 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81807\n",
            "Total Loss: 2.3527534008026123 | Context Loss: 0.0006322698900476098 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81808\n",
            "Total Loss: 2.6568992137908936 | Context Loss: 0.0006020944565534592 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81809\n",
            "Total Loss: 2.8734824657440186 | Context Loss: 0.0005887284642085433 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81810\n",
            "Total Loss: 2.466111898422241 | Context Loss: 0.0006626645335927606 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81811\n",
            "Total Loss: 2.4127285480499268 | Context Loss: 0.0009575462900102139 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81812\n",
            "Total Loss: 2.767627716064453 | Context Loss: 0.0008988757617771626 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81813\n",
            "Total Loss: 2.6393849849700928 | Context Loss: 0.0009827661560848355 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81814\n",
            "Total Loss: 3.1489617824554443 | Context Loss: 0.0007930059218779206 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 81815\n",
            "Total Loss: 3.133143663406372 | Context Loss: 0.0005260861944407225 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81816\n",
            "Total Loss: 2.7543792724609375 | Context Loss: 0.0005383504321798682 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81817\n",
            "Total Loss: 2.3390533924102783 | Context Loss: 0.0006111746188253164 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81818\n",
            "Total Loss: 2.5255274772644043 | Context Loss: 0.0008223539916798472 | Rhyme Loss: 0.4646745875734178 \n",
            "Iteration number: 81819\n",
            "Total Loss: 2.749878406524658 | Context Loss: 0.0008723047794774175 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81820\n",
            "Total Loss: 2.625500202178955 | Context Loss: 0.0009219112689606845 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81821\n",
            "Total Loss: 3.0495591163635254 | Context Loss: 0.0008581587462686002 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81822\n",
            "Total Loss: 2.1226484775543213 | Context Loss: 0.000556152022909373 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81823\n",
            "Total Loss: 2.6273152828216553 | Context Loss: 0.001010914333164692 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81824\n",
            "Total Loss: 3.7637479305267334 | Context Loss: 0.0006925786728970706 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81825\n",
            "Total Loss: 2.5750396251678467 | Context Loss: 0.0007558647776022553 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81826\n",
            "Total Loss: 2.3160159587860107 | Context Loss: 0.0005199676961638033 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81827\n",
            "Total Loss: 2.8507323265075684 | Context Loss: 0.0005999452550895512 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81828\n",
            "Total Loss: 2.084040403366089 | Context Loss: 0.0007471512071788311 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81829\n",
            "Total Loss: 3.5624337196350098 | Context Loss: 0.0005831819144077599 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81830\n",
            "Total Loss: 2.464592933654785 | Context Loss: 0.0006739730015397072 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81831\n",
            "Total Loss: 3.507049560546875 | Context Loss: 0.0004928361158818007 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81832\n",
            "Total Loss: 2.7200329303741455 | Context Loss: 0.0008708005771040916 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 81833\n",
            "Total Loss: 3.3416194915771484 | Context Loss: 0.0005991143407300115 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81834\n",
            "Total Loss: 2.66591215133667 | Context Loss: 0.0007636656519025564 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81835\n",
            "Total Loss: 2.4990768432617188 | Context Loss: 0.0012671853182837367 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81836\n",
            "Total Loss: 3.9205548763275146 | Context Loss: 0.0004747122002299875 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81837\n",
            "Total Loss: 2.310039520263672 | Context Loss: 0.0007017005700618029 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81838\n",
            "Total Loss: 2.7444851398468018 | Context Loss: 0.0007327308412641287 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81839\n",
            "Total Loss: 2.844460964202881 | Context Loss: 0.0005873127956874669 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81840\n",
            "Total Loss: 2.786165952682495 | Context Loss: 0.0005948292091488838 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81841\n",
            "Total Loss: 1.9684728384017944 | Context Loss: 0.000767212244682014 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81842\n",
            "Total Loss: 2.6604058742523193 | Context Loss: 0.0006675481563434005 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81843\n",
            "Total Loss: 2.751023292541504 | Context Loss: 0.000648805289529264 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81844\n",
            "Total Loss: 2.4934804439544678 | Context Loss: 0.0009050849475897849 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81845\n",
            "Total Loss: 2.4771671295166016 | Context Loss: 0.0005453607882373035 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81846\n",
            "Total Loss: 2.3434555530548096 | Context Loss: 0.0007279046112671494 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81847\n",
            "Total Loss: 2.590172052383423 | Context Loss: 0.0007807312067598104 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81848\n",
            "Total Loss: 2.4791817665100098 | Context Loss: 0.0006257574423216283 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81849\n",
            "Total Loss: 2.9012951850891113 | Context Loss: 0.0007320870063267648 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81850\n",
            "Total Loss: 3.308272123336792 | Context Loss: 0.0006778364768251777 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81851\n",
            "Total Loss: 2.372278928756714 | Context Loss: 0.0009039092110469937 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81852\n",
            "Total Loss: 3.136713981628418 | Context Loss: 0.0005725562805309892 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81853\n",
            "Total Loss: 2.1408803462982178 | Context Loss: 0.0007027535466477275 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81854\n",
            "Total Loss: 3.862422466278076 | Context Loss: 0.0006507558282464743 | Rhyme Loss: 0.053388066758518156 \n",
            "Iteration number: 81855\n",
            "Total Loss: 1.8425843715667725 | Context Loss: 0.0005803515668958426 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81856\n",
            "Total Loss: 3.221956729888916 | Context Loss: 0.0006197083275765181 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81857\n",
            "Total Loss: 3.0195813179016113 | Context Loss: 0.0007144126575440168 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81858\n",
            "Total Loss: 2.6707570552825928 | Context Loss: 0.0005966758471913636 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81859\n",
            "Total Loss: 2.6669633388519287 | Context Loss: 0.0005330986459739506 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81860\n",
            "Total Loss: 2.829380989074707 | Context Loss: 0.0008933712379075587 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81861\n",
            "Total Loss: 3.0581259727478027 | Context Loss: 0.000743107870221138 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81862\n",
            "Total Loss: 3.028944253921509 | Context Loss: 0.0008017139043658972 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81863\n",
            "Total Loss: 3.192763090133667 | Context Loss: 0.0007848602253943682 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81864\n",
            "Total Loss: 2.386223316192627 | Context Loss: 0.0011182442540302873 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81865\n",
            "Total Loss: 2.6876420974731445 | Context Loss: 0.0009988518431782722 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81866\n",
            "Total Loss: 3.2919533252716064 | Context Loss: 0.0008245557546615601 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81867\n",
            "Total Loss: 2.9785714149475098 | Context Loss: 0.000688176485709846 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81868\n",
            "Total Loss: 2.491413116455078 | Context Loss: 0.0007139731897041202 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81869\n",
            "Total Loss: 2.4069724082946777 | Context Loss: 0.0007321928860619664 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81870\n",
            "Total Loss: 2.023392677307129 | Context Loss: 0.0010028441902250051 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81871\n",
            "Total Loss: 2.6183786392211914 | Context Loss: 0.0007380697643384337 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81872\n",
            "Total Loss: 2.5642755031585693 | Context Loss: 0.0006786019075661898 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81873\n",
            "Total Loss: 2.7627902030944824 | Context Loss: 0.0008463916019536555 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81874\n",
            "Total Loss: 2.5285444259643555 | Context Loss: 0.0005772169097326696 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81875\n",
            "Total Loss: 2.8226661682128906 | Context Loss: 0.00045086690806783736 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81876\n",
            "Total Loss: 2.0595145225524902 | Context Loss: 0.0006116590229794383 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81877\n",
            "Total Loss: 2.010745048522949 | Context Loss: 0.0006984437350183725 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81878\n",
            "Total Loss: 2.752183198928833 | Context Loss: 0.0005688527598977089 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81879\n",
            "Total Loss: 2.66924786567688 | Context Loss: 0.0006032217061147094 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81880\n",
            "Total Loss: 2.9913432598114014 | Context Loss: 0.0006668475107289851 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81881\n",
            "Total Loss: 2.673154592514038 | Context Loss: 0.0005835382035002112 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81882\n",
            "Total Loss: 2.662753105163574 | Context Loss: 0.00101961859036237 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81883\n",
            "Total Loss: 2.5021467208862305 | Context Loss: 0.0008748715044930577 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81884\n",
            "Total Loss: 2.996136426925659 | Context Loss: 0.0007568210130557418 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81885\n",
            "Total Loss: 2.7462048530578613 | Context Loss: 0.00046714875497855246 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81886\n",
            "Total Loss: 3.5894854068756104 | Context Loss: 0.0006505497731268406 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81887\n",
            "Total Loss: 2.54252028465271 | Context Loss: 0.0008544120937585831 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81888\n",
            "Total Loss: 2.8048863410949707 | Context Loss: 0.0007080307696014643 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81889\n",
            "Total Loss: 2.5763309001922607 | Context Loss: 0.0006840266287326813 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81890\n",
            "Total Loss: 3.9516916275024414 | Context Loss: 0.0005403057439252734 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81891\n",
            "Total Loss: 2.2804951667785645 | Context Loss: 0.0005767866387031972 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81892\n",
            "Total Loss: 2.3517982959747314 | Context Loss: 0.0007130909943953156 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81893\n",
            "Total Loss: 3.1630918979644775 | Context Loss: 0.0006174005102366209 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81894\n",
            "Total Loss: 3.304835081100464 | Context Loss: 0.0005669050151482224 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81895\n",
            "Total Loss: 2.6073739528656006 | Context Loss: 0.0006890167715027928 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81896\n",
            "Total Loss: 2.7125329971313477 | Context Loss: 0.0006221652729436755 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81897\n",
            "Total Loss: 3.727411985397339 | Context Loss: 0.00048236356815323234 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81898\n",
            "Total Loss: 2.326138496398926 | Context Loss: 0.0006786884041503072 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81899\n",
            "Total Loss: 2.511502981185913 | Context Loss: 0.0006538301822729409 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81900\n",
            "Total Loss: 2.1994078159332275 | Context Loss: 0.0007386911893263459 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81901\n",
            "Total Loss: 2.496255874633789 | Context Loss: 0.0006280390080064535 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81902\n",
            "Total Loss: 2.669922113418579 | Context Loss: 0.0007621095865033567 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81903\n",
            "Total Loss: 2.7479867935180664 | Context Loss: 0.000580034451559186 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81904\n",
            "Total Loss: 2.557292938232422 | Context Loss: 0.0008340649656020105 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81905\n",
            "Total Loss: 2.44560170173645 | Context Loss: 0.0007469873526133597 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81906\n",
            "Total Loss: 2.403045892715454 | Context Loss: 0.0005878856754861772 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81907\n",
            "Total Loss: 2.0013866424560547 | Context Loss: 0.0006222774973139167 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81908\n",
            "Total Loss: 2.5876059532165527 | Context Loss: 0.0007424334762617946 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81909\n",
            "Total Loss: 3.136021137237549 | Context Loss: 0.0007124627009034157 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81910\n",
            "Total Loss: 2.82663631439209 | Context Loss: 0.00069606420584023 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81911\n",
            "Total Loss: 3.2149734497070312 | Context Loss: 0.0006384106236509979 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81912\n",
            "Total Loss: 2.7772433757781982 | Context Loss: 0.0006035049445927143 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81913\n",
            "Total Loss: 2.752821683883667 | Context Loss: 0.00048532895743846893 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81914\n",
            "Total Loss: 2.565587043762207 | Context Loss: 0.00039678419125266373 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81915\n",
            "Total Loss: 2.221055746078491 | Context Loss: 0.001381210284307599 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81916\n",
            "Total Loss: 3.229637861251831 | Context Loss: 0.0006017228006385267 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81917\n",
            "Total Loss: 2.61662220954895 | Context Loss: 0.0004670116468332708 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81918\n",
            "Total Loss: 3.275219202041626 | Context Loss: 0.0006654753815382719 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81919\n",
            "Total Loss: 2.351137161254883 | Context Loss: 0.0006892912788316607 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 81920\n",
            "Total Loss: 2.884845733642578 | Context Loss: 0.000827509444206953 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81921\n",
            "Total Loss: 3.205828905105591 | Context Loss: 0.0005504249129444361 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81922\n",
            "Total Loss: 2.438333749771118 | Context Loss: 0.0005835860501974821 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81923\n",
            "Total Loss: 2.815662384033203 | Context Loss: 0.000597632781136781 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81924\n",
            "Total Loss: 3.978806734085083 | Context Loss: 0.0005089266924187541 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81925\n",
            "Total Loss: 2.32022762298584 | Context Loss: 0.0005465837894007564 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81926\n",
            "Total Loss: 2.3341221809387207 | Context Loss: 0.0006572321290150285 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81927\n",
            "Total Loss: 2.43221116065979 | Context Loss: 0.0005814045434817672 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81928\n",
            "Total Loss: 3.108552932739258 | Context Loss: 0.0006729756714776158 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81929\n",
            "Total Loss: 2.349231004714966 | Context Loss: 0.0005210903473198414 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81930\n",
            "Total Loss: 2.6289358139038086 | Context Loss: 0.00047026731772348285 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81931\n",
            "Total Loss: 1.9623544216156006 | Context Loss: 0.0008521192939952016 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81932\n",
            "Total Loss: 2.8591418266296387 | Context Loss: 0.0007575665367767215 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 81933\n",
            "Total Loss: 2.276770830154419 | Context Loss: 0.0006460070144385099 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81934\n",
            "Total Loss: 3.600731134414673 | Context Loss: 0.0004417872114572674 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81935\n",
            "Total Loss: 2.9758894443511963 | Context Loss: 0.0006403852021321654 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81936\n",
            "Total Loss: 2.2079105377197266 | Context Loss: 0.0006619759369641542 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81937\n",
            "Total Loss: 2.0092060565948486 | Context Loss: 0.0008395460899919271 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81938\n",
            "Total Loss: 3.012160539627075 | Context Loss: 0.0004894852754659951 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81939\n",
            "Total Loss: 2.3544905185699463 | Context Loss: 0.0006418696139007807 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81940\n",
            "Total Loss: 2.655362129211426 | Context Loss: 0.0005537395481951535 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81941\n",
            "Total Loss: 3.084136486053467 | Context Loss: 0.00043988533434458077 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81942\n",
            "Total Loss: 2.7223384380340576 | Context Loss: 0.0010039673652499914 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81943\n",
            "Total Loss: 3.0900697708129883 | Context Loss: 0.0007329856744036078 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81944\n",
            "Total Loss: 1.825549840927124 | Context Loss: 0.0007253990042954683 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81945\n",
            "Total Loss: 2.3302762508392334 | Context Loss: 0.0008244997006841004 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81946\n",
            "Total Loss: 2.6461074352264404 | Context Loss: 0.0006092814146541059 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81947\n",
            "Total Loss: 2.490623950958252 | Context Loss: 0.0005858565564267337 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81948\n",
            "Total Loss: 2.224574089050293 | Context Loss: 0.0011595968389883637 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81949\n",
            "Total Loss: 4.229569435119629 | Context Loss: 0.0010243409778922796 | Rhyme Loss: 0.5546530951346693 \n",
            "Iteration number: 81950\n",
            "Total Loss: 3.5950510501861572 | Context Loss: 0.0005396341439336538 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81951\n",
            "Total Loss: 2.053697347640991 | Context Loss: 0.0007608399027958512 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81952\n",
            "Total Loss: 2.366319417953491 | Context Loss: 0.0005442706169560552 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81953\n",
            "Total Loss: 2.393026351928711 | Context Loss: 0.0008961461135186255 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81954\n",
            "Total Loss: 2.808804750442505 | Context Loss: 0.0008636218262836337 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81955\n",
            "Total Loss: 3.401292324066162 | Context Loss: 0.00080331158824265 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81956\n",
            "Total Loss: 1.8776943683624268 | Context Loss: 0.0006387743633240461 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81957\n",
            "Total Loss: 3.1696505546569824 | Context Loss: 0.0005824012332595885 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81958\n",
            "Total Loss: 2.3801441192626953 | Context Loss: 0.000820472021587193 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81959\n",
            "Total Loss: 2.4331390857696533 | Context Loss: 0.000669871224090457 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81960\n",
            "Total Loss: 2.664827346801758 | Context Loss: 0.0005912696942687035 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81961\n",
            "Total Loss: 1.9517383575439453 | Context Loss: 0.0006558576133102179 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81962\n",
            "Total Loss: 2.193605422973633 | Context Loss: 0.0004645354929380119 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81963\n",
            "Total Loss: 3.1204495429992676 | Context Loss: 0.0004403040511533618 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81964\n",
            "Total Loss: 2.168895959854126 | Context Loss: 0.000760570983402431 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81965\n",
            "Total Loss: 2.4803521633148193 | Context Loss: 0.0006628415430895984 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81966\n",
            "Total Loss: 2.7559096813201904 | Context Loss: 0.0005577915580943227 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81967\n",
            "Total Loss: 2.5160233974456787 | Context Loss: 0.0007471733260899782 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81968\n",
            "Total Loss: 2.5664772987365723 | Context Loss: 0.0007121626404114068 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 81969\n",
            "Total Loss: 2.5405354499816895 | Context Loss: 0.0007744798203930259 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81970\n",
            "Total Loss: 2.582388401031494 | Context Loss: 0.0007276071701198816 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81971\n",
            "Total Loss: 2.4363863468170166 | Context Loss: 0.0005219892482273281 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81972\n",
            "Total Loss: 2.636486768722534 | Context Loss: 0.0006332216435112059 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81973\n",
            "Total Loss: 3.0875015258789062 | Context Loss: 0.000799112138338387 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81974\n",
            "Total Loss: 2.4005916118621826 | Context Loss: 0.0007161549292504787 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81975\n",
            "Total Loss: 2.439554452896118 | Context Loss: 0.0007506846450269222 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81976\n",
            "Total Loss: 3.376492738723755 | Context Loss: 0.0007296635303646326 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81977\n",
            "Total Loss: 2.7494211196899414 | Context Loss: 0.0005972756771370769 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81978\n",
            "Total Loss: 2.2270469665527344 | Context Loss: 0.0006933589465916157 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81979\n",
            "Total Loss: 2.5855612754821777 | Context Loss: 0.0005051035550422966 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81980\n",
            "Total Loss: 2.461737632751465 | Context Loss: 0.000736510322894901 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81981\n",
            "Total Loss: 2.286350727081299 | Context Loss: 0.0006193738663569093 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81982\n",
            "Total Loss: 2.9297304153442383 | Context Loss: 0.0005105027812533081 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81983\n",
            "Total Loss: 3.5680947303771973 | Context Loss: 0.0012769595487043262 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81984\n",
            "Total Loss: 2.7832908630371094 | Context Loss: 0.0005881843389943242 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81985\n",
            "Total Loss: 2.529752731323242 | Context Loss: 0.0006769689498469234 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81986\n",
            "Total Loss: 2.640432357788086 | Context Loss: 0.0011642122408375144 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81987\n",
            "Total Loss: 2.6336729526519775 | Context Loss: 0.0006836284883320332 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81988\n",
            "Total Loss: 2.633974552154541 | Context Loss: 0.00054646231001243 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81989\n",
            "Total Loss: 1.9872337579727173 | Context Loss: 0.0007902372162789106 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81990\n",
            "Total Loss: 2.1995606422424316 | Context Loss: 0.0006388777401298285 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81991\n",
            "Total Loss: 2.470271348953247 | Context Loss: 0.0006703497492708266 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81992\n",
            "Total Loss: 2.237307548522949 | Context Loss: 0.0005969243939034641 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81993\n",
            "Total Loss: 2.3570382595062256 | Context Loss: 0.0006736743380315602 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81994\n",
            "Total Loss: 2.0613291263580322 | Context Loss: 0.0006451854133047163 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81995\n",
            "Total Loss: 2.2657148838043213 | Context Loss: 0.0006435302784666419 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81996\n",
            "Total Loss: 2.8282477855682373 | Context Loss: 0.0004789654049091041 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81997\n",
            "Total Loss: 2.656437397003174 | Context Loss: 0.0007435029838234186 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81998\n",
            "Total Loss: 2.648838520050049 | Context Loss: 0.0006080243038013577 | Rhyme Loss: 0.0 \n",
            "Iteration number: 81999\n",
            "Total Loss: 2.712310314178467 | Context Loss: 0.0005244966596364975 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82000\n",
            "\n",
            "\n",
            " -- Iteration 82000 --\n",
            "0: i would like to write limericks verse@ \n",
            " without limericks that dont make a breeze@ \n",
            " but i feel a weird thrill# \n",
            " by watching that thrill# \n",
            " im not really good at it but i@\n",
            "\n",
            "\n",
            "1: i have a love for old jess@ \n",
            " who is always a sight to behold@ \n",
            " since he brings to my home# \n",
            " a bright christmas display# \n",
            " we can see why hes making his mark@\n",
            "\n",
            "\n",
            "2: from a tree trunk we sat to discuss@ \n",
            " and our views were well into the mess@ \n",
            " but the tree on the hill# \n",
            " was a jolly good thrill# \n",
            " with each treestump with no distress@\n",
            "\n",
            "\n",
            "3: our king had been shot in the back@ \n",
            " which was surely a terrible lack@ \n",
            " it was hard to explain# \n",
            " an airgun was needed# \n",
            " so he shot all the rest of his stack@\n",
            "\n",
            "\n",
            "4: theres a term from a class now im stuck@ \n",
            " its an order in all of its mix@ \n",
            " thats the order of course# \n",
            " so i know not to force# \n",
            " you to say its a group that is classless@\n",
            "\n",
            "\n",
            "Total Loss: 2.6906847953796387 | Context Loss: 0.0006243912503123283 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82001\n",
            "Total Loss: 2.6889960765838623 | Context Loss: 0.0006734722992405295 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82002\n",
            "Total Loss: 2.8003337383270264 | Context Loss: 0.0005638465518131852 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82003\n",
            "Total Loss: 3.454925775527954 | Context Loss: 0.0005393613828346133 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82004\n",
            "Total Loss: 2.316049337387085 | Context Loss: 0.0007358740549534559 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82005\n",
            "Total Loss: 2.159276008605957 | Context Loss: 0.0010898038744926453 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82006\n",
            "Total Loss: 2.501525640487671 | Context Loss: 0.0007716732798144221 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82007\n",
            "Total Loss: 2.2394211292266846 | Context Loss: 0.0006570732221007347 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82008\n",
            "Total Loss: 1.5899766683578491 | Context Loss: 0.0005447654984891415 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82009\n",
            "Total Loss: 2.2047927379608154 | Context Loss: 0.0006536053260788321 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82010\n",
            "Total Loss: 3.464656352996826 | Context Loss: 0.0008050546166487038 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 82011\n",
            "Total Loss: 2.566978931427002 | Context Loss: 0.0005145465256646276 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82012\n",
            "Total Loss: 2.3933393955230713 | Context Loss: 0.0006648708949796855 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82013\n",
            "Total Loss: 2.5021612644195557 | Context Loss: 0.0006960257305763662 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82014\n",
            "Total Loss: 1.9335627555847168 | Context Loss: 0.0007957168272696435 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82015\n",
            "Total Loss: 2.384357452392578 | Context Loss: 0.0005322377546690404 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82016\n",
            "Total Loss: 2.620129108428955 | Context Loss: 0.0006060873856768012 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82017\n",
            "Total Loss: 2.9999942779541016 | Context Loss: 0.000608098809607327 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82018\n",
            "Total Loss: 2.431147813796997 | Context Loss: 0.0005350716528482735 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82019\n",
            "Total Loss: 2.693882465362549 | Context Loss: 0.0009431939688511193 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82020\n",
            "Total Loss: 3.3452394008636475 | Context Loss: 0.0009067193022929132 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82021\n",
            "Total Loss: 2.331935167312622 | Context Loss: 0.0006158571923151612 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82022\n",
            "Total Loss: 2.3283069133758545 | Context Loss: 0.000741960946470499 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82023\n",
            "Total Loss: 2.54793381690979 | Context Loss: 0.0008483841083943844 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82024\n",
            "Total Loss: 3.1434946060180664 | Context Loss: 0.0005408435245044529 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82025\n",
            "Total Loss: 2.6834888458251953 | Context Loss: 0.0006089563248679042 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 82026\n",
            "Total Loss: 2.582547664642334 | Context Loss: 0.0006290478049777448 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82027\n",
            "Total Loss: 2.996577024459839 | Context Loss: 0.000719415140338242 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82028\n",
            "Total Loss: 2.8410074710845947 | Context Loss: 0.0007299664430320263 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82029\n",
            "Total Loss: 2.715895891189575 | Context Loss: 0.0012410259805619717 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82030\n",
            "Total Loss: 2.203982353210449 | Context Loss: 0.0008496044320054352 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82031\n",
            "Total Loss: 1.9824976921081543 | Context Loss: 0.0006591756828129292 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82032\n",
            "Total Loss: 2.846163272857666 | Context Loss: 0.0005071047926321626 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82033\n",
            "Total Loss: 1.948022484779358 | Context Loss: 0.0005270106485113502 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82034\n",
            "Total Loss: 3.5726778507232666 | Context Loss: 0.0006676662596873939 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82035\n",
            "Total Loss: 2.0147626399993896 | Context Loss: 0.0008103190921247005 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82036\n",
            "Total Loss: 2.931239366531372 | Context Loss: 0.0006315640057437122 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82037\n",
            "Total Loss: 2.4393789768218994 | Context Loss: 0.0006380380364134908 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82038\n",
            "Total Loss: 2.718109369277954 | Context Loss: 0.0007626230362802744 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82039\n",
            "Total Loss: 2.1847026348114014 | Context Loss: 0.00048391034943051636 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82040\n",
            "Total Loss: 2.45682692527771 | Context Loss: 0.0005883840494789183 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82041\n",
            "Total Loss: 2.615835428237915 | Context Loss: 0.0005602907622233033 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82042\n",
            "Total Loss: 2.5263447761535645 | Context Loss: 0.0005412879399955273 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82043\n",
            "Total Loss: 2.6532771587371826 | Context Loss: 0.0007119313813745975 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82044\n",
            "Total Loss: 3.1264805793762207 | Context Loss: 0.0011146130273118615 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82045\n",
            "Total Loss: 2.5058717727661133 | Context Loss: 0.0006041943561285734 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82046\n",
            "Total Loss: 2.3379874229431152 | Context Loss: 0.0005343914963304996 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82047\n",
            "Total Loss: 2.5800528526306152 | Context Loss: 0.0007221370469778776 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82048\n",
            "Total Loss: 2.7473864555358887 | Context Loss: 0.0008304634829983115 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82049\n",
            "Total Loss: 2.711958408355713 | Context Loss: 0.0009797560051083565 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82050\n",
            "Total Loss: 2.374607563018799 | Context Loss: 0.0006172393914312124 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82051\n",
            "Total Loss: 1.8951196670532227 | Context Loss: 0.0009193772566504776 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82052\n",
            "Total Loss: 2.7243645191192627 | Context Loss: 0.0006718829390592873 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82053\n",
            "Total Loss: 2.6456215381622314 | Context Loss: 0.0007790373056195676 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82054\n",
            "Total Loss: 2.827949047088623 | Context Loss: 0.00073926494223997 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82055\n",
            "Total Loss: 2.5217390060424805 | Context Loss: 0.0006636198377236724 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82056\n",
            "Total Loss: 2.6977553367614746 | Context Loss: 0.0007399190217256546 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82057\n",
            "Total Loss: 2.2571401596069336 | Context Loss: 0.0009260047227144241 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82058\n",
            "Total Loss: 2.981358051300049 | Context Loss: 0.0008733426802791655 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82059\n",
            "Total Loss: 2.205747365951538 | Context Loss: 0.0006742068799212575 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82060\n",
            "Total Loss: 3.059838056564331 | Context Loss: 0.0006186806713230908 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82061\n",
            "Total Loss: 3.187391757965088 | Context Loss: 0.0007251680945046246 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82062\n",
            "Total Loss: 2.2709708213806152 | Context Loss: 0.0005043631535954773 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82063\n",
            "Total Loss: 3.270728588104248 | Context Loss: 0.0009306624997407198 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82064\n",
            "Total Loss: 2.2669641971588135 | Context Loss: 0.0008955069934017956 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82065\n",
            "Total Loss: 3.607311725616455 | Context Loss: 0.000597881618887186 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82066\n",
            "Total Loss: 2.6343564987182617 | Context Loss: 0.000608717673458159 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82067\n",
            "Total Loss: 2.5647881031036377 | Context Loss: 0.0006309532909654081 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82068\n",
            "Total Loss: 2.2166740894317627 | Context Loss: 0.0012456036638468504 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82069\n",
            "Total Loss: 2.1135783195495605 | Context Loss: 0.000592195603530854 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82070\n",
            "Total Loss: 2.0913069248199463 | Context Loss: 0.0007941029034554958 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82071\n",
            "Total Loss: 2.362251043319702 | Context Loss: 0.0006244804826565087 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82072\n",
            "Total Loss: 2.7362987995147705 | Context Loss: 0.0008499579853378236 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82073\n",
            "Total Loss: 2.904442310333252 | Context Loss: 0.0007152571924962103 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82074\n",
            "Total Loss: 2.529306650161743 | Context Loss: 0.0008128387853503227 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82075\n",
            "Total Loss: 3.218687057495117 | Context Loss: 0.0006739649106748402 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82076\n",
            "Total Loss: 2.4226796627044678 | Context Loss: 0.000511030841153115 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82077\n",
            "Total Loss: 2.4878714084625244 | Context Loss: 0.0007216786034405231 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82078\n",
            "Total Loss: 2.3976211547851562 | Context Loss: 0.0007051266729831696 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82079\n",
            "Total Loss: 3.409141778945923 | Context Loss: 0.0005978599074296653 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82080\n",
            "Total Loss: 1.8417766094207764 | Context Loss: 0.0007142784306779504 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82081\n",
            "Total Loss: 2.951622486114502 | Context Loss: 0.0006492745014838874 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82082\n",
            "Total Loss: 2.8007874488830566 | Context Loss: 0.0006330638425424695 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82083\n",
            "Total Loss: 2.884896755218506 | Context Loss: 0.0005213035037741065 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82084\n",
            "Total Loss: 2.4743072986602783 | Context Loss: 0.0006479456787928939 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82085\n",
            "Total Loss: 2.2407004833221436 | Context Loss: 0.0010916271712630987 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82086\n",
            "Total Loss: 2.6488022804260254 | Context Loss: 0.0007498771883547306 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82087\n",
            "Total Loss: 2.6274073123931885 | Context Loss: 0.0007718236884102225 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82088\n",
            "Total Loss: 2.8999433517456055 | Context Loss: 0.0008855725754983723 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82089\n",
            "Total Loss: 1.9468427896499634 | Context Loss: 0.0006523801130242646 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82090\n",
            "Total Loss: 2.4411637783050537 | Context Loss: 0.0008164317114278674 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82091\n",
            "Total Loss: 2.2523066997528076 | Context Loss: 0.0006160719785839319 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82092\n",
            "Total Loss: 3.550814628601074 | Context Loss: 0.000642476137727499 | Rhyme Loss: 0.6398425840585682 \n",
            "Iteration number: 82093\n",
            "Total Loss: 2.6510913372039795 | Context Loss: 0.0007654606597498059 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82094\n",
            "Total Loss: 2.0735979080200195 | Context Loss: 0.0008785862009972334 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82095\n",
            "Total Loss: 2.9223952293395996 | Context Loss: 0.0008879429660737514 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82096\n",
            "Total Loss: 2.053133964538574 | Context Loss: 0.000440324773080647 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82097\n",
            "Total Loss: 2.4849770069122314 | Context Loss: 0.0006687847198918462 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 82098\n",
            "Total Loss: 2.2826216220855713 | Context Loss: 0.0006566491210833192 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82099\n",
            "Total Loss: 2.9536468982696533 | Context Loss: 0.0005327566177584231 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82100\n",
            "Total Loss: 2.701364755630493 | Context Loss: 0.0009823590517044067 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82101\n",
            "Total Loss: 2.9167118072509766 | Context Loss: 0.00045705109369009733 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82102\n",
            "Total Loss: 2.6707496643066406 | Context Loss: 0.0007288277265615761 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82103\n",
            "Total Loss: 2.125290870666504 | Context Loss: 0.0006684851250611246 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82104\n",
            "Total Loss: 2.6413979530334473 | Context Loss: 0.0007210862822830677 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82105\n",
            "Total Loss: 2.797891616821289 | Context Loss: 0.0005052825435996056 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82106\n",
            "Total Loss: 3.1593031883239746 | Context Loss: 0.0006542359478771687 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82107\n",
            "Total Loss: 2.6060428619384766 | Context Loss: 0.0008997031254693866 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82108\n",
            "Total Loss: 3.2510199546813965 | Context Loss: 0.0008317750180140138 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82109\n",
            "Total Loss: 3.322463274002075 | Context Loss: 0.0005426483694463968 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82110\n",
            "Total Loss: 2.4938108921051025 | Context Loss: 0.0006528403609991074 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82111\n",
            "Total Loss: 4.22963809967041 | Context Loss: 0.0007123671821318567 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82112\n",
            "Total Loss: 2.4570863246917725 | Context Loss: 0.0004674537340179086 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82113\n",
            "Total Loss: 3.426121950149536 | Context Loss: 0.0006031199591234326 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82114\n",
            "Total Loss: 2.527799606323242 | Context Loss: 0.0008732534479349852 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82115\n",
            "Total Loss: 2.3959500789642334 | Context Loss: 0.0007700788555666804 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82116\n",
            "Total Loss: 3.43839955329895 | Context Loss: 0.0007455337909050286 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82117\n",
            "Total Loss: 2.8069918155670166 | Context Loss: 0.0006754916394129395 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82118\n",
            "Total Loss: 3.327327251434326 | Context Loss: 0.0005232305848039687 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82119\n",
            "Total Loss: 2.494029998779297 | Context Loss: 0.0006137448363006115 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82120\n",
            "Total Loss: 3.108315944671631 | Context Loss: 0.000714586756657809 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82121\n",
            "Total Loss: 2.413673162460327 | Context Loss: 0.0006235433393158019 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82122\n",
            "Total Loss: 2.95280385017395 | Context Loss: 0.0006764631834812462 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82123\n",
            "Total Loss: 2.7047553062438965 | Context Loss: 0.0006906905910000205 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82124\n",
            "Total Loss: 2.6922757625579834 | Context Loss: 0.0005361103103496134 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82125\n",
            "Total Loss: 2.3828110694885254 | Context Loss: 0.0006942595937289298 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82126\n",
            "Total Loss: 2.7913496494293213 | Context Loss: 0.0007579036755487323 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82127\n",
            "Total Loss: 2.4373326301574707 | Context Loss: 0.000572405697312206 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82128\n",
            "Total Loss: 1.8259109258651733 | Context Loss: 0.0007161947432905436 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82129\n",
            "Total Loss: 2.8917510509490967 | Context Loss: 0.0006642119260504842 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82130\n",
            "Total Loss: 2.5875906944274902 | Context Loss: 0.0005700163310393691 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82131\n",
            "Total Loss: 2.784151792526245 | Context Loss: 0.0007047482067719102 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82132\n",
            "Total Loss: 2.9600024223327637 | Context Loss: 0.0010003463830798864 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82133\n",
            "Total Loss: 2.776970863342285 | Context Loss: 0.0006532422848977149 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82134\n",
            "Total Loss: 2.5255281925201416 | Context Loss: 0.0004920000210404396 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82135\n",
            "Total Loss: 2.3959178924560547 | Context Loss: 0.0007549591828137636 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82136\n",
            "Total Loss: 2.986687421798706 | Context Loss: 0.0007382252952083945 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82137\n",
            "Total Loss: 2.8461108207702637 | Context Loss: 0.000731821171939373 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82138\n",
            "Total Loss: 2.7549285888671875 | Context Loss: 0.0007080384530127048 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82139\n",
            "Total Loss: 2.0204548835754395 | Context Loss: 0.000681266188621521 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82140\n",
            "Total Loss: 3.08263897895813 | Context Loss: 0.00047215286758728325 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82141\n",
            "Total Loss: 2.685779333114624 | Context Loss: 0.0005186318303458393 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82142\n",
            "Total Loss: 3.256021499633789 | Context Loss: 0.0008673385600559413 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82143\n",
            "Total Loss: 3.490661144256592 | Context Loss: 0.0008943172870203853 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82144\n",
            "Total Loss: 2.9978134632110596 | Context Loss: 0.0005283874925225973 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82145\n",
            "Total Loss: 2.7643566131591797 | Context Loss: 0.0008265236974693835 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82146\n",
            "Total Loss: 2.220963478088379 | Context Loss: 0.0005281085614115 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82147\n",
            "Total Loss: 2.7297096252441406 | Context Loss: 0.0009801561245694757 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82148\n",
            "Total Loss: 2.5009005069732666 | Context Loss: 0.0007061766809783876 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82149\n",
            "Total Loss: 2.6285758018493652 | Context Loss: 0.0004958305507898331 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82150\n",
            "Total Loss: 2.2345757484436035 | Context Loss: 0.00052702019456774 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82151\n",
            "Total Loss: 2.535066604614258 | Context Loss: 0.0005899741081520915 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82152\n",
            "Total Loss: 2.3204798698425293 | Context Loss: 0.0007008685497567058 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82153\n",
            "Total Loss: 2.995479106903076 | Context Loss: 0.0009735255734995008 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82154\n",
            "Total Loss: 1.7580723762512207 | Context Loss: 0.0009436080581508577 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82155\n",
            "Total Loss: 2.702038526535034 | Context Loss: 0.0007056863978505135 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82156\n",
            "Total Loss: 2.5330262184143066 | Context Loss: 0.0005787239642813802 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82157\n",
            "Total Loss: 3.0130231380462646 | Context Loss: 0.0008137631230056286 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82158\n",
            "Total Loss: 2.977180242538452 | Context Loss: 0.0008303847862407565 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82159\n",
            "Total Loss: 3.272493839263916 | Context Loss: 0.0007864905637688935 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82160\n",
            "Total Loss: 2.2915172576904297 | Context Loss: 0.0006740948301739991 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82161\n",
            "Total Loss: 2.4021201133728027 | Context Loss: 0.0006447553168982267 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82162\n",
            "Total Loss: 2.8384697437286377 | Context Loss: 0.0006710664019919932 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82163\n",
            "Total Loss: 3.5707035064697266 | Context Loss: 0.0009075349080376327 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82164\n",
            "Total Loss: 2.122337579727173 | Context Loss: 0.0008866818388924003 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82165\n",
            "Total Loss: 1.950640320777893 | Context Loss: 0.0008154410170391202 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82166\n",
            "Total Loss: 2.708068609237671 | Context Loss: 0.0006750867469236255 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82167\n",
            "Total Loss: 3.3509678840637207 | Context Loss: 0.0007983517716638744 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82168\n",
            "Total Loss: 4.719898700714111 | Context Loss: 0.0006004416500218213 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82169\n",
            "Total Loss: 2.8282361030578613 | Context Loss: 0.0006800203118473291 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82170\n",
            "Total Loss: 2.9679300785064697 | Context Loss: 0.0009003752493299544 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82171\n",
            "Total Loss: 3.311765432357788 | Context Loss: 0.0006780681433156133 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82172\n",
            "Total Loss: 3.042990207672119 | Context Loss: 0.0008302321075461805 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82173\n",
            "Total Loss: 1.9912444353103638 | Context Loss: 0.0010027787648141384 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82174\n",
            "Total Loss: 2.610792875289917 | Context Loss: 0.0009011434158310294 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82175\n",
            "Total Loss: 3.053262233734131 | Context Loss: 0.0008094821823760867 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82176\n",
            "Total Loss: 2.532960891723633 | Context Loss: 0.0006388556212186813 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82177\n",
            "Total Loss: 2.782661199569702 | Context Loss: 0.0007681444985792041 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82178\n",
            "Total Loss: 2.3534646034240723 | Context Loss: 0.0007379630114883184 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82179\n",
            "Total Loss: 2.4297327995300293 | Context Loss: 0.00044354319106787443 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82180\n",
            "Total Loss: 2.691101312637329 | Context Loss: 0.0006320109823718667 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82181\n",
            "Total Loss: 2.0007495880126953 | Context Loss: 0.0005906813312321901 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82182\n",
            "Total Loss: 2.8906850814819336 | Context Loss: 0.00080685323337093 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82183\n",
            "Total Loss: 2.513852119445801 | Context Loss: 0.0007833885028958321 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82184\n",
            "Total Loss: 2.570450782775879 | Context Loss: 0.0009673579479567707 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82185\n",
            "Total Loss: 2.438910484313965 | Context Loss: 0.0006793842185288668 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82186\n",
            "Total Loss: 2.181480884552002 | Context Loss: 0.000674387498293072 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82187\n",
            "Total Loss: 2.5182509422302246 | Context Loss: 0.0005478971870616078 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82188\n",
            "Total Loss: 2.367465019226074 | Context Loss: 0.0009162001078948379 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82189\n",
            "Total Loss: 3.0207552909851074 | Context Loss: 0.0007987598655745387 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82190\n",
            "Total Loss: 2.395308494567871 | Context Loss: 0.000568765215575695 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82191\n",
            "Total Loss: 2.984201431274414 | Context Loss: 0.0008243172196671367 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82192\n",
            "Total Loss: 2.5098111629486084 | Context Loss: 0.0008134280797094107 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82193\n",
            "Total Loss: 3.0542702674865723 | Context Loss: 0.0007001954363659024 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82194\n",
            "Total Loss: 2.757148027420044 | Context Loss: 0.0008211302338168025 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82195\n",
            "Total Loss: 2.6690077781677246 | Context Loss: 0.000711168278940022 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82196\n",
            "Total Loss: 2.688532590866089 | Context Loss: 0.0007685828022658825 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82197\n",
            "Total Loss: 3.175206422805786 | Context Loss: 0.0007408388191834092 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82198\n",
            "Total Loss: 3.2756268978118896 | Context Loss: 0.00048525509191676974 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82199\n",
            "Total Loss: 2.458233594894409 | Context Loss: 0.0006185008096508682 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82200\n",
            "Total Loss: 2.692636489868164 | Context Loss: 0.0007713519735261798 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82201\n",
            "Total Loss: 3.3576407432556152 | Context Loss: 0.0005676036234945059 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 82202\n",
            "Total Loss: 2.40301513671875 | Context Loss: 0.00069796247407794 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82203\n",
            "Total Loss: 1.8231127262115479 | Context Loss: 0.0007191232871264219 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82204\n",
            "Total Loss: 2.2568414211273193 | Context Loss: 0.0006423871964216232 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82205\n",
            "Total Loss: 1.843264102935791 | Context Loss: 0.0006735401693731546 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82206\n",
            "Total Loss: 2.3939590454101562 | Context Loss: 0.0007554967887699604 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82207\n",
            "Total Loss: 2.3847601413726807 | Context Loss: 0.0007376921130344272 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82208\n",
            "Total Loss: 2.6566898822784424 | Context Loss: 0.0007032062276266515 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82209\n",
            "Total Loss: 2.824129104614258 | Context Loss: 0.0006014708196744323 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82210\n",
            "Total Loss: 2.1603119373321533 | Context Loss: 0.0005268119275569916 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82211\n",
            "Total Loss: 2.6481800079345703 | Context Loss: 0.0006071861134842038 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82212\n",
            "Total Loss: 2.791553020477295 | Context Loss: 0.0006171306595206261 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82213\n",
            "Total Loss: 2.4855334758758545 | Context Loss: 0.0005797214107587934 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82214\n",
            "Total Loss: 2.7144789695739746 | Context Loss: 0.0006256232736632228 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82215\n",
            "Total Loss: 2.522775888442993 | Context Loss: 0.0007851727423258126 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82216\n",
            "Total Loss: 2.8351378440856934 | Context Loss: 0.0006515443092212081 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 82217\n",
            "Total Loss: 3.0675225257873535 | Context Loss: 0.0005397502682171762 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82218\n",
            "Total Loss: 2.999838352203369 | Context Loss: 0.0006620679632760584 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82219\n",
            "Total Loss: 2.9068984985351562 | Context Loss: 0.0006471622618846595 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82220\n",
            "Total Loss: 2.4175002574920654 | Context Loss: 0.0005450675380416214 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82221\n",
            "Total Loss: 2.712609052658081 | Context Loss: 0.0004121851525269449 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82222\n",
            "Total Loss: 2.81493878364563 | Context Loss: 0.0006469625514000654 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82223\n",
            "Total Loss: 2.849116086959839 | Context Loss: 0.000493953819386661 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82224\n",
            "Total Loss: 2.2221508026123047 | Context Loss: 0.0006531433900818229 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82225\n",
            "Total Loss: 2.8044464588165283 | Context Loss: 0.0007424981449730694 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 82226\n",
            "Total Loss: 2.769216299057007 | Context Loss: 0.0007975923363119364 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82227\n",
            "Total Loss: 2.8536319732666016 | Context Loss: 0.0006603751098737121 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82228\n",
            "Total Loss: 2.5428454875946045 | Context Loss: 0.0004988735890947282 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82229\n",
            "Total Loss: 2.2623097896575928 | Context Loss: 0.0007235220982693136 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82230\n",
            "Total Loss: 2.852773427963257 | Context Loss: 0.0009180512861348689 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 82231\n",
            "Total Loss: 2.4380013942718506 | Context Loss: 0.0004997788346372545 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82232\n",
            "Total Loss: 2.288861036300659 | Context Loss: 0.0006883154273964465 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82233\n",
            "Total Loss: 2.6369364261627197 | Context Loss: 0.0007800074527040124 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82234\n",
            "Total Loss: 2.343014717102051 | Context Loss: 0.0008386739064007998 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82235\n",
            "Total Loss: 2.7780301570892334 | Context Loss: 0.0009135499713011086 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82236\n",
            "Total Loss: 2.7851712703704834 | Context Loss: 0.0009540972532704473 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82237\n",
            "Total Loss: 2.6097495555877686 | Context Loss: 0.00044045495451427996 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82238\n",
            "Total Loss: 2.4662585258483887 | Context Loss: 0.0006685947300866246 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82239\n",
            "Total Loss: 2.488900661468506 | Context Loss: 0.0005502280546352267 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82240\n",
            "Total Loss: 2.2736549377441406 | Context Loss: 0.0007498767226934433 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82241\n",
            "Total Loss: 2.5673093795776367 | Context Loss: 0.0005955357337370515 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82242\n",
            "Total Loss: 2.970055103302002 | Context Loss: 0.00038959571975283325 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82243\n",
            "Total Loss: 2.7950828075408936 | Context Loss: 0.0009062549797818065 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82244\n",
            "Total Loss: 3.4860336780548096 | Context Loss: 0.0006033230456523597 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82245\n",
            "Total Loss: 3.042123317718506 | Context Loss: 0.0007208182360045612 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 82246\n",
            "Total Loss: 2.7537920475006104 | Context Loss: 0.0005916754598729312 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82247\n",
            "Total Loss: 2.573897123336792 | Context Loss: 0.0009575205040164292 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82248\n",
            "Total Loss: 2.1545658111572266 | Context Loss: 0.0006380623672157526 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82249\n",
            "Total Loss: 3.2832119464874268 | Context Loss: 0.0005597034469246864 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82250\n",
            "\n",
            "\n",
            " -- Iteration 82250 --\n",
            "0: a limericks not really bad@ \n",
            " its a style of liming its had@ \n",
            " by the rhyme and the rhyme# \n",
            " to give rhyming a pause# \n",
            " or the words not a bit of latched@\n",
            "\n",
            "\n",
            "1: i was hired to write limericks in jenner@ \n",
            " and now im a lark and a fanner@ \n",
            " i write thrillers so great# \n",
            " such are my career as a host# \n",
            " but i miss every one in hisoster@\n",
            "\n",
            "\n",
            "2: theres a man with a heart full of mirth@ \n",
            " who has heard his own voice and knows when to burst@ \n",
            " of the life hed begun# \n",
            " he wont quit till hes done# \n",
            " and his heart has grown strong and then burst@\n",
            "\n",
            "\n",
            "3: the cole of my dog is quite cute@ \n",
            " as she burbles her teeth and her mott@ \n",
            " to look more like moles# \n",
            " im afraid she looks like holes# \n",
            " well her mott is the hole in her mott@\n",
            "\n",
            "\n",
            "4: a young man with a beard said that day@ \n",
            " i love you im here to say goodbye@ \n",
            " what ive got here is clear# \n",
            " youre my son but its clear# \n",
            " that this baldwin just broke a few loose@\n",
            "\n",
            "\n",
            "Total Loss: 2.5297343730926514 | Context Loss: 0.0005913716740906239 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82251\n",
            "Total Loss: 2.2899396419525146 | Context Loss: 0.0009154207073152065 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82252\n",
            "Total Loss: 2.7283713817596436 | Context Loss: 0.0008549360791221261 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82253\n",
            "Total Loss: 2.771474838256836 | Context Loss: 0.0006981418700888753 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82254\n",
            "Total Loss: 2.5136945247650146 | Context Loss: 0.0006240163929760456 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82255\n",
            "Total Loss: 2.7955269813537598 | Context Loss: 0.0007566644344478846 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82256\n",
            "Total Loss: 2.3938980102539062 | Context Loss: 0.0007667510653845966 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82257\n",
            "Total Loss: 2.4855644702911377 | Context Loss: 0.0008542045252397656 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82258\n",
            "Total Loss: 3.041933536529541 | Context Loss: 0.0005906795850023627 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82259\n",
            "Total Loss: 3.4416301250457764 | Context Loss: 0.0006726884748786688 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82260\n",
            "Total Loss: 2.5407776832580566 | Context Loss: 0.0007602025289088488 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82261\n",
            "Total Loss: 3.0457160472869873 | Context Loss: 0.0007574954070150852 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82262\n",
            "Total Loss: 2.6056406497955322 | Context Loss: 0.0015603620558977127 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82263\n",
            "Total Loss: 2.201958417892456 | Context Loss: 0.0009274479234591126 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82264\n",
            "Total Loss: 2.8529396057128906 | Context Loss: 0.0005209487862884998 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82265\n",
            "Total Loss: 3.339825391769409 | Context Loss: 0.0006846367614343762 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82266\n",
            "Total Loss: 2.9114246368408203 | Context Loss: 0.0008041021646931767 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82267\n",
            "Total Loss: 2.1301612854003906 | Context Loss: 0.0007045427337288857 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82268\n",
            "Total Loss: 2.167248487472534 | Context Loss: 0.0006103746127337217 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82269\n",
            "Total Loss: 2.912167549133301 | Context Loss: 0.0008863225812092423 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82270\n",
            "Total Loss: 2.730319023132324 | Context Loss: 0.0005177727434784174 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82271\n",
            "Total Loss: 2.2656424045562744 | Context Loss: 0.0005858010845258832 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82272\n",
            "Total Loss: 2.863452434539795 | Context Loss: 0.0007250041235238314 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82273\n",
            "Total Loss: 2.6780478954315186 | Context Loss: 0.0007393778068944812 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82274\n",
            "Total Loss: 3.2057993412017822 | Context Loss: 0.0005455825012177229 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82275\n",
            "Total Loss: 2.814992904663086 | Context Loss: 0.00065406080102548 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82276\n",
            "Total Loss: 2.415133237838745 | Context Loss: 0.0006015655235387385 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82277\n",
            "Total Loss: 2.3299994468688965 | Context Loss: 0.0005625588819384575 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82278\n",
            "Total Loss: 3.6001956462860107 | Context Loss: 0.000644958985503763 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82279\n",
            "Total Loss: 2.841747283935547 | Context Loss: 0.0004910249263048172 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82280\n",
            "Total Loss: 2.911142110824585 | Context Loss: 0.0006229024147614837 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82281\n",
            "Total Loss: 2.861682415008545 | Context Loss: 0.0006358919781632721 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82282\n",
            "Total Loss: 3.041900396347046 | Context Loss: 0.0011102859862148762 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82283\n",
            "Total Loss: 3.2754852771759033 | Context Loss: 0.00046256661880761385 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82284\n",
            "Total Loss: 2.091811180114746 | Context Loss: 0.0008553856168873608 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82285\n",
            "Total Loss: 3.232811450958252 | Context Loss: 0.0006799381226301193 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82286\n",
            "Total Loss: 3.224578380584717 | Context Loss: 0.000567269220482558 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82287\n",
            "Total Loss: 3.0811331272125244 | Context Loss: 0.0004478659830056131 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82288\n",
            "Total Loss: 2.7938873767852783 | Context Loss: 0.0008274607826024294 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82289\n",
            "Total Loss: 3.388871431350708 | Context Loss: 0.0006049158982932568 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82290\n",
            "Total Loss: 2.1048331260681152 | Context Loss: 0.0006305471179075539 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82291\n",
            "Total Loss: 3.1795730590820312 | Context Loss: 0.0008010579040274024 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82292\n",
            "Total Loss: 2.4978437423706055 | Context Loss: 0.000959619996137917 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82293\n",
            "Total Loss: 2.1898927688598633 | Context Loss: 0.000621615385171026 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82294\n",
            "Total Loss: 2.726612091064453 | Context Loss: 0.0008657526923343539 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82295\n",
            "Total Loss: 2.3944449424743652 | Context Loss: 0.0010285796597599983 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82296\n",
            "Total Loss: 2.596874237060547 | Context Loss: 0.0007319586584344506 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82297\n",
            "Total Loss: 2.764254093170166 | Context Loss: 0.0006844013696536422 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82298\n",
            "Total Loss: 2.695385456085205 | Context Loss: 0.0008935085497796535 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82299\n",
            "Total Loss: 2.9382264614105225 | Context Loss: 0.0009411994833499193 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82300\n",
            "Total Loss: 2.6024391651153564 | Context Loss: 0.0007811668911017478 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82301\n",
            "Total Loss: 1.991955280303955 | Context Loss: 0.0007655427325516939 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82302\n",
            "Total Loss: 3.0132105350494385 | Context Loss: 0.0005379091016948223 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82303\n",
            "Total Loss: 2.86395263671875 | Context Loss: 0.0005658845766447484 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82304\n",
            "Total Loss: 2.471062183380127 | Context Loss: 0.0005279754986986518 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82305\n",
            "Total Loss: 3.2053935527801514 | Context Loss: 0.0006497738650068641 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82306\n",
            "Total Loss: 2.6825568675994873 | Context Loss: 0.0007801659521646798 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82307\n",
            "Total Loss: 3.358071804046631 | Context Loss: 0.00048779850476421416 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82308\n",
            "Total Loss: 2.0479793548583984 | Context Loss: 0.0006652895826846361 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82309\n",
            "Total Loss: 2.5572640895843506 | Context Loss: 0.0004997436772100627 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82310\n",
            "Total Loss: 2.2311975955963135 | Context Loss: 0.0008510566549375653 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82311\n",
            "Total Loss: 2.842996120452881 | Context Loss: 0.0007454875158146024 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82312\n",
            "Total Loss: 3.5628604888916016 | Context Loss: 0.0005438713124021888 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82313\n",
            "Total Loss: 3.030317783355713 | Context Loss: 0.0006841275608167052 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82314\n",
            "Total Loss: 2.2780306339263916 | Context Loss: 0.0006819125264883041 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82315\n",
            "Total Loss: 2.7007908821105957 | Context Loss: 0.0006867169286124408 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82316\n",
            "Total Loss: 3.0810086727142334 | Context Loss: 0.0006415386451408267 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82317\n",
            "Total Loss: 1.7998582124710083 | Context Loss: 0.000573407975025475 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82318\n",
            "Total Loss: 1.9390606880187988 | Context Loss: 0.0010120569495484233 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82319\n",
            "Total Loss: 3.028853178024292 | Context Loss: 0.000643189181573689 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82320\n",
            "Total Loss: 2.2945685386657715 | Context Loss: 0.0005375037435442209 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82321\n",
            "Total Loss: 2.934690237045288 | Context Loss: 0.0005849266890436411 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82322\n",
            "Total Loss: 2.9808335304260254 | Context Loss: 0.0005774874007329345 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82323\n",
            "Total Loss: 2.7336859703063965 | Context Loss: 0.0007095056353136897 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82324\n",
            "Total Loss: 2.644197702407837 | Context Loss: 0.001072280341759324 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82325\n",
            "Total Loss: 1.8974920511245728 | Context Loss: 0.0004546686541289091 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82326\n",
            "Total Loss: 2.117445707321167 | Context Loss: 0.0011187579948455095 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82327\n",
            "Total Loss: 2.7075912952423096 | Context Loss: 0.0008555940585210919 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82328\n",
            "Total Loss: 2.6459152698516846 | Context Loss: 0.0009342079283669591 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82329\n",
            "Total Loss: 1.8988018035888672 | Context Loss: 0.0006807388854213059 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82330\n",
            "Total Loss: 2.878814458847046 | Context Loss: 0.000497982488013804 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82331\n",
            "Total Loss: 2.439650058746338 | Context Loss: 0.0007062742952257395 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82332\n",
            "Total Loss: 2.0726630687713623 | Context Loss: 0.000871271186042577 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82333\n",
            "Total Loss: 2.6883394718170166 | Context Loss: 0.0006484622717835009 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82334\n",
            "Total Loss: 3.214539051055908 | Context Loss: 0.0009056765120476484 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82335\n",
            "Total Loss: 2.840493679046631 | Context Loss: 0.0006565313669852912 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82336\n",
            "Total Loss: 2.2343862056732178 | Context Loss: 0.0005151214427314699 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82337\n",
            "Total Loss: 2.979281187057495 | Context Loss: 0.0008785717072896659 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82338\n",
            "Total Loss: 2.8009941577911377 | Context Loss: 0.0005740319611504674 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82339\n",
            "Total Loss: 2.638054132461548 | Context Loss: 0.0009999989997595549 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82340\n",
            "Total Loss: 3.140115261077881 | Context Loss: 0.0005837571807205677 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82341\n",
            "Total Loss: 2.674323558807373 | Context Loss: 0.0008062113774940372 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82342\n",
            "Total Loss: 2.426469564437866 | Context Loss: 0.0004515861510299146 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82343\n",
            "Total Loss: 2.1393473148345947 | Context Loss: 0.000644590356387198 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82344\n",
            "Total Loss: 2.2585983276367188 | Context Loss: 0.0006564209470525384 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82345\n",
            "Total Loss: 2.242605209350586 | Context Loss: 0.000703949190210551 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82346\n",
            "Total Loss: 2.4574708938598633 | Context Loss: 0.0008021090761758387 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82347\n",
            "Total Loss: 2.3562326431274414 | Context Loss: 0.0005808554706163704 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82348\n",
            "Total Loss: 2.607680082321167 | Context Loss: 0.0007310964865610003 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82349\n",
            "Total Loss: 3.2422053813934326 | Context Loss: 0.00039350701263174415 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 82350\n",
            "Total Loss: 2.3806045055389404 | Context Loss: 0.0006771099288016558 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82351\n",
            "Total Loss: 2.3855462074279785 | Context Loss: 0.0006354497163556516 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82352\n",
            "Total Loss: 2.452861785888672 | Context Loss: 0.0007537839119322598 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82353\n",
            "Total Loss: 3.6607182025909424 | Context Loss: 0.0006107722292654216 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82354\n",
            "Total Loss: 2.789632797241211 | Context Loss: 0.000694340851623565 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82355\n",
            "Total Loss: 3.057236909866333 | Context Loss: 0.0006636818870902061 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82356\n",
            "Total Loss: 2.796473503112793 | Context Loss: 0.0006017322884872556 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82357\n",
            "Total Loss: 2.797297954559326 | Context Loss: 0.0006792476633563638 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82358\n",
            "Total Loss: 2.4114904403686523 | Context Loss: 0.0008647663053125143 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82359\n",
            "Total Loss: 2.2236928939819336 | Context Loss: 0.000588532246183604 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82360\n",
            "Total Loss: 2.9690492153167725 | Context Loss: 0.0006049533258192241 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82361\n",
            "Total Loss: 2.4887568950653076 | Context Loss: 0.0005897559458389878 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82362\n",
            "Total Loss: 2.633908987045288 | Context Loss: 0.0006668145069852471 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82363\n",
            "Total Loss: 2.9381566047668457 | Context Loss: 0.0006033570389263332 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82364\n",
            "Total Loss: 2.4954380989074707 | Context Loss: 0.0007196813239715993 | Rhyme Loss: 0.053388066758518156 \n",
            "Iteration number: 82365\n",
            "Total Loss: 2.384371757507324 | Context Loss: 0.0006404721643775702 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82366\n",
            "Total Loss: 2.517608165740967 | Context Loss: 0.0006382125429809093 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82367\n",
            "Total Loss: 2.296015501022339 | Context Loss: 0.0004931367584504187 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82368\n",
            "Total Loss: 2.397975206375122 | Context Loss: 0.0007479033665731549 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82369\n",
            "Total Loss: 2.2670674324035645 | Context Loss: 0.000733608496375382 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82370\n",
            "Total Loss: 3.218663454055786 | Context Loss: 0.0006305819842964411 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82371\n",
            "Total Loss: 3.3774778842926025 | Context Loss: 0.000648414483293891 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82372\n",
            "Total Loss: 2.62306547164917 | Context Loss: 0.0009326263098046184 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82373\n",
            "Total Loss: 3.035409927368164 | Context Loss: 0.0006694071926176548 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82374\n",
            "Total Loss: 2.4718170166015625 | Context Loss: 0.0005341029609553516 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82375\n",
            "Total Loss: 2.6602463722229004 | Context Loss: 0.0005729646654799581 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82376\n",
            "Total Loss: 2.199660301208496 | Context Loss: 0.00077292718924582 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82377\n",
            "Total Loss: 2.0625534057617188 | Context Loss: 0.0007585317362099886 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82378\n",
            "Total Loss: 1.8728796243667603 | Context Loss: 0.0007813223055563867 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82379\n",
            "Total Loss: 2.0932390689849854 | Context Loss: 0.00113607884850353 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82380\n",
            "Total Loss: 1.54812753200531 | Context Loss: 0.000513985869474709 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82381\n",
            "Total Loss: 2.1302599906921387 | Context Loss: 0.0009510763920843601 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82382\n",
            "Total Loss: 2.728278398513794 | Context Loss: 0.0006172650028020144 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82383\n",
            "Total Loss: 2.4173696041107178 | Context Loss: 0.0007864824729040265 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82384\n",
            "Total Loss: 2.598512887954712 | Context Loss: 0.0007151469471864402 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82385\n",
            "Total Loss: 3.4516842365264893 | Context Loss: 0.0005683955969288945 | Rhyme Loss: 0.3434008959515049 \n",
            "Iteration number: 82386\n",
            "Total Loss: 3.0818803310394287 | Context Loss: 0.0009315236820839345 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82387\n",
            "Total Loss: 2.5467312335968018 | Context Loss: 0.0006678159115836024 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82388\n",
            "Total Loss: 2.5189688205718994 | Context Loss: 0.0007825472857803106 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82389\n",
            "Total Loss: 2.684711456298828 | Context Loss: 0.0007051758002489805 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82390\n",
            "Total Loss: 3.4527132511138916 | Context Loss: 0.0005747064133174717 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82391\n",
            "Total Loss: 2.694071054458618 | Context Loss: 0.0005388159188441932 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82392\n",
            "Total Loss: 2.6500284671783447 | Context Loss: 0.0005364301614463329 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82393\n",
            "Total Loss: 2.149517774581909 | Context Loss: 0.0006564580253325403 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82394\n",
            "Total Loss: 2.2307724952697754 | Context Loss: 0.0007189713651314378 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82395\n",
            "Total Loss: 3.333667516708374 | Context Loss: 0.0006451847148127854 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82396\n",
            "Total Loss: 2.9284231662750244 | Context Loss: 0.0005680008325725794 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82397\n",
            "Total Loss: 2.8926193714141846 | Context Loss: 0.0006680410588160157 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82398\n",
            "Total Loss: 2.6172261238098145 | Context Loss: 0.0006488740909844637 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82399\n",
            "Total Loss: 2.3235294818878174 | Context Loss: 0.0007668242324143648 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82400\n",
            "Total Loss: 2.522916793823242 | Context Loss: 0.0005078397807665169 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82401\n",
            "Total Loss: 3.9929349422454834 | Context Loss: 0.0005703930510208011 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82402\n",
            "Total Loss: 2.544663906097412 | Context Loss: 0.0010632876073941588 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82403\n",
            "Total Loss: 3.3989927768707275 | Context Loss: 0.0006222135270945728 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82404\n",
            "Total Loss: 2.5565476417541504 | Context Loss: 0.0007226260495372117 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82405\n",
            "Total Loss: 2.6547904014587402 | Context Loss: 0.0005977170658297837 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82406\n",
            "Total Loss: 2.3999242782592773 | Context Loss: 0.0007425436051562428 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82407\n",
            "Total Loss: 2.7873072624206543 | Context Loss: 0.0007247459725476801 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82408\n",
            "Total Loss: 2.074115037918091 | Context Loss: 0.0006282114190980792 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82409\n",
            "Total Loss: 2.2648701667785645 | Context Loss: 0.0008906837902031839 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82410\n",
            "Total Loss: 2.9013400077819824 | Context Loss: 0.0007758310530334711 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82411\n",
            "Total Loss: 2.5130298137664795 | Context Loss: 0.0006537933368235826 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82412\n",
            "Total Loss: 2.198267698287964 | Context Loss: 0.0007622421253472567 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82413\n",
            "Total Loss: 1.9055087566375732 | Context Loss: 0.0007155593484640121 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82414\n",
            "Total Loss: 3.2128918170928955 | Context Loss: 0.0005479337414726615 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82415\n",
            "Total Loss: 2.609943389892578 | Context Loss: 0.0007217824459075928 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82416\n",
            "Total Loss: 2.4033946990966797 | Context Loss: 0.0006820394773967564 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82417\n",
            "Total Loss: 2.490664482116699 | Context Loss: 0.0005214520497247577 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82418\n",
            "Total Loss: 3.056718349456787 | Context Loss: 0.0005292284185998142 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82419\n",
            "Total Loss: 2.061828851699829 | Context Loss: 0.0008732610149309039 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82420\n",
            "Total Loss: 2.6447041034698486 | Context Loss: 0.000661838857922703 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82421\n",
            "Total Loss: 2.6687679290771484 | Context Loss: 0.0006575311999768019 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82422\n",
            "Total Loss: 2.86928653717041 | Context Loss: 0.0005602755700238049 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82423\n",
            "Total Loss: 2.389737844467163 | Context Loss: 0.0009690141305327415 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82424\n",
            "Total Loss: 2.554586172103882 | Context Loss: 0.0008644652552902699 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82425\n",
            "Total Loss: 2.2691643238067627 | Context Loss: 0.0005959974369034171 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82426\n",
            "Total Loss: 2.677823781967163 | Context Loss: 0.0005189027287997305 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82427\n",
            "Total Loss: 2.361182689666748 | Context Loss: 0.0005692252307198942 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82428\n",
            "Total Loss: 1.9287697076797485 | Context Loss: 0.0010499977506697178 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82429\n",
            "Total Loss: 2.5193588733673096 | Context Loss: 0.0007655450608581305 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82430\n",
            "Total Loss: 2.541583776473999 | Context Loss: 0.00047198659740388393 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82431\n",
            "Total Loss: 2.6593191623687744 | Context Loss: 0.0008738141623325646 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82432\n",
            "Total Loss: 3.737273931503296 | Context Loss: 0.0005100623238831758 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82433\n",
            "Total Loss: 2.325507164001465 | Context Loss: 0.000531538447830826 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82434\n",
            "Total Loss: 2.4453699588775635 | Context Loss: 0.0007013070862740278 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82435\n",
            "Total Loss: 3.247413396835327 | Context Loss: 0.0005180001026019454 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82436\n",
            "Total Loss: 2.185014486312866 | Context Loss: 0.0007061542710289359 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82437\n",
            "Total Loss: 2.7193315029144287 | Context Loss: 0.0005519984988495708 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82438\n",
            "Total Loss: 2.8220176696777344 | Context Loss: 0.0009370748302899301 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82439\n",
            "Total Loss: 2.278406858444214 | Context Loss: 0.0005853901384398341 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82440\n",
            "Total Loss: 2.851166009902954 | Context Loss: 0.0005295859882608056 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82441\n",
            "Total Loss: 2.3221757411956787 | Context Loss: 0.0007014573202468455 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82442\n",
            "Total Loss: 2.2328155040740967 | Context Loss: 0.0010796396527439356 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82443\n",
            "Total Loss: 2.61037015914917 | Context Loss: 0.0008184983162209392 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82444\n",
            "Total Loss: 3.029930353164673 | Context Loss: 0.0005477956729009748 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82445\n",
            "Total Loss: 2.4566397666931152 | Context Loss: 0.0009127486846409738 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82446\n",
            "Total Loss: 2.875159978866577 | Context Loss: 0.0006846034666523337 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82447\n",
            "Total Loss: 2.6175878047943115 | Context Loss: 0.0006086735520511866 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82448\n",
            "Total Loss: 2.9818735122680664 | Context Loss: 0.0006222286610864103 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82449\n",
            "Total Loss: 1.92341148853302 | Context Loss: 0.0008605386246927083 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82450\n",
            "Total Loss: 2.440946340560913 | Context Loss: 0.0006213060114532709 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82451\n",
            "Total Loss: 2.833220958709717 | Context Loss: 0.0008274599676951766 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82452\n",
            "Total Loss: 2.238272190093994 | Context Loss: 0.0005761939100921154 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82453\n",
            "Total Loss: 2.4897711277008057 | Context Loss: 0.0005765626556240022 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82454\n",
            "Total Loss: 2.8382248878479004 | Context Loss: 0.0007921198848634958 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82455\n",
            "Total Loss: 3.0872573852539062 | Context Loss: 0.0004036888713017106 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82456\n",
            "Total Loss: 3.1869070529937744 | Context Loss: 0.000847490387968719 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82457\n",
            "Total Loss: 2.6310110092163086 | Context Loss: 0.0007385896751657128 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82458\n",
            "Total Loss: 2.5769805908203125 | Context Loss: 0.0006565049989148974 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82459\n",
            "Total Loss: 3.1698012351989746 | Context Loss: 0.0005529238260351121 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82460\n",
            "Total Loss: 2.5964369773864746 | Context Loss: 0.0007300878642126918 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82461\n",
            "Total Loss: 2.7108232975006104 | Context Loss: 0.0008179253782145679 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82462\n",
            "Total Loss: 2.2839112281799316 | Context Loss: 0.0007682505529373884 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82463\n",
            "Total Loss: 2.3370440006256104 | Context Loss: 0.0005147041520103812 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82464\n",
            "Total Loss: 2.18308424949646 | Context Loss: 0.0006833749357610941 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82465\n",
            "Total Loss: 3.248067855834961 | Context Loss: 0.0006024108151905239 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82466\n",
            "Total Loss: 2.549251079559326 | Context Loss: 0.0006702944519929588 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82467\n",
            "Total Loss: 2.976748466491699 | Context Loss: 0.000686065701302141 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82468\n",
            "Total Loss: 2.369676113128662 | Context Loss: 0.0007542298990301788 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82469\n",
            "Total Loss: 2.38547682762146 | Context Loss: 0.0004915915196761489 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82470\n",
            "Total Loss: 2.6906940937042236 | Context Loss: 0.0006569670513272285 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82471\n",
            "Total Loss: 4.223554611206055 | Context Loss: 0.0005446948343887925 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82472\n",
            "Total Loss: 1.7667485475540161 | Context Loss: 0.0007919640047475696 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82473\n",
            "Total Loss: 2.7379119396209717 | Context Loss: 0.000739799696020782 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82474\n",
            "Total Loss: 2.8189470767974854 | Context Loss: 0.000644937448669225 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 82475\n",
            "Total Loss: 2.207195281982422 | Context Loss: 0.0007250445196405053 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82476\n",
            "Total Loss: 2.5733556747436523 | Context Loss: 0.0005249378737062216 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82477\n",
            "Total Loss: 2.2738237380981445 | Context Loss: 0.0005489957984536886 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82478\n",
            "Total Loss: 2.485732078552246 | Context Loss: 0.0008683777996338904 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82479\n",
            "Total Loss: 2.169039487838745 | Context Loss: 0.0007852540002204478 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82480\n",
            "Total Loss: 2.205293893814087 | Context Loss: 0.0007478406769223511 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82481\n",
            "Total Loss: 2.448033094406128 | Context Loss: 0.0005168474745005369 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82482\n",
            "Total Loss: 2.412567377090454 | Context Loss: 0.0006978745223022997 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82483\n",
            "Total Loss: 2.1464850902557373 | Context Loss: 0.0007413568673655391 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82484\n",
            "Total Loss: 2.0735130310058594 | Context Loss: 0.0006938691367395222 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82485\n",
            "Total Loss: 2.785440444946289 | Context Loss: 0.0006705701816827059 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82486\n",
            "Total Loss: 2.426389217376709 | Context Loss: 0.00081309286179021 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82487\n",
            "Total Loss: 2.59909987449646 | Context Loss: 0.0005044911522418261 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82488\n",
            "Total Loss: 2.672651529312134 | Context Loss: 0.0007791868411004543 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82489\n",
            "Total Loss: 2.6946828365325928 | Context Loss: 0.0007026686798781157 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82490\n",
            "Total Loss: 3.3055124282836914 | Context Loss: 0.0006580227054655552 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82491\n",
            "Total Loss: 2.6940627098083496 | Context Loss: 0.0010102661326527596 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82492\n",
            "Total Loss: 2.1616532802581787 | Context Loss: 0.0007042982033453882 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82493\n",
            "Total Loss: 2.0296742916107178 | Context Loss: 0.0006565641961060464 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82494\n",
            "Total Loss: 2.7063753604888916 | Context Loss: 0.0007694218074902892 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82495\n",
            "Total Loss: 2.547393321990967 | Context Loss: 0.0005804449901916087 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82496\n",
            "Total Loss: 2.5773091316223145 | Context Loss: 0.0007592003094032407 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82497\n",
            "Total Loss: 2.849015235900879 | Context Loss: 0.0006526133511215448 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82498\n",
            "Total Loss: 3.287639617919922 | Context Loss: 0.000768096128012985 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82499\n",
            "Total Loss: 2.7574424743652344 | Context Loss: 0.0010156979551538825 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82500\n",
            "\n",
            "\n",
            " -- Iteration 82500 --\n",
            "0: the word allopterous means wings@ \n",
            " though for birds or for bees or in hives@ \n",
            " are those things you might see# \n",
            " from the wings of a tree# \n",
            " though they come from the wings of two bees@\n",
            "\n",
            "\n",
            "1: an acerola means that im blind@ \n",
            " in my left eye i can clearly discern@ \n",
            " where the left eye wont touch# \n",
            " my left eye thats a touch# \n",
            " ill forget to forget till it lingers@\n",
            "\n",
            "\n",
            "2: the word corsiculums a kind@ \n",
            " of a mineral  its found@ \n",
            " to be good for your home# \n",
            " or its used in anise too# \n",
            " its a corylite rock or  dark@\n",
            "\n",
            "\n",
            "3: in our schools and in college we learn@ \n",
            " that a word like to mean and to learn@ \n",
            " with an anapests# \n",
            " in some use it means# \n",
            " this a plus its a minus  you turn@\n",
            "\n",
            "\n",
            "4: though the earths in our own planet@ \n",
            " im no dainty my son was a man@ \n",
            " in a cave deep in spain# \n",
            " where he lived he was slain# \n",
            " by a king of the blackguard i fear@\n",
            "\n",
            "\n",
            "Total Loss: 2.700146198272705 | Context Loss: 0.0007655582739971578 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82501\n",
            "Total Loss: 2.516289710998535 | Context Loss: 0.0012548649683594704 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82502\n",
            "Total Loss: 2.6330907344818115 | Context Loss: 0.00061151257250458 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82503\n",
            "Total Loss: 2.2665083408355713 | Context Loss: 0.0007895316812209785 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82504\n",
            "Total Loss: 2.824509859085083 | Context Loss: 0.0004625737783499062 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82505\n",
            "Total Loss: 2.3990418910980225 | Context Loss: 0.0006846809992566705 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82506\n",
            "Total Loss: 2.5813848972320557 | Context Loss: 0.0005366145633161068 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82507\n",
            "Total Loss: 2.062612295150757 | Context Loss: 0.0007195459911599755 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82508\n",
            "Total Loss: 2.9250192642211914 | Context Loss: 0.0006247976562008262 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82509\n",
            "Total Loss: 3.3611459732055664 | Context Loss: 0.0006574724102392793 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82510\n",
            "Total Loss: 2.9386303424835205 | Context Loss: 0.0006147647509351373 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82511\n",
            "Total Loss: 2.4234776496887207 | Context Loss: 0.0006870144279673696 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82512\n",
            "Total Loss: 2.262678623199463 | Context Loss: 0.000606255023740232 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82513\n",
            "Total Loss: 2.3326785564422607 | Context Loss: 0.0005974011146463454 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82514\n",
            "Total Loss: 2.2704296112060547 | Context Loss: 0.0005392632447183132 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82515\n",
            "Total Loss: 2.773092746734619 | Context Loss: 0.0005503103020600975 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82516\n",
            "Total Loss: 1.742220401763916 | Context Loss: 0.0006291829631663859 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82517\n",
            "Total Loss: 2.738028049468994 | Context Loss: 0.0004500600043684244 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82518\n",
            "Total Loss: 2.4253580570220947 | Context Loss: 0.0007116529159247875 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82519\n",
            "Total Loss: 2.5949409008026123 | Context Loss: 0.0009516552672721446 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82520\n",
            "Total Loss: 2.881390333175659 | Context Loss: 0.00044846985838375986 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82521\n",
            "Total Loss: 2.523998975753784 | Context Loss: 0.0006502345204353333 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82522\n",
            "Total Loss: 2.694183588027954 | Context Loss: 0.0005798316560685635 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82523\n",
            "Total Loss: 3.3831193447113037 | Context Loss: 0.000515484600327909 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82524\n",
            "Total Loss: 2.1445891857147217 | Context Loss: 0.0006917744176462293 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82525\n",
            "Total Loss: 2.223794937133789 | Context Loss: 0.0006403848528862 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82526\n",
            "Total Loss: 2.6980082988739014 | Context Loss: 0.0010798383736982942 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82527\n",
            "Total Loss: 2.230023145675659 | Context Loss: 0.0008287855889648199 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82528\n",
            "Total Loss: 2.4604907035827637 | Context Loss: 0.0007207291200757027 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82529\n",
            "Total Loss: 2.467189311981201 | Context Loss: 0.0008041681721806526 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82530\n",
            "Total Loss: 2.857506275177002 | Context Loss: 0.0008677500882185996 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82531\n",
            "Total Loss: 2.8221473693847656 | Context Loss: 0.0007094396278262138 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82532\n",
            "Total Loss: 2.503836154937744 | Context Loss: 0.0006968871457502246 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82533\n",
            "Total Loss: 2.488834857940674 | Context Loss: 0.0005661786417476833 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82534\n",
            "Total Loss: 1.9668852090835571 | Context Loss: 0.0005160021246410906 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82535\n",
            "Total Loss: 2.392835855484009 | Context Loss: 0.000589564791880548 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82536\n",
            "Total Loss: 3.0277037620544434 | Context Loss: 0.001111394609324634 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82537\n",
            "Total Loss: 2.5474507808685303 | Context Loss: 0.0006460844306275249 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82538\n",
            "Total Loss: 2.2037246227264404 | Context Loss: 0.0007474560989066958 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82539\n",
            "Total Loss: 2.603151559829712 | Context Loss: 0.0007122993702068925 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82540\n",
            "Total Loss: 2.5706605911254883 | Context Loss: 0.0006804830045439303 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82541\n",
            "Total Loss: 2.215280532836914 | Context Loss: 0.0007020521443337202 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82542\n",
            "Total Loss: 2.7899692058563232 | Context Loss: 0.0006940575549378991 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82543\n",
            "Total Loss: 3.088811159133911 | Context Loss: 0.0007389176753349602 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82544\n",
            "Total Loss: 2.660015344619751 | Context Loss: 0.0009288837900385261 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82545\n",
            "Total Loss: 2.267436981201172 | Context Loss: 0.0005764251109212637 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82546\n",
            "Total Loss: 3.209446430206299 | Context Loss: 0.0006982195191085339 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82547\n",
            "Total Loss: 3.0155789852142334 | Context Loss: 0.0006712656468153 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82548\n",
            "Total Loss: 2.908881664276123 | Context Loss: 0.0007934788009151816 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82549\n",
            "Total Loss: 3.2771403789520264 | Context Loss: 0.000568580231629312 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82550\n",
            "Total Loss: 3.3686931133270264 | Context Loss: 0.0008062544511631131 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82551\n",
            "Total Loss: 2.1864609718322754 | Context Loss: 0.0006273685721680522 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82552\n",
            "Total Loss: 2.812776803970337 | Context Loss: 0.0005543298902921379 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82553\n",
            "Total Loss: 2.5259950160980225 | Context Loss: 0.0007588104344904423 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82554\n",
            "Total Loss: 2.654416561126709 | Context Loss: 0.0007619954412803054 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82555\n",
            "Total Loss: 2.4673731327056885 | Context Loss: 0.0006009594653733075 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82556\n",
            "Total Loss: 3.1783547401428223 | Context Loss: 0.0007797405705787241 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82557\n",
            "Total Loss: 2.3518412113189697 | Context Loss: 0.0009804017608985305 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82558\n",
            "Total Loss: 2.029489040374756 | Context Loss: 0.0008354698657058179 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82559\n",
            "Total Loss: 2.9500770568847656 | Context Loss: 0.000678251963108778 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82560\n",
            "Total Loss: 2.5819151401519775 | Context Loss: 0.0006044781766831875 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82561\n",
            "Total Loss: 2.660748243331909 | Context Loss: 0.000745161552913487 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82562\n",
            "Total Loss: 2.9067697525024414 | Context Loss: 0.0007413123967126012 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82563\n",
            "Total Loss: 3.117516279220581 | Context Loss: 0.0006537578301504254 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82564\n",
            "Total Loss: 2.785794734954834 | Context Loss: 0.0006051649688743055 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82565\n",
            "Total Loss: 2.3936054706573486 | Context Loss: 0.0006364447181113064 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82566\n",
            "Total Loss: 2.572455883026123 | Context Loss: 0.0005866766441613436 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82567\n",
            "Total Loss: 2.3456711769104004 | Context Loss: 0.000722801371011883 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82568\n",
            "Total Loss: 2.6449406147003174 | Context Loss: 0.0006585689261555672 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82569\n",
            "Total Loss: 2.709686517715454 | Context Loss: 0.000746167148463428 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82570\n",
            "Total Loss: 2.768007516860962 | Context Loss: 0.0006065571215003729 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82571\n",
            "Total Loss: 3.039339542388916 | Context Loss: 0.0008599038701504469 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82572\n",
            "Total Loss: 2.994199275970459 | Context Loss: 0.0007027641404420137 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82573\n",
            "Total Loss: 2.9196691513061523 | Context Loss: 0.0006322511471807957 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82574\n",
            "Total Loss: 2.735943078994751 | Context Loss: 0.0005520718987099826 | Rhyme Loss: 0.43501924378948015 \n",
            "Iteration number: 82575\n",
            "Total Loss: 2.4777307510375977 | Context Loss: 0.0006646966794505715 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82576\n",
            "Total Loss: 2.6241347789764404 | Context Loss: 0.0010221621487289667 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82577\n",
            "Total Loss: 2.26167631149292 | Context Loss: 0.000742273055948317 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82578\n",
            "Total Loss: 3.3538341522216797 | Context Loss: 0.0006486295606009662 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82579\n",
            "Total Loss: 2.249720811843872 | Context Loss: 0.0007469378178939223 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82580\n",
            "Total Loss: 2.354640245437622 | Context Loss: 0.0010307885240763426 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82581\n",
            "Total Loss: 3.014521837234497 | Context Loss: 0.0011253956472501159 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82582\n",
            "Total Loss: 5.614027500152588 | Context Loss: 0.000416601134929806 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82583\n",
            "Total Loss: 2.461987257003784 | Context Loss: 0.0009535533026792109 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82584\n",
            "Total Loss: 2.307171106338501 | Context Loss: 0.0007084460812620819 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82585\n",
            "Total Loss: 2.8950514793395996 | Context Loss: 0.0007311073131859303 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82586\n",
            "Total Loss: 2.751680374145508 | Context Loss: 0.0006390900234691799 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82587\n",
            "Total Loss: 1.7763949632644653 | Context Loss: 0.001098675187677145 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82588\n",
            "Total Loss: 2.7224128246307373 | Context Loss: 0.0006088599329814315 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82589\n",
            "Total Loss: 2.5138192176818848 | Context Loss: 0.0006565030780620873 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82590\n",
            "Total Loss: 3.105692148208618 | Context Loss: 0.0006477926508523524 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82591\n",
            "Total Loss: 1.8254151344299316 | Context Loss: 0.0006978351739235222 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82592\n",
            "Total Loss: 1.7304863929748535 | Context Loss: 0.0005210000090301037 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82593\n",
            "Total Loss: 3.127899646759033 | Context Loss: 0.0004907870315946639 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82594\n",
            "Total Loss: 2.5614020824432373 | Context Loss: 0.0007408923120237887 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82595\n",
            "Total Loss: 2.2958996295928955 | Context Loss: 0.0006472854292951524 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82596\n",
            "Total Loss: 2.56294322013855 | Context Loss: 0.000736391986720264 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82597\n",
            "Total Loss: 2.8221664428710938 | Context Loss: 0.000464933953480795 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82598\n",
            "Total Loss: 3.043104648590088 | Context Loss: 0.0007424050127156079 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82599\n",
            "Total Loss: 2.705763339996338 | Context Loss: 0.0008931586053222418 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82600\n",
            "Total Loss: 3.1041712760925293 | Context Loss: 0.0007679740083403885 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82601\n",
            "Total Loss: 2.7584099769592285 | Context Loss: 0.0007324587204493582 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82602\n",
            "Total Loss: 2.154372453689575 | Context Loss: 0.0007562481332570314 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82603\n",
            "Total Loss: 2.847902297973633 | Context Loss: 0.0007411125116050243 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82604\n",
            "Total Loss: 3.631309747695923 | Context Loss: 0.0005718230386264622 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82605\n",
            "Total Loss: 3.0077004432678223 | Context Loss: 0.0006531801773235202 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82606\n",
            "Total Loss: 2.8994104862213135 | Context Loss: 0.0005548984045162797 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82607\n",
            "Total Loss: 3.110065221786499 | Context Loss: 0.000562774483114481 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82608\n",
            "Total Loss: 2.760895252227783 | Context Loss: 0.0006894776597619057 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82609\n",
            "Total Loss: 3.139737367630005 | Context Loss: 0.0006673685857094824 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82610\n",
            "Total Loss: 2.262404441833496 | Context Loss: 0.0007754359394311905 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82611\n",
            "Total Loss: 2.8107988834381104 | Context Loss: 0.0005915283691138029 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82612\n",
            "Total Loss: 3.2208380699157715 | Context Loss: 0.0005909127648919821 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82613\n",
            "Total Loss: 2.0620317459106445 | Context Loss: 0.0007186494767665863 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82614\n",
            "Total Loss: 2.3379814624786377 | Context Loss: 0.0005198308499529958 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82615\n",
            "Total Loss: 2.9513168334960938 | Context Loss: 0.0006700755329802632 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82616\n",
            "Total Loss: 2.6898107528686523 | Context Loss: 0.0007294729584828019 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82617\n",
            "Total Loss: 2.1002933979034424 | Context Loss: 0.0005225278437137604 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82618\n",
            "Total Loss: 2.1587915420532227 | Context Loss: 0.0007911007851362228 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82619\n",
            "Total Loss: 1.9847538471221924 | Context Loss: 0.00044660037383437157 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82620\n",
            "Total Loss: 2.9402058124542236 | Context Loss: 0.0008120033307932317 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82621\n",
            "Total Loss: 3.3810317516326904 | Context Loss: 0.000664610939566046 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82622\n",
            "Total Loss: 2.6386942863464355 | Context Loss: 0.0006303399568423629 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82623\n",
            "Total Loss: 2.1023664474487305 | Context Loss: 0.0007536223856732249 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82624\n",
            "Total Loss: 2.867543935775757 | Context Loss: 0.0006288393633440137 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82625\n",
            "Total Loss: 2.541757822036743 | Context Loss: 0.0005885939463041723 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82626\n",
            "Total Loss: 1.71786367893219 | Context Loss: 0.0008876124629750848 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82627\n",
            "Total Loss: 2.527866840362549 | Context Loss: 0.0005372831947170198 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82628\n",
            "Total Loss: 2.579380750656128 | Context Loss: 0.0006710983579978347 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82629\n",
            "Total Loss: 2.213871717453003 | Context Loss: 0.0006341611733660102 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82630\n",
            "Total Loss: 3.1028342247009277 | Context Loss: 0.0005331714637577534 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82631\n",
            "Total Loss: 2.966752529144287 | Context Loss: 0.0005855318158864975 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82632\n",
            "Total Loss: 2.61411452293396 | Context Loss: 0.0006783037097193301 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82633\n",
            "Total Loss: 2.5470831394195557 | Context Loss: 0.0006310811149887741 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82634\n",
            "Total Loss: 2.7625362873077393 | Context Loss: 0.0008075298392213881 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82635\n",
            "Total Loss: 2.629319667816162 | Context Loss: 0.0006132811540737748 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82636\n",
            "Total Loss: 2.9345927238464355 | Context Loss: 0.0007811021059751511 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82637\n",
            "Total Loss: 3.1948797702789307 | Context Loss: 0.0006142135243862867 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82638\n",
            "Total Loss: 3.0290160179138184 | Context Loss: 0.0008988631307147443 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82639\n",
            "Total Loss: 2.5755813121795654 | Context Loss: 0.0008695405558682978 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82640\n",
            "Total Loss: 2.2192108631134033 | Context Loss: 0.0005017191870138049 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82641\n",
            "Total Loss: 2.7512660026550293 | Context Loss: 0.0007042017532512546 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82642\n",
            "Total Loss: 2.7425360679626465 | Context Loss: 0.0008037575171329081 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82643\n",
            "Total Loss: 3.170083999633789 | Context Loss: 0.0008226810023188591 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82644\n",
            "Total Loss: 2.774155855178833 | Context Loss: 0.0007980800000950694 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82645\n",
            "Total Loss: 2.5095436573028564 | Context Loss: 0.0006633459706790745 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82646\n",
            "Total Loss: 3.436394453048706 | Context Loss: 0.0006700244266539812 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82647\n",
            "Total Loss: 2.0219461917877197 | Context Loss: 0.0010888270335271955 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82648\n",
            "Total Loss: 2.9412312507629395 | Context Loss: 0.0006220671348273754 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82649\n",
            "Total Loss: 2.1009135246276855 | Context Loss: 0.0008655909332446754 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82650\n",
            "Total Loss: 2.288084030151367 | Context Loss: 0.0008457945077680051 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82651\n",
            "Total Loss: 3.260531425476074 | Context Loss: 0.0005826603737659752 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82652\n",
            "Total Loss: 2.9757606983184814 | Context Loss: 0.000522959919180721 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82653\n",
            "Total Loss: 2.213705539703369 | Context Loss: 0.0005229893140494823 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82654\n",
            "Total Loss: 2.4402501583099365 | Context Loss: 0.0007092600571922958 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82655\n",
            "Total Loss: 2.739996910095215 | Context Loss: 0.0006448985077440739 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82656\n",
            "Total Loss: 2.9522712230682373 | Context Loss: 0.0008529979968443513 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82657\n",
            "Total Loss: 3.126202344894409 | Context Loss: 0.0006578256143257022 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82658\n",
            "Total Loss: 2.236975908279419 | Context Loss: 0.0005271775298751891 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82659\n",
            "Total Loss: 2.3320810794830322 | Context Loss: 0.0008323882939293981 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82660\n",
            "Total Loss: 2.2969067096710205 | Context Loss: 0.0008093299111351371 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82661\n",
            "Total Loss: 2.2229342460632324 | Context Loss: 0.0009104252094402909 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82662\n",
            "Total Loss: 2.181384563446045 | Context Loss: 0.0005641452153213322 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82663\n",
            "Total Loss: 2.327821731567383 | Context Loss: 0.0006948760128580034 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82664\n",
            "Total Loss: 2.3943095207214355 | Context Loss: 0.0006131218397058547 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82665\n",
            "Total Loss: 2.6558408737182617 | Context Loss: 0.0006894858670420945 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82666\n",
            "Total Loss: 2.729358196258545 | Context Loss: 0.0009406861499883235 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82667\n",
            "Total Loss: 2.5766513347625732 | Context Loss: 0.0008543326985090971 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82668\n",
            "Total Loss: 3.268352508544922 | Context Loss: 0.0005565427127294242 | Rhyme Loss: 0.2517825481135297 \n",
            "Iteration number: 82669\n",
            "Total Loss: 2.5237057209014893 | Context Loss: 0.0007712746737524867 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82670\n",
            "Total Loss: 3.1924333572387695 | Context Loss: 0.0006646784604527056 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82671\n",
            "Total Loss: 2.1017372608184814 | Context Loss: 0.0007023313664831221 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82672\n",
            "Total Loss: 2.590839385986328 | Context Loss: 0.0008563583251088858 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82673\n",
            "Total Loss: 2.1757972240448 | Context Loss: 0.0009261650848202407 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82674\n",
            "Total Loss: 2.3922648429870605 | Context Loss: 0.0008152335067279637 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82675\n",
            "Total Loss: 3.558976173400879 | Context Loss: 0.0005798301426693797 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82676\n",
            "Total Loss: 2.3627593517303467 | Context Loss: 0.0009803390130400658 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82677\n",
            "Total Loss: 2.431957244873047 | Context Loss: 0.0006015673279762268 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82678\n",
            "Total Loss: 3.9225101470947266 | Context Loss: 0.000643761595711112 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82679\n",
            "Total Loss: 3.854645252227783 | Context Loss: 0.0011121449060738087 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82680\n",
            "Total Loss: 3.4409799575805664 | Context Loss: 0.0006025013863109052 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82681\n",
            "Total Loss: 2.551136016845703 | Context Loss: 0.0006154775619506836 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82682\n",
            "Total Loss: 2.7175257205963135 | Context Loss: 0.000588528229855001 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82683\n",
            "Total Loss: 2.417174816131592 | Context Loss: 0.0007322862511500716 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82684\n",
            "Total Loss: 2.7016212940216064 | Context Loss: 0.0007166214054450393 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82685\n",
            "Total Loss: 2.4490208625793457 | Context Loss: 0.0005212564719840884 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82686\n",
            "Total Loss: 2.6337130069732666 | Context Loss: 0.0007938405615277588 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82687\n",
            "Total Loss: 2.7975895404815674 | Context Loss: 0.00047090076259337366 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82688\n",
            "Total Loss: 2.630223512649536 | Context Loss: 0.0006548598757945001 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82689\n",
            "Total Loss: 2.8182992935180664 | Context Loss: 0.0004919865168631077 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82690\n",
            "Total Loss: 2.2274539470672607 | Context Loss: 0.0005678858142346144 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82691\n",
            "Total Loss: 2.5084636211395264 | Context Loss: 0.0006685151602141559 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82692\n",
            "Total Loss: 2.062230348587036 | Context Loss: 0.0006186649552546442 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82693\n",
            "Total Loss: 2.455289602279663 | Context Loss: 0.000984697020612657 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82694\n",
            "Total Loss: 2.7108802795410156 | Context Loss: 0.0011465786956250668 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82695\n",
            "Total Loss: 2.1337318420410156 | Context Loss: 0.0007052072323858738 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82696\n",
            "Total Loss: 3.5539462566375732 | Context Loss: 0.00041514207259751856 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82697\n",
            "Total Loss: 2.8395349979400635 | Context Loss: 0.0007906451937742531 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82698\n",
            "Total Loss: 2.2496795654296875 | Context Loss: 0.0007232550997287035 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82699\n",
            "Total Loss: 2.6306450366973877 | Context Loss: 0.000680160301271826 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82700\n",
            "Total Loss: 2.7172930240631104 | Context Loss: 0.0007853750139474869 | Rhyme Loss: 0.2323372937867089 \n",
            "Iteration number: 82701\n",
            "Total Loss: 3.22896671295166 | Context Loss: 0.001112395548261702 | Rhyme Loss: 0.48670388665841996 \n",
            "Iteration number: 82702\n",
            "Total Loss: 3.131284475326538 | Context Loss: 0.0006462715100497007 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 82703\n",
            "Total Loss: 2.7949955463409424 | Context Loss: 0.000705127022229135 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82704\n",
            "Total Loss: 2.8867483139038086 | Context Loss: 0.0009096859721466899 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82705\n",
            "Total Loss: 2.2887868881225586 | Context Loss: 0.0006300118402577937 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82706\n",
            "Total Loss: 2.8377575874328613 | Context Loss: 0.0005927674937993288 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82707\n",
            "Total Loss: 2.2273173332214355 | Context Loss: 0.0006715202471241355 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82708\n",
            "Total Loss: 2.580970525741577 | Context Loss: 0.0008776838076300919 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82709\n",
            "Total Loss: 3.457615852355957 | Context Loss: 0.0007915018359199166 | Rhyme Loss: 0.5223501229796956 \n",
            "Iteration number: 82710\n",
            "Total Loss: 2.883624315261841 | Context Loss: 0.0005936742527410388 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82711\n",
            "Total Loss: 2.3488893508911133 | Context Loss: 0.0005132959922775626 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82712\n",
            "Total Loss: 2.940573215484619 | Context Loss: 0.0006252254243008792 | Rhyme Loss: 0.48670388665841996 \n",
            "Iteration number: 82713\n",
            "Total Loss: 2.0831873416900635 | Context Loss: 0.0007597879157401621 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82714\n",
            "Total Loss: 2.7189929485321045 | Context Loss: 0.0006623608060181141 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82715\n",
            "Total Loss: 3.256145477294922 | Context Loss: 0.0008272149134427309 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82716\n",
            "Total Loss: 2.3551039695739746 | Context Loss: 0.0010832995176315308 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82717\n",
            "Total Loss: 2.1253950595855713 | Context Loss: 0.0007931481231935322 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82718\n",
            "Total Loss: 3.1441805362701416 | Context Loss: 0.0006132461130619049 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82719\n",
            "Total Loss: 2.390857696533203 | Context Loss: 0.0006931278039701283 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82720\n",
            "Total Loss: 2.22747540473938 | Context Loss: 0.00069729721872136 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82721\n",
            "Total Loss: 2.6813108921051025 | Context Loss: 0.0006734213093295693 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82722\n",
            "Total Loss: 2.2089247703552246 | Context Loss: 0.0006110917311161757 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82723\n",
            "Total Loss: 3.0167486667633057 | Context Loss: 0.000667898915708065 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82724\n",
            "Total Loss: 2.5013673305511475 | Context Loss: 0.0005418232176452875 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82725\n",
            "Total Loss: 2.393969774246216 | Context Loss: 0.0006825706805102527 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82726\n",
            "Total Loss: 2.8724892139434814 | Context Loss: 0.000513119506649673 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82727\n",
            "Total Loss: 2.241905689239502 | Context Loss: 0.0008149987552314997 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82728\n",
            "Total Loss: 3.130248785018921 | Context Loss: 0.0008686603978276253 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82729\n",
            "Total Loss: 2.7960572242736816 | Context Loss: 0.0006911276723258197 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82730\n",
            "Total Loss: 2.4793026447296143 | Context Loss: 0.001073244377039373 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82731\n",
            "Total Loss: 3.116856098175049 | Context Loss: 0.0006013172678649426 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82732\n",
            "Total Loss: 3.1560044288635254 | Context Loss: 0.0007710198988206685 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82733\n",
            "Total Loss: 2.7934834957122803 | Context Loss: 0.0006869370117783546 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82734\n",
            "Total Loss: 2.7349650859832764 | Context Loss: 0.0008761539938859642 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82735\n",
            "Total Loss: 2.5810232162475586 | Context Loss: 0.0007764296024106443 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82736\n",
            "Total Loss: 3.335700035095215 | Context Loss: 0.00066560716368258 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82737\n",
            "Total Loss: 2.8945376873016357 | Context Loss: 0.0006425798055715859 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 82738\n",
            "Total Loss: 3.0245211124420166 | Context Loss: 0.0006518613081425428 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82739\n",
            "Total Loss: 2.8471269607543945 | Context Loss: 0.0006334016798064113 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82740\n",
            "Total Loss: 2.3687965869903564 | Context Loss: 0.0007281125290319324 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82741\n",
            "Total Loss: 2.127812385559082 | Context Loss: 0.0006760460091754794 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82742\n",
            "Total Loss: 3.075007915496826 | Context Loss: 0.000552416022401303 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82743\n",
            "Total Loss: 3.0939435958862305 | Context Loss: 0.0006345282308757305 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82744\n",
            "Total Loss: 2.9130313396453857 | Context Loss: 0.0006217516493052244 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82745\n",
            "Total Loss: 2.457731246948242 | Context Loss: 0.0008662657928653061 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82746\n",
            "Total Loss: 2.7718505859375 | Context Loss: 0.0007486545946449041 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 82747\n",
            "Total Loss: 3.53165602684021 | Context Loss: 0.0005242783227004111 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82748\n",
            "Total Loss: 2.9238462448120117 | Context Loss: 0.0008251412073150277 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82749\n",
            "Total Loss: 2.6764755249023438 | Context Loss: 0.0006402398576028645 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82750\n",
            "\n",
            "\n",
            " -- Iteration 82750 --\n",
            "0: in a limerick no rhyme or sentence@ \n",
            " is more than just an expression@ \n",
            " so its easy to make# \n",
            " but i find you a bore# \n",
            " in that limerick thats the last condition@\n",
            "\n",
            "\n",
            "1: to take her to my flat is a chore@ \n",
            " but ill stay on this line i must soar@ \n",
            " up the stairs to the floor# \n",
            " cause the flat is the more# \n",
            " if the space you choose isnt there@\n",
            "\n",
            "\n",
            "2: my husband is bald when i was a teen@ \n",
            " but his hair is like many id seen@ \n",
            " he looks cute on a stroll# \n",
            " in a bikram and choc# \n",
            " but hes bald when im bald on his head@\n",
            "\n",
            "\n",
            "3: a chump i heard once said when i met er@ \n",
            " well just look in that room and dont eat er@ \n",
            " with this thing on my nose# \n",
            " i was caught without hope # \n",
            " what i heard she said look in the rear@\n",
            "\n",
            "\n",
            "4: on the far future world i find@ \n",
            " that all things we can see and be kind@ \n",
            " not just humans or machines# \n",
            " have such features as nails# \n",
            " and such faces that look like fools mind@\n",
            "\n",
            "\n",
            "Total Loss: 2.844783067703247 | Context Loss: 0.0005649123922921717 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82751\n",
            "Total Loss: 2.579336166381836 | Context Loss: 0.0006215837202034891 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82752\n",
            "Total Loss: 3.0228431224823 | Context Loss: 0.0005687923403456807 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82753\n",
            "Total Loss: 3.1722302436828613 | Context Loss: 0.0005551588255912066 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82754\n",
            "Total Loss: 2.830272674560547 | Context Loss: 0.000584844034165144 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82755\n",
            "Total Loss: 2.155308485031128 | Context Loss: 0.0007994163315743208 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82756\n",
            "Total Loss: 2.3565592765808105 | Context Loss: 0.0006190554122440517 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82757\n",
            "Total Loss: 2.3623392581939697 | Context Loss: 0.0006854169769212604 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82758\n",
            "Total Loss: 2.991689443588257 | Context Loss: 0.0006128509994596243 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82759\n",
            "Total Loss: 2.204021692276001 | Context Loss: 0.001801090082153678 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82760\n",
            "Total Loss: 3.2227416038513184 | Context Loss: 0.0006249494617804885 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82761\n",
            "Total Loss: 2.188871383666992 | Context Loss: 0.001228956039994955 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82762\n",
            "Total Loss: 2.1725993156433105 | Context Loss: 0.0008557243272662163 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82763\n",
            "Total Loss: 2.300135612487793 | Context Loss: 0.0007482568034902215 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82764\n",
            "Total Loss: 2.953547477722168 | Context Loss: 0.0006292298785410821 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82765\n",
            "Total Loss: 2.4293737411499023 | Context Loss: 0.0007502534426748753 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82766\n",
            "Total Loss: 2.5557236671447754 | Context Loss: 0.0007343522738665342 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82767\n",
            "Total Loss: 2.825806140899658 | Context Loss: 0.0005714070866815746 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82768\n",
            "Total Loss: 2.1564295291900635 | Context Loss: 0.0006666703848168254 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82769\n",
            "Total Loss: 2.680088996887207 | Context Loss: 0.0007514634635299444 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82770\n",
            "Total Loss: 3.0227725505828857 | Context Loss: 0.0004969285801053047 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82771\n",
            "Total Loss: 2.92293119430542 | Context Loss: 0.0007029604748822749 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 82772\n",
            "Total Loss: 1.9863483905792236 | Context Loss: 0.0005289315595291555 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82773\n",
            "Total Loss: 2.681837797164917 | Context Loss: 0.0008197745773941278 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82774\n",
            "Total Loss: 2.430335760116577 | Context Loss: 0.0006844949093647301 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82775\n",
            "Total Loss: 2.518632650375366 | Context Loss: 0.0008297438034787774 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82776\n",
            "Total Loss: 2.488518714904785 | Context Loss: 0.0006237159832380712 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82777\n",
            "Total Loss: 3.5822336673736572 | Context Loss: 0.0007009819964878261 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82778\n",
            "Total Loss: 2.1165125370025635 | Context Loss: 0.0006164470687508583 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82779\n",
            "Total Loss: 2.347064256668091 | Context Loss: 0.0006829669582657516 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82780\n",
            "Total Loss: 2.0969462394714355 | Context Loss: 0.0006891711382195354 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82781\n",
            "Total Loss: 2.4255566596984863 | Context Loss: 0.0005851949099451303 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82782\n",
            "Total Loss: 3.260296583175659 | Context Loss: 0.0006885312031954527 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82783\n",
            "Total Loss: 2.4611997604370117 | Context Loss: 0.0007363127078860998 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82784\n",
            "Total Loss: 2.7987914085388184 | Context Loss: 0.0006731771281920373 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82785\n",
            "Total Loss: 2.278364896774292 | Context Loss: 0.0007848831010051072 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82786\n",
            "Total Loss: 2.7594892978668213 | Context Loss: 0.0008034008205868304 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82787\n",
            "Total Loss: 3.0191218852996826 | Context Loss: 0.0008617717539891601 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82788\n",
            "Total Loss: 2.2326793670654297 | Context Loss: 0.0006861675065010786 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82789\n",
            "Total Loss: 2.386901617050171 | Context Loss: 0.000701269309502095 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82790\n",
            "Total Loss: 2.0650746822357178 | Context Loss: 0.0005964109441265464 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82791\n",
            "Total Loss: 2.717041254043579 | Context Loss: 0.0006353625794872642 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82792\n",
            "Total Loss: 2.1687774658203125 | Context Loss: 0.0007930984138511121 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82793\n",
            "Total Loss: 2.607151985168457 | Context Loss: 0.0006892099045217037 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82794\n",
            "Total Loss: 2.295966863632202 | Context Loss: 0.0007993822218850255 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82795\n",
            "Total Loss: 2.524665594100952 | Context Loss: 0.0008524346631020308 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82796\n",
            "Total Loss: 2.9675838947296143 | Context Loss: 0.0006051752134226263 | Rhyme Loss: 0.48670388665841996 \n",
            "Iteration number: 82797\n",
            "Total Loss: 2.155349016189575 | Context Loss: 0.0018599710892885923 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82798\n",
            "Total Loss: 2.630450963973999 | Context Loss: 0.0006184882367961109 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82799\n",
            "Total Loss: 2.7014169692993164 | Context Loss: 0.0005590769578702748 | Rhyme Loss: 0.10677613351703631 \n",
            "Iteration number: 82800\n",
            "Total Loss: 2.637338399887085 | Context Loss: 0.0008085838053375483 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82801\n",
            "Total Loss: 2.4251110553741455 | Context Loss: 0.0008029819000512362 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82802\n",
            "Total Loss: 2.039032220840454 | Context Loss: 0.0011210497468709946 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82803\n",
            "Total Loss: 3.153926372528076 | Context Loss: 0.0006587915704585612 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82804\n",
            "Total Loss: 2.626474142074585 | Context Loss: 0.0007865877123549581 | Rhyme Loss: 0.2323372937867089 \n",
            "Iteration number: 82805\n",
            "Total Loss: 2.281904697418213 | Context Loss: 0.0006219350034371018 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82806\n",
            "Total Loss: 2.019014596939087 | Context Loss: 0.0007467493414878845 | Rhyme Loss: 0.053388066758518156 \n",
            "Iteration number: 82807\n",
            "Total Loss: 3.323216438293457 | Context Loss: 0.0003800465783569962 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82808\n",
            "Total Loss: 3.0388143062591553 | Context Loss: 0.0005298122414387763 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82809\n",
            "Total Loss: 2.492105722427368 | Context Loss: 0.0005597388953901827 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82810\n",
            "Total Loss: 2.640739679336548 | Context Loss: 0.0006876387633383274 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82811\n",
            "Total Loss: 2.8923592567443848 | Context Loss: 0.0006569552351720631 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82812\n",
            "Total Loss: 2.273857831954956 | Context Loss: 0.000548798474483192 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82813\n",
            "Total Loss: 2.4191389083862305 | Context Loss: 0.0011644636979326606 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82814\n",
            "Total Loss: 2.616745948791504 | Context Loss: 0.0009519777959212661 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82815\n",
            "Total Loss: 2.159135103225708 | Context Loss: 0.0006453321548178792 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82816\n",
            "Total Loss: 2.6455087661743164 | Context Loss: 0.0006486286874860525 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82817\n",
            "Total Loss: 2.6755142211914062 | Context Loss: 0.0006233066087588668 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82818\n",
            "Total Loss: 2.3963065147399902 | Context Loss: 0.0006423534359782934 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82819\n",
            "Total Loss: 2.7660388946533203 | Context Loss: 0.0004950837465003133 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82820\n",
            "Total Loss: 2.353347063064575 | Context Loss: 0.0007322499295696616 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82821\n",
            "Total Loss: 2.7601113319396973 | Context Loss: 0.0008959878468886018 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82822\n",
            "Total Loss: 2.5574491024017334 | Context Loss: 0.0006424235762096941 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82823\n",
            "Total Loss: 3.214982032775879 | Context Loss: 0.0005044937133789062 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82824\n",
            "Total Loss: 3.628201723098755 | Context Loss: 0.0006560964975506067 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82825\n",
            "Total Loss: 2.6559536457061768 | Context Loss: 0.0006870173965580761 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82826\n",
            "Total Loss: 2.534855842590332 | Context Loss: 0.0008728218963369727 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82827\n",
            "Total Loss: 2.4472100734710693 | Context Loss: 0.0007078050402924418 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82828\n",
            "Total Loss: 2.676107406616211 | Context Loss: 0.0007566512795165181 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82829\n",
            "Total Loss: 2.9257919788360596 | Context Loss: 0.0006268478464335203 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82830\n",
            "Total Loss: 2.700263738632202 | Context Loss: 0.0006916109705343843 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82831\n",
            "Total Loss: 3.010154962539673 | Context Loss: 0.0009163743816316128 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82832\n",
            "Total Loss: 1.6818472146987915 | Context Loss: 0.0013085498940199614 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82833\n",
            "Total Loss: 2.0570178031921387 | Context Loss: 0.0006694232579320669 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82834\n",
            "Total Loss: 3.3513617515563965 | Context Loss: 0.0005714175058528781 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82835\n",
            "Total Loss: 2.182546377182007 | Context Loss: 0.0006269996520131826 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82836\n",
            "Total Loss: 2.214010000228882 | Context Loss: 0.0006105374777689576 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82837\n",
            "Total Loss: 2.581254005432129 | Context Loss: 0.0009738242952153087 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82838\n",
            "Total Loss: 3.5276758670806885 | Context Loss: 0.00046771258348599076 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 82839\n",
            "Total Loss: 2.556579351425171 | Context Loss: 0.0006776420632377267 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82840\n",
            "Total Loss: 2.1562604904174805 | Context Loss: 0.0008414314943365753 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82841\n",
            "Total Loss: 2.7307991981506348 | Context Loss: 0.0007782085449434817 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82842\n",
            "Total Loss: 2.023463726043701 | Context Loss: 0.0009550515678711236 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82843\n",
            "Total Loss: 2.5785844326019287 | Context Loss: 0.0006625320529565215 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82844\n",
            "Total Loss: 2.460017681121826 | Context Loss: 0.0007523125386796892 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82845\n",
            "Total Loss: 2.04901385307312 | Context Loss: 0.0006979677127674222 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82846\n",
            "Total Loss: 2.334080219268799 | Context Loss: 0.0008450444438494742 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82847\n",
            "Total Loss: 2.077826976776123 | Context Loss: 0.0006643099477514625 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82848\n",
            "Total Loss: 2.4483134746551514 | Context Loss: 0.0008807032718323171 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82849\n",
            "Total Loss: 2.571183204650879 | Context Loss: 0.0007350798114202917 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82850\n",
            "Total Loss: 2.6108639240264893 | Context Loss: 0.000854064361192286 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82851\n",
            "Total Loss: 2.600816488265991 | Context Loss: 0.0009975831490010023 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82852\n",
            "Total Loss: 2.6654322147369385 | Context Loss: 0.0005338920163922012 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82853\n",
            "Total Loss: 2.1741795539855957 | Context Loss: 0.0006051537930034101 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82854\n",
            "Total Loss: 2.9238758087158203 | Context Loss: 0.0007020999910309911 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82855\n",
            "Total Loss: 2.453598737716675 | Context Loss: 0.0007059593335725367 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82856\n",
            "Total Loss: 2.9457528591156006 | Context Loss: 0.0005624821060337126 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82857\n",
            "Total Loss: 2.7389752864837646 | Context Loss: 0.0006903982721269131 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82858\n",
            "Total Loss: 2.963859796524048 | Context Loss: 0.000874740828294307 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82859\n",
            "Total Loss: 3.285365343093872 | Context Loss: 0.0009000912541523576 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82860\n",
            "Total Loss: 2.5513052940368652 | Context Loss: 0.0007760911248624325 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82861\n",
            "Total Loss: 2.5928773880004883 | Context Loss: 0.0006840122514404356 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82862\n",
            "Total Loss: 2.248213291168213 | Context Loss: 0.0008660481544211507 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82863\n",
            "Total Loss: 2.09303879737854 | Context Loss: 0.000637061835732311 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82864\n",
            "Total Loss: 2.1582839488983154 | Context Loss: 0.0008611695375293493 | Rhyme Loss: 0.053388066758518156 \n",
            "Iteration number: 82865\n",
            "Total Loss: 3.129065990447998 | Context Loss: 0.0006218967610038817 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82866\n",
            "Total Loss: 2.209521532058716 | Context Loss: 0.0007834691787138581 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82867\n",
            "Total Loss: 2.3411405086517334 | Context Loss: 0.0005736805032938719 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82868\n",
            "Total Loss: 3.5440800189971924 | Context Loss: 0.0006890846416354179 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82869\n",
            "Total Loss: 2.550713539123535 | Context Loss: 0.000724500510841608 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82870\n",
            "Total Loss: 3.461688995361328 | Context Loss: 0.0007684709271416068 | Rhyme Loss: 0.409646680538176 \n",
            "Iteration number: 82871\n",
            "Total Loss: 2.1541430950164795 | Context Loss: 0.0008031770121306181 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82872\n",
            "Total Loss: 2.534518241882324 | Context Loss: 0.0006932205287739635 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82873\n",
            "Total Loss: 3.5678086280822754 | Context Loss: 0.0004386919317767024 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82874\n",
            "Total Loss: 5.048368453979492 | Context Loss: 0.0005105746095068753 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82875\n",
            "Total Loss: 2.873995542526245 | Context Loss: 0.0005909575847908854 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82876\n",
            "Total Loss: 2.2814524173736572 | Context Loss: 0.0005495167570188642 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82877\n",
            "Total Loss: 3.105742931365967 | Context Loss: 0.0005881502293050289 | Rhyme Loss: 0.29001282919298677 \n",
            "Iteration number: 82878\n",
            "Total Loss: 2.744932174682617 | Context Loss: 0.0008276570588350296 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82879\n",
            "Total Loss: 2.293646812438965 | Context Loss: 0.0007991999736987054 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82880\n",
            "Total Loss: 2.5819342136383057 | Context Loss: 0.0007441174820996821 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82881\n",
            "Total Loss: 1.9262714385986328 | Context Loss: 0.0007520311628468335 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82882\n",
            "Total Loss: 3.636394500732422 | Context Loss: 0.0008021218236535788 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82883\n",
            "Total Loss: 2.859893321990967 | Context Loss: 0.0007526177214458585 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82884\n",
            "Total Loss: 1.601588249206543 | Context Loss: 0.0007570425514131784 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82885\n",
            "Total Loss: 2.1633942127227783 | Context Loss: 0.0007892221910879016 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82886\n",
            "Total Loss: 2.964975595474243 | Context Loss: 0.0006751384353265166 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82887\n",
            "Total Loss: 2.4505279064178467 | Context Loss: 0.0012244503013789654 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82888\n",
            "Total Loss: 2.958378791809082 | Context Loss: 0.0008357561309821904 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82889\n",
            "Total Loss: 2.440498113632202 | Context Loss: 0.0005577253759838641 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82890\n",
            "Total Loss: 2.9695820808410645 | Context Loss: 0.0005514839431270957 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82891\n",
            "Total Loss: 2.46435809135437 | Context Loss: 0.0009753787890076637 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82892\n",
            "Total Loss: 2.5359718799591064 | Context Loss: 0.0005853499751538038 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82893\n",
            "Total Loss: 2.20878005027771 | Context Loss: 0.0006798924878239632 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82894\n",
            "Total Loss: 2.678804397583008 | Context Loss: 0.000675734132528305 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82895\n",
            "Total Loss: 2.6198952198028564 | Context Loss: 0.0007656710804440081 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82896\n",
            "Total Loss: 2.359571933746338 | Context Loss: 0.0005596958217211068 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82897\n",
            "Total Loss: 2.899956464767456 | Context Loss: 0.0005214656703174114 | Rhyme Loss: 0.204823340269088 \n",
            "Iteration number: 82898\n",
            "Total Loss: 3.3580384254455566 | Context Loss: 0.0007079708739183843 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82899\n",
            "Total Loss: 3.9502182006835938 | Context Loss: 0.0006186679238453507 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82900\n",
            "Total Loss: 3.4894630908966064 | Context Loss: 0.0005746276583522558 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82901\n",
            "Total Loss: 3.617464542388916 | Context Loss: 0.0006536823348142207 | Rhyme Loss: 0.5546530951346693 \n",
            "Iteration number: 82902\n",
            "Total Loss: 2.782111644744873 | Context Loss: 0.0005683956551365554 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82903\n",
            "Total Loss: 1.7218328714370728 | Context Loss: 0.0008221880998462439 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82904\n",
            "Total Loss: 2.9770803451538086 | Context Loss: 0.0005587682826444507 | Rhyme Loss: 0.14500641459649338 \n",
            "Iteration number: 82905\n",
            "Total Loss: 2.336406707763672 | Context Loss: 0.001185834757052362 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82906\n",
            "Total Loss: 2.379774570465088 | Context Loss: 0.0007752762176096439 | Rhyme Loss: 0.0 \n",
            "Iteration number: 82907\n"
          ]
        }
      ]
    }
  ]
}